{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7vz0__2J7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e7514b-b5f3-4885-e31f-b5e49cb7ad13"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEFtL-QINrpe",
        "outputId": "a41151ab-5591-4f38-bf7e-9d57dd920259"
      },
      "source": [
        "!pip install livelossplot==0.5.4\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: livelossplot==0.5.4 in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.4) (2.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.4) (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.4) (5.5.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (1.19.5)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (2.8.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (21.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (3.7.4.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (5.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot==0.5.4) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot==0.5.4) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot==0.5.4) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (57.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (5.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot==0.5.4) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->livelossplot==0.5.4) (0.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.5.4) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.5.4) (0.10.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->livelossplot==0.5.4) (0.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H9Z4iZ2XPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcde2410-0d8c-466f-d0c6-8048d095ba0d"
      },
      "source": [
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "h0uiWBjK2jtU",
        "outputId": "0a3c045d-818e-4ff0-8ded-391271cf2c5e"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd3bddf7-81f9-4c57-a981-2017b239e3e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd3bddf7-81f9-4c57-a981-2017b239e3e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gabib3b\",\"key\":\"817d7e169db4cbef867b22907320144c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFkqZ-42pXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bbce41-44bf-4256-a5ee-136283a2fe22"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c home-depot-product-search-relevance"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "product_descriptions.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "attributes.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "relevance_instructions.docx: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc3SPuZR366P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68224a4-83e9-4a30-843d-e3c85d3609ed"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "import nltk \n",
        "import unidecode\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FTp4EQn3Ai5",
        "outputId": "49ae129c-fc5d-49ee-fba7-146cbf1d4ae7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attributes.csv.zip  product_descriptions.csv.zip  sample_submission.csv.zip\n",
            "GabiBurabia.pdf     relevance_instructions.docx   test.csv.zip\n",
            "kaggle.json\t    sample_data\t\t\t  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5kTCLu3wPp"
      },
      "source": [
        "att_df= pd.read_csv('attributes.csv.zip')\n",
        "desc_df= pd.read_csv('product_descriptions.csv.zip')\n",
        "df = pd.read_csv('train.csv.zip', encoding='latin-1')\n",
        "test_df = pd.read_csv('test.csv.zip',encoding='latin-1')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtCnjkmEgB4"
      },
      "source": [
        "desc_df = desc_df.fillna(0)\n",
        "df = df.fillna(0)\n",
        "test_df = test_df.fillna(0)\n",
        "att_df = att_df.fillna(0)\n",
        "\n",
        "desc_df['product_uid'] = desc_df['product_uid'].astype(np.int64)\n",
        "df['product_uid'] = df['product_uid'].astype(np.int64)\n",
        "test_df['product_uid'] = test_df['product_uid'].astype(np.int64)\n",
        "att_df['product_uid'] = att_df['product_uid'].astype(np.int64)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "Wc9y_9xh39qp",
        "outputId": "dd77421e-9275-45e0-d2e2-3bdd6d8f9594"
      },
      "source": [
        "df.sample(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60877</th>\n",
              "      <td>183673</td>\n",
              "      <td>177083</td>\n",
              "      <td>Delta Pilar Single-Handle Pull-Down Sprayer Ki...</td>\n",
              "      <td>touch 4 faucet</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17235</th>\n",
              "      <td>53219</td>\n",
              "      <td>113794</td>\n",
              "      <td>Carlon 4 in. x 4 in. x 4 in. PVC Junction Box</td>\n",
              "      <td>4inch ligh junction box</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ...              search_term relevance\n",
              "60877  183673       177083  ...           touch 4 faucet       2.0\n",
              "17235   53219       113794  ...  4inch ligh junction box       3.0\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVEuEm1CPBfa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LizRelmmMTOO",
        "outputId": "98cb3e1f-5821-49f7-cca2-124318389a40"
      },
      "source": [
        "np.min(df['relevance'].tolist()), np.max(df['relevance'].tolist())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQMvnh9G6eUX",
        "outputId": "e428917b-f2dd-4055-9ee3-b77d65d2d305"
      },
      "source": [
        "sorted(pd.unique(df['relevance']).tolist())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.25, 1.33, 1.5, 1.67, 1.75, 2.0, 2.25, 2.33, 2.5, 2.67, 2.75, 3.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXIjvtz5O6F8"
      },
      "source": [
        "# train_df['my_relevance'] = train_df['relevance'].apply(lambda x: (x - 1.0)/2.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEsYyEZdPNuC",
        "outputId": "7861602d-d756-4d15-da7b-be2943631a8f"
      },
      "source": [
        "# np.min(train_df['my_relevance'].tolist()), np.max(train_df['my_relevance'].tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYhPgWl3PQ_7"
      },
      "source": [
        "# train_df['my_relevance2'] = train_df['my_relevance'].apply(lambda x: ((x - 0.0)/1.0) * 2.0 + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Lx1rYzOzPHYD",
        "outputId": "2f1c0d00-afa9-4e74-fd87-409306d63d7a"
      },
      "source": [
        "# train_df[['relevance', 'my_relevance', 'my_relevance2']].sample(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relevance</th>\n",
              "      <th>my_relevance</th>\n",
              "      <th>my_relevance2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42392</th>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67764</th>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20523</th>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "      <td>2.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72001</th>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       relevance  my_relevance  my_relevance2\n",
              "42392       2.00         0.500           2.00\n",
              "67764       3.00         1.000           3.00\n",
              "20523       2.67         0.835           2.67\n",
              "72001       2.00         0.500           2.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "EcIh2Oqq4tQV",
        "outputId": "a9c5d0b5-3b95-4162-e7e6-b99861bc4c04"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>112385.709223</td>\n",
              "      <td>142331.911553</td>\n",
              "      <td>2.381634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>64016.573650</td>\n",
              "      <td>30770.774864</td>\n",
              "      <td>0.533984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>100001.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>57163.500000</td>\n",
              "      <td>115128.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>113228.000000</td>\n",
              "      <td>137334.000000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>168275.500000</td>\n",
              "      <td>166883.500000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>221473.000000</td>\n",
              "      <td>206650.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id    product_uid     relevance\n",
              "count   74067.000000   74067.000000  74067.000000\n",
              "mean   112385.709223  142331.911553      2.381634\n",
              "std     64016.573650   30770.774864      0.533984\n",
              "min         2.000000  100001.000000      1.000000\n",
              "25%     57163.500000  115128.500000      2.000000\n",
              "50%    113228.000000  137334.000000      2.330000\n",
              "75%    168275.500000  166883.500000      3.000000\n",
              "max    221473.000000  206650.000000      3.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ZgdzI4DeUR",
        "outputId": "708aae07-1e61-40c2-835f-5453e8e8dab4"
      },
      "source": [
        "# train_df.drop_duplicates([\"product_uid\"]).shape[0]/len(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7380749861611784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoiInP_e5LJw",
        "outputId": "c8582c97-1e15-47d3-a821-7272412af794"
      },
      "source": [
        "# pd.merge(train_df, desc_df, how='left', on='product_uid').shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GSioO4uDVOs",
        "outputId": "970a241c-1d49-415b-cf95-936674ab0bf1"
      },
      "source": [
        "df.shape[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VZQCATBHsLL"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "MAX_SEARCH_TERM_LENGTH = 15\n",
        "MAX_TITLE_LENGTH = 70"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knD9_juYJh-2"
      },
      "source": [
        "def tokenize(text, max_length):\n",
        "  \n",
        "  return tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length = max_length, \n",
        "            padding = 'max_length',\n",
        "            truncation = True, \n",
        "            return_attention_mask = True, \n",
        "            add_special_tokens = True, \n",
        "            )\n",
        "  \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSXhO_yKJ78V"
      },
      "source": [
        "#  encoding = tokenizer.encode_plus(\n",
        "#       'he went home',\n",
        "#       add_special_tokens=True,\n",
        "#       max_length= 10,\n",
        "#       return_token_type_ids=False,\n",
        "#       padding=\"max_length\",\n",
        "#       truncation=True,\n",
        "#       return_attention_mask=True\n",
        "      \n",
        "#     )\n",
        " \n",
        "#  encoding"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWbi3atuLKEU",
        "outputId": "02e326cc-c712-4f1b-e09a-ab0855c64f13"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997299742125373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBmOPW8hJAC7",
        "outputId": "2f7beca3-c3e8-45a7-9f51-27392dfb0830"
      },
      "source": [
        "df['product_title_tokens'] = df['product_title'].progress_apply(lambda text: tokenize(text, MAX_TITLE_LENGTH))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 74067/74067 [00:43<00:00, 1715.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWEyqUS_JITR",
        "outputId": "12c03a04-4605-4166-aaa4-0c1f7f914998"
      },
      "source": [
        "df['search_term_tokens'] = df['search_term'].progress_apply(lambda text: tokenize(text, MAX_SEARCH_TERM_LENGTH))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 74067/74067 [00:22<00:00, 3282.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlqKW3Pqjosz",
        "outputId": "0888295f-0376-400f-850f-b2a31f5ecf53"
      },
      "source": [
        "\n",
        "test_df['product_title_tokens'] = test_df['product_title'].progress_apply(lambda text: tokenize(text, MAX_TITLE_LENGTH))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 166693/166693 [01:36<00:00, 1734.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGbOT4XBjxm7",
        "outputId": "a1c958c3-b9ba-4de9-b7b7-2e0a868d3510"
      },
      "source": [
        "test_df['search_term_tokens'] = test_df['search_term'].progress_apply(lambda text: tokenize(text, MAX_SEARCH_TERM_LENGTH))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 166693/166693 [00:50<00:00, 3333.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3gp5t6lL4Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f29871-b8bb-4576-aa00-f403803b9a95"
      },
      "source": [
        "pd.set_option(\"max_colwidth\", -1)\n",
        "\n",
        "original_train_df_length = len(df)\n",
        "df = df[df['search_term_tokens'].notnull()]\n",
        "len(df)/original_train_df_length"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "f3eVXii3JfNI",
        "outputId": "169a0fe9-0d16-42c7-ad42-0a94deef2321"
      },
      "source": [
        "df.sample(3)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2530</th>\n",
              "      <td>7779</td>\n",
              "      <td>101312</td>\n",
              "      <td>36 in. x 80 in. 6-Panel Primed Premium Steel Front Door Slab</td>\n",
              "      <td>front doors</td>\n",
              "      <td>2.00</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39410</th>\n",
              "      <td>120229</td>\n",
              "      <td>140655</td>\n",
              "      <td>KitchenAid 30 in. Double Electric Wall Oven Self-Cleaning with Convection in Stainless Steel</td>\n",
              "      <td>30 double wall oven</td>\n",
              "      <td>2.67</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9742</th>\n",
              "      <td>30185</td>\n",
              "      <td>106532</td>\n",
              "      <td>Simpson Strong-Tie Double 2 in. x 10 in. Top Flange Face Mount Joist Hanger</td>\n",
              "      <td>top flange face mount joist hanger</td>\n",
              "      <td>3.00</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...  relevance_class\n",
              "2530   7779    ...  4              \n",
              "39410  120229  ...  3              \n",
              "9742   30185   ...  0              \n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avWAdjfoKyoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49d20df-9ec1-457a-aeeb-43144f63e0e1"
      },
      "source": [
        "\n",
        "relevance_values = sorted(pd.unique(df['relevance']).tolist())\n",
        "\n",
        "relevance_map = {relevance: index for (index, relevance) in enumerate(relevance_values)}\n",
        "num_of_classes = len(relevance_map)\n",
        "relevance_map, num_of_classes"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({1.0: 0,\n",
              "  1.25: 1,\n",
              "  1.33: 2,\n",
              "  1.5: 3,\n",
              "  1.67: 4,\n",
              "  1.75: 5,\n",
              "  2.0: 6,\n",
              "  2.25: 7,\n",
              "  2.33: 8,\n",
              "  2.5: 9,\n",
              "  2.67: 10,\n",
              "  2.75: 11,\n",
              "  3.0: 12},\n",
              " 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoNQJXA_NcFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d247b242-418e-4542-9300-9b81c7afe579"
      },
      "source": [
        "cls_to_score = {cls: score for (score, cls) in relevance_map.items()}\n",
        "cls_to_score\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0,\n",
              " 1: 1.25,\n",
              " 2: 1.33,\n",
              " 3: 1.5,\n",
              " 4: 1.67,\n",
              " 5: 1.75,\n",
              " 6: 2.0,\n",
              " 7: 2.25,\n",
              " 8: 2.33,\n",
              " 9: 2.5,\n",
              " 10: 2.67,\n",
              " 11: 2.75,\n",
              " 12: 3.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyjfyQmxMA28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f1a93d-76a4-4238-c830-88ec9befb792"
      },
      "source": [
        "\n",
        "df['relevance_class'] = df['relevance'].apply(lambda relevance: relevance_map[relevance])\n",
        "pd.unique(df['relevance_class'])\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12,  9,  8, 10,  6,  0,  4,  2,  1, 11,  5,  3,  7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0DjFymeMqeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e95758bd-379f-4b0c-e02a-c53aaec09c68"
      },
      "source": [
        "ax = sns.countplot(x=\"relevance_class\", data=df)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRGXsU7R0yFq",
        "outputId": "a2aa4a33-6d92-409a-a69d-9ea5472e4ab7"
      },
      "source": [
        "weights1"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7066325598392105,\n",
              " 1424.3653846153848,\n",
              " 1.8953631199140182,\n",
              " 1139.4923076923078,\n",
              " 0.8403335602450647,\n",
              " 633.0512820512821,\n",
              " 0.4857170962030298,\n",
              " 517.951048951049,\n",
              " 0.35476099243222536,\n",
              " 299.8663967611337,\n",
              " 0.37478368230900794,\n",
              " 517.951048951049,\n",
              " 0.2979064856711916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MnkT1xzONVQ",
        "outputId": "494df10c-ec37-404f-b316-232ba0e470f9"
      },
      "source": [
        "num_of_classes = len(pd.unique(df['relevance_class']))\n",
        "num_of_classes"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYRLs4MfNRpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61373325-5d4b-4c21-902f-27fdbbb44ca8"
      },
      "source": [
        "weights = compute_class_weight('balanced',   pd.unique(df['relevance_class']), np.array(df['relevance_class'].tolist()))\n",
        "#class_weight, *, classes, y\n",
        "weights"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.97906486e-01, 2.99866397e+02, 3.54760992e-01, 3.74783682e-01,\n",
              "       4.85717096e-01, 2.70663256e+00, 8.40333560e-01, 1.89536312e+00,\n",
              "       1.42436538e+03, 5.17951049e+02, 6.33051282e+02, 1.13949231e+03,\n",
              "       5.17951049e+02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlitDkeYNk0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d46b0de-bc8d-41e6-af4b-17aa3bed3b1d"
      },
      "source": [
        "weights[0], weights[12]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.29790648567119155, 517.951048951049)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_abuT7Gj3Ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51dcc44b-beea-4691-9287-cbe078bd0303"
      },
      "source": [
        "df[df['relevance_class'] == 12].shape[0], df[df['relevance_class'] == 0].shape[0],"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19125, 2105)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV7N4GDYNt70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22cf8af7-f8ec-4fcb-8187-3b1b3134e01c"
      },
      "source": [
        "np.bincount(df['relevance_class'].tolist())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2105,     4,  3006,     5,  6780,     9, 11730,    11, 16060,\n",
              "          19, 15202,    11, 19125])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-RIhiikNx0N"
      },
      "source": [
        "  #  encoding = tokenizer.encode_plus(\n",
        "  #     'he went home',\n",
        "  #     add_special_tokens=True,\n",
        "  #     max_length= 10,\n",
        "  #     return_token_type_ids=False,\n",
        "  #     padding=\"max_length\",\n",
        "  #     truncation=True,\n",
        "  #     return_attention_mask=True,\n",
        "  #     return_tensors='pt',\n",
        "  #   )"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC-_3NcFN6vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e67bde8-6ee0-45d1-af7c-f58b4ecc1ae6"
      },
      "source": [
        "encoding"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 1119, 1355, 1313,  102,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBWR3ogxzlgr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuiD695l1sa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz-SXcFvCGkw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3w-Ti9Ll4ty"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkY6UFlomBmQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIrQMC_njbh3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J08IiqM0Yoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98ea219-03f9-4b55-b4f2-f42241095128"
      },
      "source": [
        "1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysvXuI-DaYNR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhr-sK-Ja4hS"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlXHvpSaxhcv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw3XOMq7ceR4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HGajw9zcWWT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccgT0RxIx9xg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UtpFLaO0eGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cC_PmSZxzpX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGydTxu0O58b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdCgrrWaPKyy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "935RIRNYPVmH"
      },
      "source": [
        "test_df['relevance_class'] = -1"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhuWDnLF44ly",
        "outputId": "bcba7323-4fee-4a66-9dcc-15127e2e8123"
      },
      "source": [
        "df.iloc[0]['search_term_tokens']"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 6341, 26083, 102, 0], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ITAnaPU7P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8fGj-0COjWj"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(int(time.time()))\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "from torch import nn, utils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable \n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self._df = df\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self._df.iloc[idx]\n",
        "\n",
        "        search_term = np.array(row['search_term_tokens']['input_ids'])\n",
        "        search_term_attention_mask = np.array(row['search_term_tokens']['attention_mask'])\n",
        "        product_title = np.array(row['product_title_tokens']['input_ids'])\n",
        "        product_title_attention_mask = np.array(row['product_title_tokens']['attention_mask'])\n",
        "\n",
        "   \n",
        "\n",
        "        return row['id'], search_term, search_term_attention_mask, product_title, product_title_attention_mask, row['relevance_class']\n",
        "    \n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "NRSLuzN1kqe7",
        "outputId": "e656bce1-0871-4b4e-9e21-ee8db43f817f"
      },
      "source": [
        "df.sample(1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33462</th>\n",
              "      <td>102341</td>\n",
              "      <td>132466</td>\n",
              "      <td>UniFlame Black Wrought Iron Single-Panel Fireplace Screen with Doors, Medium</td>\n",
              "      <td>hail protective window screen</td>\n",
              "      <td>2.33</td>\n",
              "      <td>[101, 4895, 10128, 10278, 2063, 2304, 18481, 3707, 2309, 1011, 5997, 13788, 3898, 2007, 102]</td>\n",
              "      <td>[101, 16889, 9474, 3332, 102]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ...             search_term_tokens relevance_class\n",
              "33462  102341  132466       ...  [101, 16889, 9474, 3332, 102]  2             \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w27tIMkWMPR3",
        "outputId": "4c387163-440a-49a5-8c02-bebf8705efae"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "training_df, validation_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "len(training_df)+ len(validation_df), len(df)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74067, 74067)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTudx3_9QEOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34082368-7459-48a0-8138-7e3ad16940ac"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "data_loader = DatasetLoader(training_df)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(data_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "\n",
        "o_loader = DatasetLoader(training_df.sample(30))\n",
        "\n",
        "o_data_loader = torch.utils.data.DataLoader(o_loader,\n",
        "                                                 batch_size=6, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "\n",
        "validation_data_df = validation_df[['id', 'product_title_tokens', 'search_term_tokens', 'relevance', 'relevance_class']]\n",
        "validation_dataset = DatasetLoader(validation_data_df)\n",
        "\n",
        "valiodation_data_loader = torch.utils.data.DataLoader(validation_dataset,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "test_df_fixed = test_df[(test_df['search_term_tokens'].map(len) > 0) & (test_df['product_title_tokens'].map(len) > 0)]\n",
        "test_df_fixed['relevance_class'] = -1\n",
        "\n",
        "\n",
        "test_loader = DatasetLoader(test_df_fixed[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class']])\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=False, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "len(data_loader), len(test_loader), len(o_data_loader)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66660, 166693, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "hYKG8QQEAXLS",
        "outputId": "b871bacf-a1e7-4b51-d9b1-a978a35005af"
      },
      "source": [
        "df.sample(1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70607</th>\n",
              "      <td>211488</td>\n",
              "      <td>198203</td>\n",
              "      <td>Pass &amp;amp; Seymour 2-Gang 2 Duplex Outlet Wall...</td>\n",
              "      <td>stainless steel light cover plates</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...  relevance_class\n",
              "70607  211488  ...               12\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ti4DjnB3AC2K",
        "outputId": "7dc13d34-2646-42f2-c0ef-871aba6f5cbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>my_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35646</th>\n",
              "      <td>52729</td>\n",
              "      <td>113622</td>\n",
              "      <td>AT&amp;amp;T Trimline Telephone With Memory - Black</td>\n",
              "      <td>at</td>\n",
              "      <td>[amp, &lt;word&gt;, telephon, memori, black]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  product_uid  ... search_term_tokens my_relevance\n",
              "35646  52729  113622       ...  []                 1          \n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg9ZjtvyQYYj"
      },
      "source": [
        "for ids, search_term, a1, product_title, a2, target_relevance_score in test_data_loader:\n",
        "  break"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAb7Xrshd-Ap"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaU8p0SBalql"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wcUGHjMcBXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv4iT_xlBNeY"
      },
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "# config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "#                                     output_hidden_states=True)\n",
        "\n",
        "# bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                          config=config)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDYpQzBNRhe3"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "class RelevanceModel(nn.Module):\n",
        "\n",
        "  def __init__(self, num_of_classes):\n",
        "    super(RelevanceModel, self).__init__()\n",
        "    config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "                                    output_hidden_states=True)\n",
        "\n",
        "    BERT_MODEL_NAME = 'bert-base-cased'\n",
        "    # self.bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "\n",
        "\n",
        "    # for param in self.bert.parameters():\n",
        "    #   param.requires_grad = False\n",
        "\n",
        "    self.fc1 = nn.Linear(768 * 2, 512)\n",
        "    self.fc2 = nn.Linear(512, num_of_classes)\n",
        "\n",
        "\n",
        "  def  forward(self, queries, queries_masks, titles, titles_masks):\n",
        " \n",
        "    encoded_queries = self.bert(queries, attention_mask=queries_masks)\n",
        "    encoded_titles = self.bert(titles, attention_mask=titles_masks)\n",
        "\n",
        "\n",
        "    out = torch.cat((encoded_queries.pooler_output, encoded_titles.pooler_output), 1)\n",
        "\n",
        "    out = self.fc1(out)\n",
        "    out = torch.relu(out)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out \n",
        "\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.uniform_(self.fc1.weight)\n",
        "    nn.init.uniform_(self.fc2.weight)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnTv4wTQRn--"
      },
      "source": [
        "# from transformers import BertForSequenceClassification\n",
        "\n",
        "# class RelevanceModel(nn.Module):\n",
        "\n",
        "#   def __init__(self, num_of_classes):\n",
        "#     super(RelevanceModel, self).__init__()\n",
        "#     config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "#                                     output_hidden_states=True)\n",
        "\n",
        "#     self.bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "\n",
        "#     for param in self.bert_model.parameters():\n",
        "#       param.requires_grad = False\n",
        "\n",
        "#     self.fc = nn.Linear(768 * 2, num_of_classes)\n",
        "\n",
        "#   def  forward(self, queries, titles):\n",
        "#     encoded_queries = self.bert_model(queries)['hidden_states'][-1][:, -1,:]\n",
        "#     #last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "#     encoded_titles = self.bert_model(titles)['hidden_states'][-1][:, -1,:]\n",
        "\n",
        "#     out = torch.cat((encoded_queries, encoded_titles), 1)\n",
        "\n",
        "#     out = self.fc(out)\n",
        "    \n",
        "#     return out \n",
        "\n",
        "\n",
        "#   def reset_parameters(self):\n",
        "#     nn.init.uniform_(self.fc.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VMlZG21ZCK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4559ba7-c22e-4aeb-d0b1-039442bf9236"
      },
      "source": [
        "\n",
        "# # for x in model.parameters():\n",
        "# #   if not x.is_cuda:\n",
        "# #     print(x) \n",
        "\n",
        "# # e1 = EncoderModel(len(vocab)).to(device)\n",
        "# # r = e1(product_title.to(device), product_title_length)\n",
        "# output.shape, product_title_length\n",
        "# #output = r \n",
        "\n",
        "# #8\n",
        "# #out_forward = output[range(len(output)), lengths - 1, :self.embedding_dim ]\n",
        "\n",
        "# # output[range(len(output)), product_title_length - 1, :300][0]\n",
        "# product_title_length\n",
        "#output[0][14], product_title_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14, 12, 10, 15,  8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpN5VHYENQJ",
        "outputId": "5fdb6a9e-27b4-4018-d550-1631392db324"
      },
      "source": [
        "# output[0][13][300:]\n",
        "# output[:, 0, 300 :].shape, output[:, 0,]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 300]), torch.Size([5, 15, 600]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFR-SouFR5PB"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# query_encoder = EncoderModel(len(vocab))\n",
        "# title_encoder = EncoderModel(len(vocab))\n",
        "\n",
        "# query_encoder.reset_parameters()\n",
        "# title_encoder.reset_parameters()\n",
        "\n",
        "# #search_term, search_term_length, product_title, product_title_length\n",
        "# query_encoded = query_encoder(search_term, search_term_length)\n",
        "# title_encoded = query_encoder(product_title, product_title_length)\n",
        "# torch.cat((query_encoded, title_encoded), 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWnKAQe_WQyF",
        "outputId": "232d7c0f-42ca-47a8-8f76-6c19084ea35e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9AiAsOFMumH"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# weights = compute_class_weight('balanced', pd.unique(df['relevance_class']), df['relevance_class'].tolist())\n",
        "# weights"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEpPTJGLoi1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75efb3e9-1a16-47a8-a922-102f27a20faf"
      },
      "source": [
        "weights[0], weights[12]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.29790648567119155, 517.951048951049)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu2VvCcmyVy1",
        "outputId": "280eeb2c-45f2-4976-b1dc-271a886b887e"
      },
      "source": [
        "weights, weights1"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.97906486e-01, 2.99866397e+02, 3.54760992e-01, 3.74783682e-01,\n",
              "        4.85717096e-01, 2.70663256e+00, 8.40333560e-01, 1.89536312e+00,\n",
              "        1.42436538e+03, 5.17951049e+02, 6.33051282e+02, 1.13949231e+03,\n",
              "        5.17951049e+02]),\n",
              " [2.7066325598392105,\n",
              "  1424.3653846153848,\n",
              "  1.8953631199140182,\n",
              "  1139.4923076923078,\n",
              "  0.8403335602450647,\n",
              "  633.0512820512821,\n",
              "  0.4857170962030298,\n",
              "  517.951048951049,\n",
              "  0.35476099243222536,\n",
              "  299.8663967611337,\n",
              "  0.37478368230900794,\n",
              "  517.951048951049,\n",
              "  0.2979064856711916])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4d4BaszD13U",
        "outputId": "c3935d6a-adfb-4afa-b3de-ea5538ac9f5c"
      },
      "source": [
        "counts = df.groupby(\"relevance_class\").size().reset_index()\n",
        "#total = np.sum(counts[0].tolist())\n",
        "\n",
        "# [(row['relevance_class'],  row[0]/total) for (_, row) in counts[['relevance_class', 0]].iterrows()]\n",
        "\n",
        "total = 0.0\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  total += row[0]\n",
        "total \n",
        "weights1 = []\n",
        "print(total)\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  #print(row[0])\n",
        "  cls = row['relevance_class']\n",
        "  # print((cls, row[0]))\n",
        "  sampeples_weight = (row[0] / total)\n",
        "  required_weight = 1.0/len(counts)\n",
        "\n",
        "  # print('-----')\n",
        "  # print(sampeples_weight)\n",
        "  # print(required_weight)\n",
        "  x = required_weight/sampeples_weight\n",
        "  # print(x)\n",
        "\n",
        "  weight_for_class_a = (1 / row[0]) * total/len(counts)\n",
        "  \n",
        "\n",
        "   \n",
        "  # weight = x * sampeples_weight\n",
        "  # print(weight)\n",
        "  # print('-------')\n",
        "\n",
        "  weights1.append((cls, x))\n",
        "\n",
        "\n",
        "\n",
        "weights1 = sorted(weights1, key = lambda x: x[0])\n",
        "weights1 = [w[1] for w in weights1]\n",
        "weights1\n",
        "weights = weights1\n",
        "weights"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74067.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7066325598392105,\n",
              " 1424.3653846153848,\n",
              " 1.8953631199140182,\n",
              " 1139.4923076923078,\n",
              " 0.8403335602450647,\n",
              " 633.0512820512821,\n",
              " 0.4857170962030298,\n",
              " 517.951048951049,\n",
              " 0.35476099243222536,\n",
              " 299.8663967611337,\n",
              " 0.37478368230900794,\n",
              " 517.951048951049,\n",
              " 0.2979064856711916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeOpvUEp21Z7",
        "outputId": "26091d83-001f-4537-858a-077ea68169d1"
      },
      "source": [
        "weights"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7066325598392105,\n",
              " 1424.3653846153848,\n",
              " 1.8953631199140182,\n",
              " 1139.4923076923078,\n",
              " 0.8403335602450647,\n",
              " 633.0512820512821,\n",
              " 0.4857170962030298,\n",
              " 517.951048951049,\n",
              " 0.35476099243222536,\n",
              " 299.8663967611337,\n",
              " 0.37478368230900794,\n",
              " 517.951048951049,\n",
              " 0.2979064856711916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdHK8OyD0ej"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEK66lCTIt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3903157-5ee9-4142-c1e3-54ee570d813f"
      },
      "source": [
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "model = RelevanceModel(num_of_classes)\n",
        "model.reset_parameters()\n",
        "model.to(device)\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr= 1e-5)\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "#optimizer = AdamW(model.parameters(),lr = 0.001)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.0001)\n",
        "\n",
        "class_weights = torch.tensor(weights,dtype=torch.float)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight = class_weights, reduction='sum').to(device)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJiU_nc8WP8l"
      },
      "source": [
        "#  for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score  in train_data_loader:\n",
        "#     search_term = Variable(search_term).to(device)\n",
        "#     product_title = Variable(product_title).to(device)\n",
        "#     search_term_mask = Variable(search_term_mask).to(device)\n",
        "#     product_title_mask = Variable(product_title_mask).to(device)\n",
        "#     target_relevance_score = Variable(target_relevance_score).long().to(device)\n",
        "#     scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "#     break \n",
        "\n",
        "# scores.shape"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knnaKV2bWAA8"
      },
      "source": [
        "\n",
        "def train_epoc(epoc):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "  counter = 0.0\n",
        "  correct_classified = 0.0 \n",
        "  for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score  in o_data_loader: #train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    target_relevance_score = Variable(target_relevance_score).long().to(device)\n",
        "\n",
        "    search_term_mask = Variable(search_term_mask).to(device)\n",
        "    product_title_mask = Variable(product_title_mask).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "    loss = criterion(scores, target_relevance_score)\n",
        "\n",
        "    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    counter += search_term.shape[0]\n",
        "    correct_classified += np.sum(torch.argmax(scores, dim=1).cpu().detach().numpy()== target_relevance_score.cpu().numpy())\n",
        "\n",
        "  return running_loss/counter, correct_classified/counter\n",
        "\n",
        "\n",
        "def validation():\n",
        "  model.eval()\n",
        "\n",
        "  running_loss  = 0.0\n",
        "  counter = 0.0\n",
        "\n",
        "  correct_classified = 0.0 \n",
        "\n",
        "  with torch.no_grad():\n",
        "    for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score in valiodation_data_loader:\n",
        "      search_term = Variable(search_term).to(device)\n",
        "      product_title = Variable(product_title).to(device)\n",
        "\n",
        "      search_term_mask = Variable(search_term_mask).to(device)\n",
        "      product_title_mask = Variable(product_title_mask).to(device)\n",
        "\n",
        "      target_relevance_score = Variable(target_relevance_score).float().to(device)\n",
        "\n",
        "      scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "\n",
        "    \n",
        "      \n",
        "      loss = criterion(scores, target_relevance_score.long())\n",
        "      running_loss += loss.item()\n",
        "      counter += search_term.shape[0]\n",
        "      correct_classified += np.sum(torch.argmax(scores, dim=1).cpu().detach().numpy()== target_relevance_score.cpu().numpy())\n",
        "  \n",
        "  #print('validation epoc {} loss {} counter {}'.format(epoc, running_loss/counter, counter))\n",
        "\n",
        "  return running_loss/counter, correct_classified/counter  \n",
        "\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5w7B_5bF5tl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "32cf9ceb-7451-4bee-cba1-37bed58b0e0a"
      },
      "source": [
        "from livelossplot import PlotLosses\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "\n",
        "for epoc in range(1000):\n",
        "\n",
        "  train_loss, train_accuracy = train_epoc(epoc)\n",
        "  validation_loss, val_accuracy = 0, 0  #validation()\n",
        "\n",
        "  liveloss.update({\n",
        "          'train_loss': train_loss,\n",
        "          'validation_loss': validation_loss,\n",
        "\n",
        "          'train_accuracy': train_accuracy,\n",
        "          'validation_accuracy': val_accuracy\n",
        "      })\n",
        "    \n",
        "  liveloss.draw()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-f4bd7e5d8c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m#validation()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-31653344cf37>\u001b[0m in \u001b[0;36mtrain_epoc\u001b[0;34m(epoc)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_term_mask\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mproduct_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_title_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_relevance_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-605549241449>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, queries, queries_masks, titles, titles_masks)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mencoded_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mencoded_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitles_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         )\n\u001b[1;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j23Rz5eLleqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87221c04-f14f-440b-f53a-dbf8ed9a9151"
      },
      "source": [
        "train_loss, train_accuracy "
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.960157677449875, 0.06183618361836184)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B5hKqKGe-y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40ac4d6-11ad-4d5b-c20a-b111868f38a1"
      },
      "source": [
        "np.sum(torch.argmax(scores, dim=1).detach().cpu().numpy() == target_relevance_score.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "GTBEJ3CasIks",
        "outputId": "26206649-135f-4a51-f31e-6afd534431f6"
      },
      "source": [
        "r1, scores.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-e40e950c9e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'r1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgvd78qCkW8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91fc4088-6c99-4399-cbbe-8f0c77d61f49"
      },
      "source": [
        "\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "\n",
        "bb = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True, output_hidden_states=True).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    search_term_mask = Variable(search_term_mask).to(device)\n",
        "    \n",
        "    xx = bb(search_term, attention_mask=search_term_mask)\n",
        "    # scores = model(search_term, product_title)\n",
        "\n",
        "    # test_scores.extend(scores.detach().cpu().numpy().flatten().tolist())\n",
        "    # test_ids.extend(ids.numpy().tolist())\n",
        "    # tt.extend(target_relevance_score.numpy().tolist())\n",
        "\n",
        "    break\n",
        "  \n",
        "\n"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbHcq1FIn00K",
        "outputId": "b8a2dcaa-0b43-4f83-8cec-d16f5b4ab15e"
      },
      "source": [
        "xx[0].shape, xx[1].shape, len(xx)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 5, 768]), torch.Size([64, 768]), 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdxRw_b_LTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4149dfe-59a4-43e6-bf5c-e28e32c89929"
      },
      "source": [
        "xx.last_hidden_state.shape, xx.pooler_output.shape, len(xx.hidden_states[0])"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 5, 768]), torch.Size([64, 768]), 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYqvaAVNk6pY",
        "outputId": "16cc1c51-8bdd-47c7-d0a3-519169d8e55e"
      },
      "source": [
        "# model.eval()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score in valiodation_data_loader:\n",
        "#     search_term = Variable(search_term).to(device)\n",
        "#     product_title = Variable(product_title).to(device)\n",
        "\n",
        "#     search_term_mask = Variable(search_term_mask).to(device)\n",
        "#     product_title_mask = Variable(product_title_mask).to(device)\n",
        "\n",
        "#     target_relevance_score = Variable(target_relevance_score).float().to(device)\n",
        "\n",
        "#     scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "\n",
        "#     break\n",
        "i=33\n",
        "torch.softmax(scores, dim=1)[i], target_relevance_score[i], torch.argmax(scores), torch.argmax(scores, dim=1)[i]\n",
        "    \n",
        "  "
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0783, 0.0807, 0.0782, 0.0778, 0.0785, 0.0782, 0.0785, 0.0779, 0.0657,\n",
              "         0.0778, 0.0756, 0.0699, 0.0828], device='cuda:0'),\n",
              " tensor(0., device='cuda:0'),\n",
              " tensor(12, device='cuda:0'),\n",
              " tensor(12, device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-HHAoXDZCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce45f3e5-ac44-4e64-8bec-8e2353ce7fe0"
      },
      "source": [
        "# 166693, len(test_data), len(test_df)\n",
        "all_ids = {x for (x, _) in test_data}\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "  if row['id'] not in all_ids:\n",
        "    test_data.append((row['id'], 1))\n",
        "    \n",
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCkYUGAMgvqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "22baab70-d698-426d-91cb-b8b4ac14201c"
      },
      "source": [
        "yy = df.sample(10)[['product_title', 'search_term', 'relevance', 'relevance_class', 'product_title_tokens', 'search_term_tokens']]\n",
        "yy"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>relevance_class</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6952</th>\n",
              "      <td>Delta Porter 4 in. Centerset 2-Handle High-Arc Bathroom Faucet in Oil Rubbed Bronze</td>\n",
              "      <td>Bronze bath rug</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6394</th>\n",
              "      <td>Husky 8-Pocket Nail Pouch</td>\n",
              "      <td>nail bags</td>\n",
              "      <td>2.67</td>\n",
              "      <td>3</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34189</th>\n",
              "      <td>RIDGID JobMax 12-Volt Multi-Tool Starter Kit</td>\n",
              "      <td>ridgid 12 volt</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23924</th>\n",
              "      <td>MOEN Brantford Tank Lever in Brushed Nickel</td>\n",
              "      <td>moen brantford nickel</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14101</th>\n",
              "      <td>WeatherStar 36 in. x 55 in. 2-Track Storm Aluminum Window</td>\n",
              "      <td>Aluminum track for windows</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65139</th>\n",
              "      <td>DEWALT Harsh Condition Insulated Size Large Work Glove</td>\n",
              "      <td>Insulted work gloves</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33636</th>\n",
              "      <td>A-C Draftshields 12 in. x 12 in. Vent Cover</td>\n",
              "      <td>8x22 a/c vent</td>\n",
              "      <td>1.33</td>\n",
              "      <td>7</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70402</th>\n",
              "      <td>Commercial Electric 2 in. 45å¡ Sch. 40 Belled End Elbow</td>\n",
              "      <td>2 pipe 45</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57216</th>\n",
              "      <td>Commercial Electric 11 in. Cable Tie - Natural (100-Pack)</td>\n",
              "      <td>commercial smart tie</td>\n",
              "      <td>2.33</td>\n",
              "      <td>2</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20838</th>\n",
              "      <td>Nature Power Bayport 72 in. Black Outdoor Solar Lamp Post with Super Bright Natural White LED</td>\n",
              "      <td>post lamp tier</td>\n",
              "      <td>2.67</td>\n",
              "      <td>3</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                       product_title  ...                           search_term_tokens\n",
              "6952   Delta Porter 4 in. Centerset 2-Handle High-Arc Bathroom Faucet in Oil Rubbed Bronze            ...  [input_ids, token_type_ids, attention_mask]\n",
              "6394   Husky 8-Pocket Nail Pouch                                                                      ...  [input_ids, token_type_ids, attention_mask]\n",
              "34189  RIDGID JobMax 12-Volt Multi-Tool Starter Kit                                                   ...  [input_ids, token_type_ids, attention_mask]\n",
              "23924  MOEN Brantford Tank Lever in Brushed Nickel                                                    ...  [input_ids, token_type_ids, attention_mask]\n",
              "14101  WeatherStar 36 in. x 55 in. 2-Track Storm Aluminum Window                                      ...  [input_ids, token_type_ids, attention_mask]\n",
              "65139  DEWALT Harsh Condition Insulated Size Large Work Glove                                         ...  [input_ids, token_type_ids, attention_mask]\n",
              "33636  A-C Draftshields 12 in. x 12 in. Vent Cover                                                    ...  [input_ids, token_type_ids, attention_mask]\n",
              "70402  Commercial Electric 2 in. 45å¡ Sch. 40 Belled End Elbow                                        ...  [input_ids, token_type_ids, attention_mask]\n",
              "57216  Commercial Electric 11 in. Cable Tie - Natural (100-Pack)                                      ...  [input_ids, token_type_ids, attention_mask]\n",
              "20838  Nature Power Bayport 72 in. Black Outdoor Solar Lamp Post with Super Bright Natural White LED  ...  [input_ids, token_type_ids, attention_mask]\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6XfNPdDKx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18c4fd2a-77b5-40dc-b802-71af0983f330"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f1fa6b5d-807b-4df1-b82c-3b19b4724bfd\", \"test_res.csv\", 1850918)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrqzbWUODp-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0655e0a-327b-452d-b0e5-9ab2c912b494"
      },
      "source": [
        "i = 0\n",
        "yy.iloc[i]['product_title'], tokenizer.convert_ids_to_tokens(yy.iloc[i]['product_title_tokens']['input_ids'])"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Delta Porter 4 in. Centerset 2-Handle High-Arc Bathroom Faucet in Oil Rubbed Bronze',\n",
              " ['[CLS]',\n",
              "  'delta',\n",
              "  'porter',\n",
              "  '4',\n",
              "  'in',\n",
              "  '.',\n",
              "  'centers',\n",
              "  '##et',\n",
              "  '2',\n",
              "  '-',\n",
              "  'handle',\n",
              "  'high',\n",
              "  '-',\n",
              "  'arc',\n",
              "  'bathroom',\n",
              "  'fa',\n",
              "  '##uce',\n",
              "  '##t',\n",
              "  'in',\n",
              "  'oil',\n",
              "  'rubbed',\n",
              "  'bronze',\n",
              "  '[SEP]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    }
  ]
}