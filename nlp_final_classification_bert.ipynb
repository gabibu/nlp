{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7vz0__2J7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f1b392-d68c-4b4b-f6f4-235ee32ed47c"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ax7FdV0_Kq"
      },
      "source": [
        "import os \n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEFtL-QINrpe",
        "outputId": "e4eb3a0d-1804-4aa0-ae55-2a3b6d3f87b4"
      },
      "source": [
        "!pip install livelossplot==0.5.4\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: livelossplot==0.5.4 in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.4) (3.2.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.4) (2.3.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.4) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (1.19.5)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (2.11.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (5.4.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (5.1.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (21.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.4) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot==0.5.4) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot==0.5.4) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot==0.5.4) (1.15.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (5.0.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (57.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.4) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot==0.5.4) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->livelossplot==0.5.4) (0.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.5.4) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.5.4) (0.10.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->livelossplot==0.5.4) (0.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H9Z4iZ2XPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b600dd2b-4288-46c7-ef72-5c411e403305"
      },
      "source": [
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "h0uiWBjK2jtU",
        "outputId": "5c57ae31-0324-40a0-bde6-f268f73e9f6e"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa0b34d7-76e3-468f-b774-c1c4fd53252a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa0b34d7-76e3-468f-b774-c1c4fd53252a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gabib3b\",\"key\":\"817d7e169db4cbef867b22907320144c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFkqZ-42pXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78458374-0e78-4298-ad75-542c046d848f"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c home-depot-product-search-relevance"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "relevance_instructions.docx: Skipping, found more recently modified local copy (use --force to force download)\n",
            "product_descriptions.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "attributes.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc3SPuZR366P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8d7f45-99c9-40b3-efa9-544b1b5733c2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "import nltk \n",
        "import unidecode\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FTp4EQn3Ai5",
        "outputId": "89e1548b-871e-4032-9538-9eed2672d22c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " attributes.csv.zip   product_descriptions.csv.zip   sample_submission.csv.zip\n",
            "'kaggle (1).json'     relevance_instructions.docx    test.csv.zip\n",
            " kaggle.json\t      sample_data\t\t     train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5kTCLu3wPp"
      },
      "source": [
        "att_df= pd.read_csv('attributes.csv.zip')\n",
        "desc_df= pd.read_csv('product_descriptions.csv.zip')\n",
        "df = pd.read_csv('train.csv.zip', encoding='latin-1')\n",
        "test_df = pd.read_csv('test.csv.zip',encoding='latin-1')\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtCnjkmEgB4"
      },
      "source": [
        "desc_df = desc_df.fillna(0)\n",
        "df = df.fillna(0)\n",
        "\n",
        "test_df = test_df.fillna(0)\n",
        "att_df = att_df.fillna(0)\n",
        "\n",
        "desc_df['product_uid'] = desc_df['product_uid'].astype(np.int64)\n",
        "df['product_uid'] = df['product_uid'].astype(np.int64)\n",
        "test_df['product_uid'] = test_df['product_uid'].astype(np.int64)\n",
        "att_df['product_uid'] = att_df['product_uid'].astype(np.int64)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "Wc9y_9xh39qp",
        "outputId": "46d893ed-7e31-4808-98b9-02d34a99bd80"
      },
      "source": [
        "df.sample(2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>58143</th>\n",
              "      <td>175698</td>\n",
              "      <td>171638</td>\n",
              "      <td>Linzer 6 in. x 1/2 in. Woven Fabric Roller Cov...</td>\n",
              "      <td>linzer 6 1/2 fabric rollers</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37611</th>\n",
              "      <td>115017</td>\n",
              "      <td>138150</td>\n",
              "      <td>Husky 33 gal. Quiet Portable Electric Air Comp...</td>\n",
              "      <td>vetical 125lb air compressors</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ...                    search_term relevance\n",
              "58143  175698       171638  ...    linzer 6 1/2 fabric rollers      2.33\n",
              "37611  115017       138150  ...  vetical 125lb air compressors      2.33\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LizRelmmMTOO",
        "outputId": "c8a4414e-f8db-4f4d-f16f-1ec90d73c086"
      },
      "source": [
        "np.min(df['relevance'].tolist()), np.max(df['relevance'].tolist())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQMvnh9G6eUX",
        "outputId": "74936559-b5e7-40d4-dea4-2b0a30f75922"
      },
      "source": [
        "sorted(pd.unique(df['relevance']).tolist())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.25, 1.33, 1.5, 1.67, 1.75, 2.0, 2.25, 2.33, 2.5, 2.67, 2.75, 3.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "EcIh2Oqq4tQV",
        "outputId": "b20d2e33-e71d-4663-d411-6007c3aa7eba"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>112385.709223</td>\n",
              "      <td>142331.911553</td>\n",
              "      <td>2.381634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>64016.573650</td>\n",
              "      <td>30770.774864</td>\n",
              "      <td>0.533984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>100001.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>57163.500000</td>\n",
              "      <td>115128.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>113228.000000</td>\n",
              "      <td>137334.000000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>168275.500000</td>\n",
              "      <td>166883.500000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>221473.000000</td>\n",
              "      <td>206650.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id    product_uid     relevance\n",
              "count   74067.000000   74067.000000  74067.000000\n",
              "mean   112385.709223  142331.911553      2.381634\n",
              "std     64016.573650   30770.774864      0.533984\n",
              "min         2.000000  100001.000000      1.000000\n",
              "25%     57163.500000  115128.500000      2.000000\n",
              "50%    113228.000000  137334.000000      2.330000\n",
              "75%    168275.500000  166883.500000      3.000000\n",
              "max    221473.000000  206650.000000      3.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GSioO4uDVOs",
        "outputId": "3cd9275b-b23f-44fd-ad8f-eed4d64adc9b"
      },
      "source": [
        "df.shape[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VZQCATBHsLL"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "MAX_SEARCH_TERM_LENGTH = 15\n",
        "MAX_TITLE_LENGTH = 50"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knD9_juYJh-2"
      },
      "source": [
        "def tokenize(text, max_length):\n",
        "  \n",
        "  return tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length = max_length, \n",
        "            padding = 'max_length',\n",
        "            truncation = True, \n",
        "            return_attention_mask = True, \n",
        "            add_special_tokens = True, \n",
        "            )\n",
        "  \n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBmOPW8hJAC7",
        "outputId": "11775362-63f2-42e6-bb6f-b3f5a33c25cc"
      },
      "source": [
        "df['product_title_tokens'] = df['product_title'].progress_apply(lambda text: tokenize(text, MAX_TITLE_LENGTH))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 74067/74067 [00:35<00:00, 2111.87it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWEyqUS_JITR",
        "outputId": "189fe7d8-f0c3-4ba1-f253-aa0965581b40"
      },
      "source": [
        "df['search_term_tokens'] = df['search_term'].progress_apply(lambda text: tokenize(text, MAX_SEARCH_TERM_LENGTH))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 74067/74067 [00:16<00:00, 4397.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlqKW3Pqjosz",
        "outputId": "75d20f28-916b-4d21-8162-d72d59c2b2b8"
      },
      "source": [
        "\n",
        "test_df['product_title_tokens'] = test_df['product_title'].progress_apply(lambda text: tokenize(text, MAX_TITLE_LENGTH))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 166693/166693 [01:17<00:00, 2161.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGbOT4XBjxm7",
        "outputId": "8cfca5c8-bae5-4c41-c677-b834ec9e3cfe"
      },
      "source": [
        "test_df['search_term_tokens'] = test_df['search_term'].progress_apply(lambda text: tokenize(text, MAX_SEARCH_TERM_LENGTH))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 166693/166693 [00:38<00:00, 4300.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3gp5t6lL4Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc3ec61-ed88-48c4-8acd-5dc2269b3271"
      },
      "source": [
        "pd.set_option(\"max_colwidth\", -1)\n",
        "\n",
        "original_train_df_length = len(df)\n",
        "df = df[df['search_term_tokens'].notnull()]\n",
        "len(df)/original_train_df_length"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "f3eVXii3JfNI",
        "outputId": "83bb83aa-34df-4f0e-c5e7-c8dbda141f15"
      },
      "source": [
        "df.sample(3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53235</th>\n",
              "      <td>161555</td>\n",
              "      <td>162738</td>\n",
              "      <td>No Drilling Required Draad Rustproof Solid Brass Shower Caddy 12 in. Double Shelf in Chrome</td>\n",
              "      <td>brass shower</td>\n",
              "      <td>3.00</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37900</th>\n",
              "      <td>115829</td>\n",
              "      <td>138513</td>\n",
              "      <td>American Standard EverClean 6 ft. x 36 in. Reversible Drain Whirlpool Tub in White</td>\n",
              "      <td>main drain tub</td>\n",
              "      <td>1.33</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68455</th>\n",
              "      <td>205412</td>\n",
              "      <td>193274</td>\n",
              "      <td>Brite Star 18 ft. 50-Light Red Rope Light</td>\n",
              "      <td>rope light kid</td>\n",
              "      <td>2.67</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                           search_term_tokens\n",
              "53235  161555  ...  [input_ids, token_type_ids, attention_mask]\n",
              "37900  115829  ...  [input_ids, token_type_ids, attention_mask]\n",
              "68455  205412  ...  [input_ids, token_type_ids, attention_mask]\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avWAdjfoKyoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae581e68-6294-4504-e17a-c085df89905a"
      },
      "source": [
        "\n",
        "relevance_values = sorted(pd.unique(df['relevance']).tolist())\n",
        "\n",
        "relevance_map = {relevance: index for (index, relevance) in enumerate(relevance_values)}\n",
        "num_of_classes = len(relevance_map)\n",
        "relevance_map, num_of_classes"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({1.0: 0,\n",
              "  1.25: 1,\n",
              "  1.33: 2,\n",
              "  1.5: 3,\n",
              "  1.67: 4,\n",
              "  1.75: 5,\n",
              "  2.0: 6,\n",
              "  2.25: 7,\n",
              "  2.33: 8,\n",
              "  2.5: 9,\n",
              "  2.67: 10,\n",
              "  2.75: 11,\n",
              "  3.0: 12},\n",
              " 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoNQJXA_NcFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f674d81-07c4-4923-9298-755af60d9fc8"
      },
      "source": [
        "cls_to_score = {cls: score for (score, cls) in relevance_map.items()}\n",
        "cls_to_score"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0,\n",
              " 1: 1.25,\n",
              " 2: 1.33,\n",
              " 3: 1.5,\n",
              " 4: 1.67,\n",
              " 5: 1.75,\n",
              " 6: 2.0,\n",
              " 7: 2.25,\n",
              " 8: 2.33,\n",
              " 9: 2.5,\n",
              " 10: 2.67,\n",
              " 11: 2.75,\n",
              " 12: 3.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyjfyQmxMA28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc1015d-0da5-4ba2-cd18-0016c9b94abc"
      },
      "source": [
        "\n",
        "df['relevance_class'] = df['relevance'].apply(lambda relevance: relevance_map[relevance])\n",
        "pd.unique(df['relevance_class'])\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12,  9,  8, 10,  6,  0,  4,  2,  1, 11,  5,  3,  7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0DjFymeMqeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "4c94ee0a-ccc0-4afb-e595-351dd20e5c81"
      },
      "source": [
        "ax = sns.countplot(x=\"relevance_class\", data=df)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MnkT1xzONVQ",
        "outputId": "fd90f696-54c7-4c54-8def-afba63326099"
      },
      "source": [
        "num_of_classes = len(pd.unique(df['relevance_class']))\n",
        "num_of_classes"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYRLs4MfNRpz"
      },
      "source": [
        "# weights = compute_class_weight('balanced',   pd.unique(df['relevance_class']), np.array(df['relevance_class'].tolist()))\n",
        "# #class_weight, *, classes, y\n",
        "# weights"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_abuT7Gj3Ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55757737-53b8-4340-9c36-3a2936f8d1c3"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV7N4GDYNt70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89701a4b-88a6-4fe9-b113-6ae25b8384f7"
      },
      "source": [
        "np.bincount(df['relevance_class'].tolist())"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2105,     4,  3006,     5,  6780,     9, 11730,    11, 16060,\n",
              "          19, 15202,    11, 19125])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-RIhiikNx0N"
      },
      "source": [
        "  #  encoding = tokenizer.encode_plus(\n",
        "  #     'he went home',\n",
        "  #     add_special_tokens=True,\n",
        "  #     max_length= 10,\n",
        "  #     return_token_type_ids=False,\n",
        "  #     padding=\"max_length\",\n",
        "  #     truncation=True,\n",
        "  #     return_attention_mask=True,\n",
        "  #     return_tensors='pt',\n",
        "  #   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "935RIRNYPVmH"
      },
      "source": [
        "test_df['relevance_class'] = -1"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhuWDnLF44ly",
        "outputId": "5a9addaa-4230-468c-d35a-6f18ff00edc7"
      },
      "source": [
        "df.iloc[0]['search_term_tokens']"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 6466, 21605, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ITAnaPU7P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8fGj-0COjWj"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(int(time.time()))\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "from torch import nn, utils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable \n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self._df = df\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self._df.iloc[idx]\n",
        "\n",
        "        search_term = np.array(row['search_term_tokens']['input_ids'])\n",
        "        search_term_attention_mask = np.array(row['search_term_tokens']['attention_mask'])\n",
        "        product_title = np.array(row['product_title_tokens']['input_ids'])\n",
        "        product_title_attention_mask = np.array(row['product_title_tokens']['attention_mask'])\n",
        "\n",
        "   \n",
        "\n",
        "        return row['id'], search_term, search_term_attention_mask, product_title, product_title_attention_mask, row['relevance_class']\n",
        "    \n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "NRSLuzN1kqe7",
        "outputId": "e2dcecd3-cabc-41a3-c152-f2f76aafec87"
      },
      "source": [
        "df.sample(1)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11775</th>\n",
              "      <td>36311</td>\n",
              "      <td>108370</td>\n",
              "      <td>the great outdoors by Minka Lavery Mossoro LED Mossoro 1-Light Black Outdoor LED Chain Hung</td>\n",
              "      <td>the great outdoors grills</td>\n",
              "      <td>1.33</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...  relevance_class\n",
              "11775  36311  ...  2              \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w27tIMkWMPR3",
        "outputId": "3e6f6294-eb5c-4af2-9430-f55bc6269048"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "training_df, validation_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "len(training_df)+ len(validation_df), len(df)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74067, 74067)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTudx3_9QEOw"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "data_loader = DatasetLoader(training_df)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(data_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "\n",
        "o_loader = DatasetLoader(training_df)\n",
        "\n",
        "o_data_loader = torch.utils.data.DataLoader(o_loader,\n",
        "                                                 batch_size=6, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "\n",
        "validation_data_df = validation_df[['id', 'product_title_tokens', 'search_term_tokens', 'relevance', 'relevance_class']]\n",
        "validation_dataset = DatasetLoader(validation_data_df)\n",
        "\n",
        "valiodation_data_loader = torch.utils.data.DataLoader(validation_dataset,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "# test_df_fixed = test_df[(test_df['search_term_tokens'].map(len) > 0) & (test_df['product_title_tokens'].map(len) > 0)]\n",
        "# test_df_fixed['relevance_class'] = -1\n",
        "\n",
        "\n",
        "# test_loader = DatasetLoader(test_df_fixed[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class']])\n",
        "\n",
        "# test_data_loader = torch.utils.data.DataLoader(test_loader,\n",
        "#                                                  batch_size=BATCH_SIZE, shuffle=False, \n",
        "#                                                  num_workers=4,drop_last=False)\n",
        "\n",
        "# len(data_loader), len(test_loader), len(o_data_loader)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "hYKG8QQEAXLS",
        "outputId": "70a6a9a1-d6f4-4ffa-8e45-c64168dbb673"
      },
      "source": [
        "df.sample(1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60730</th>\n",
              "      <td>183287</td>\n",
              "      <td>176807</td>\n",
              "      <td>Cutler Kitchen &amp;amp; Bath Textures Collection 15 in. W Linen Storage Cabinet in Driftwood</td>\n",
              "      <td>westminster kitchen cabinets</td>\n",
              "      <td>1.67</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...  relevance_class\n",
              "60730  183287  ...  4              \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv4iT_xlBNeY"
      },
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "# config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "#                                     output_hidden_states=True)\n",
        "\n",
        "# bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                          config=config)\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDYpQzBNRhe3"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "class RelevanceModel(nn.Module):\n",
        "\n",
        "  def __init__(self, num_of_classes):\n",
        "    super(RelevanceModel, self).__init__()\n",
        "    config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "                                    output_hidden_states=True)\n",
        "\n",
        "    BERT_MODEL_NAME = 'bert-base-cased'\n",
        "    # self.bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "\n",
        "\n",
        "    # for param in self.bert.parameters():\n",
        "    #   param.requires_grad = False\n",
        "\n",
        "    self.fc1 = nn.Linear(768 * 2, 512)\n",
        "    self.fc2 = nn.Linear(512, num_of_classes)\n",
        "\n",
        "\n",
        "  def  forward(self, queries, queries_masks, titles, titles_masks):\n",
        " \n",
        "    encoded_queries = self.bert(queries, attention_mask=queries_masks)\n",
        "    encoded_titles = self.bert(titles, attention_mask=titles_masks)\n",
        "\n",
        "\n",
        "    out = torch.cat((encoded_queries.pooler_output, encoded_titles.pooler_output), 1)\n",
        "\n",
        "    out = self.fc1(out)\n",
        "    out = torch.relu(out)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out \n",
        "\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.uniform_(self.fc1.weight)\n",
        "    nn.init.uniform_(self.fc2.weight)\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFR-SouFR5PB"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# query_encoder = EncoderModel(len(vocab))\n",
        "# title_encoder = EncoderModel(len(vocab))\n",
        "\n",
        "# query_encoder.reset_parameters()\n",
        "# title_encoder.reset_parameters()\n",
        "\n",
        "# #search_term, search_term_length, product_title, product_title_length\n",
        "# query_encoded = query_encoder(search_term, search_term_length)\n",
        "# title_encoded = query_encoder(product_title, product_title_length)\n",
        "# torch.cat((query_encoded, title_encoded), 1)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWnKAQe_WQyF",
        "outputId": "f88c2701-43c8-405e-9e61-c4839a6a6bed"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9AiAsOFMumH"
      },
      "source": [
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# weights = compute_class_weight('balanced', pd.unique(df['relevance_class']), df['relevance_class'].tolist())\n",
        "# weights"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4d4BaszD13U",
        "outputId": "0486b573-26e0-45ac-b6c0-d3c1248807cf"
      },
      "source": [
        "counts = df.groupby(\"relevance_class\").size().reset_index()\n",
        "#total = np.sum(counts[0].tolist())\n",
        "\n",
        "# [(row['relevance_class'],  row[0]/total) for (_, row) in counts[['relevance_class', 0]].iterrows()]\n",
        "\n",
        "total = 0.0\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  total += row[0]\n",
        "total \n",
        "weights1 = []\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  #print(row[0])\n",
        "  cls = row['relevance_class']\n",
        "  # print((cls, row[0]))\n",
        "  sampeples_weight = (row[0] / total)\n",
        "  required_weight = 1.0/len(counts)\n",
        "\n",
        "  # print('-----')\n",
        "  # print(sampeples_weight)\n",
        "  # print(required_weight)\n",
        "  x = required_weight/sampeples_weight\n",
        "  # print(x)\n",
        "\n",
        "  weight_for_class_a = (1 / row[0]) * total/len(counts)\n",
        "  \n",
        "\n",
        "   \n",
        "  # weight = x * sampeples_weight\n",
        "  # print(weight)\n",
        "  # print('-------')\n",
        "\n",
        "  weights1.append((cls, x))\n",
        "\n",
        "\n",
        "\n",
        "weights1 = sorted(weights1, key = lambda x: x[0])\n",
        "weights1 = [w[1] for w in weights1]\n",
        "weights1\n",
        "weights = weights1\n",
        "weights"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7066325598392105,\n",
              " 1424.3653846153848,\n",
              " 1.8953631199140182,\n",
              " 1139.4923076923078,\n",
              " 0.8403335602450647,\n",
              " 633.0512820512821,\n",
              " 0.4857170962030298,\n",
              " 517.951048951049,\n",
              " 0.35476099243222536,\n",
              " 299.8663967611337,\n",
              " 0.37478368230900794,\n",
              " 517.951048951049,\n",
              " 0.2979064856711916]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdHK8OyD0ej"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEK66lCTIt9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "12dfbc4d-8846-49b1-a50c-c4e828947171"
      },
      "source": [
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "model = RelevanceModel(num_of_classes)\n",
        "model.reset_parameters()\n",
        "model.to(device)\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr= 1e-5)\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "#optimizer = AdamW(model.parameters(),lr = 0.001)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.0001)\n",
        "\n",
        "class_weights = torch.tensor(weights,dtype=torch.float)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight = class_weights, reduction='sum').to(device)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-b0b248e484c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRelevanceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#optimizer = torch.optim.Adam(model.parameters(), lr= 1e-5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJiU_nc8WP8l"
      },
      "source": [
        "#  for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score  in train_data_loader:\n",
        "#     search_term = Variable(search_term).to(device)\n",
        "#     product_title = Variable(product_title).to(device)\n",
        "#     search_term_mask = Variable(search_term_mask).to(device)\n",
        "#     product_title_mask = Variable(product_title_mask).to(device)\n",
        "#     target_relevance_score = Variable(target_relevance_score).long().to(device)\n",
        "#     scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "#     break \n",
        "\n",
        "# scores.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knnaKV2bWAA8"
      },
      "source": [
        "\n",
        "def train_epoc(epoc):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "  counter = 0.0\n",
        "  correct_classified = 0.0 \n",
        "  for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score  in o_data_loader: #train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    target_relevance_score = Variable(target_relevance_score).long().to(device)\n",
        "\n",
        "    search_term_mask = Variable(search_term_mask).to(device)\n",
        "    product_title_mask = Variable(product_title_mask).to(device)\n",
        "    \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "    \n",
        "    loss = criterion(scores, target_relevance_score)\n",
        "\n",
        "    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    counter += search_term.shape[0]\n",
        "    correct_classified += np.sum(torch.argmax(scores, dim=1).cpu().detach().numpy()== target_relevance_score.cpu().numpy())\n",
        "\n",
        "  return running_loss/counter, correct_classified/counter\n",
        "\n",
        "\n",
        "\n",
        "def validation():\n",
        "  model.eval()\n",
        "\n",
        "  running_loss  = 0.0\n",
        "  counter = 0.0\n",
        "\n",
        "  correct_classified = 0.0 \n",
        "\n",
        "  with torch.no_grad():\n",
        "    for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score in valiodation_data_loader:\n",
        "      search_term = Variable(search_term).to(device)\n",
        "      product_title = Variable(product_title).to(device)\n",
        "\n",
        "      search_term_mask = Variable(search_term_mask).to(device)\n",
        "      product_title_mask = Variable(product_title_mask).to(device)\n",
        "\n",
        "      target_relevance_score = Variable(target_relevance_score).float().to(device)\n",
        "\n",
        "      scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "\n",
        "    \n",
        "      \n",
        "      loss = criterion(scores, target_relevance_score.long())\n",
        "      running_loss += loss.item()\n",
        "      counter += search_term.shape[0]\n",
        "      correct_classified += np.sum(torch.argmax(scores, dim=1).cpu().detach().numpy()== target_relevance_score.cpu().numpy())\n",
        "  \n",
        "\n",
        "  return running_loss/counter, correct_classified/counter  \n",
        "\n",
        "\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAIzsy0dzjdk"
      },
      "source": [
        "# for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score  in o_data_loader: #train_data_loader:\n",
        "#   break\n",
        "\n",
        "# # import os \n",
        "\n",
        "# # os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "# Variable(search_term).to(device)\n",
        "# Variable(search_term_mask).to(device)\n",
        "# Variable(product_title).to(device)\n",
        "# Variable(product_title_mask).to(device)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5w7B_5bF5tl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "d01788d0-cb24-4271-bf88-c1f112accc2d"
      },
      "source": [
        "from livelossplot import PlotLosses\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "\n",
        "for epoc in range(1000):\n",
        "\n",
        "  train_loss, train_accuracy = train_epoc(epoc)\n",
        "  validation_loss, val_accuracy = 0, 0  #validation()\n",
        "\n",
        "  liveloss.update({\n",
        "          'train_loss': train_loss,\n",
        "          'validation_loss': validation_loss,\n",
        "\n",
        "          'train_accuracy': train_accuracy,\n",
        "          'validation_accuracy': val_accuracy\n",
        "      })\n",
        "    \n",
        "  liveloss.draw()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-f4bd7e5d8c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m#validation()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-14dc48db977b>\u001b[0m in \u001b[0;36mtrain_epoc\u001b[0;34m(epoc)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j23Rz5eLleqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b63490-7219-4c64-89bd-1b140552ceb0"
      },
      "source": [
        "# for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score  in o_data_loader:\n",
        "#   break\n",
        "\n",
        "# search_term = Variable(search_term).to(device)\n",
        "# product_title = Variable(product_title).to(device)\n",
        "\n",
        "# search_term_mask = Variable(search_term_mask).to(device)\n",
        "# product_title_mask = Variable(product_title_mask).to(device)\n",
        "\n",
        "search_term.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 15])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B5hKqKGe-y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40ac4d6-11ad-4d5b-c20a-b111868f38a1"
      },
      "source": [
        "np.sum(torch.argmax(scores, dim=1).detach().cpu().numpy() == target_relevance_score.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "GTBEJ3CasIks",
        "outputId": "26206649-135f-4a51-f31e-6afd534431f6"
      },
      "source": [
        "r1, scores.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-e40e950c9e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'r1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgvd78qCkW8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91fc4088-6c99-4399-cbbe-8f0c77d61f49"
      },
      "source": [
        "\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "\n",
        "bb = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True, output_hidden_states=True).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    search_term_mask = Variable(search_term_mask).to(device)\n",
        "    \n",
        "    xx = bb(search_term, attention_mask=search_term_mask)\n",
        "    # scores = model(search_term, product_title)\n",
        "\n",
        "    # test_scores.extend(scores.detach().cpu().numpy().flatten().tolist())\n",
        "    # test_ids.extend(ids.numpy().tolist())\n",
        "    # tt.extend(target_relevance_score.numpy().tolist())\n",
        "\n",
        "    break\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbHcq1FIn00K",
        "outputId": "b8a2dcaa-0b43-4f83-8cec-d16f5b4ab15e"
      },
      "source": [
        "xx[0].shape, xx[1].shape, len(xx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 5, 768]), torch.Size([64, 768]), 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdxRw_b_LTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4149dfe-59a4-43e6-bf5c-e28e32c89929"
      },
      "source": [
        "xx.last_hidden_state.shape, xx.pooler_output.shape, len(xx.hidden_states[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 5, 768]), torch.Size([64, 768]), 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYqvaAVNk6pY",
        "outputId": "16cc1c51-8bdd-47c7-d0a3-519169d8e55e"
      },
      "source": [
        "# model.eval()\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   for ids, search_term, search_term_mask, product_title, product_title_mask, target_relevance_score in valiodation_data_loader:\n",
        "#     search_term = Variable(search_term).to(device)\n",
        "#     product_title = Variable(product_title).to(device)\n",
        "\n",
        "#     search_term_mask = Variable(search_term_mask).to(device)\n",
        "#     product_title_mask = Variable(product_title_mask).to(device)\n",
        "\n",
        "#     target_relevance_score = Variable(target_relevance_score).float().to(device)\n",
        "\n",
        "#     scores = model(search_term, search_term_mask,  product_title, product_title_mask)\n",
        "\n",
        "#     break\n",
        "i=33\n",
        "torch.softmax(scores, dim=1)[i], target_relevance_score[i], torch.argmax(scores), torch.argmax(scores, dim=1)[i]\n",
        "    \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0783, 0.0807, 0.0782, 0.0778, 0.0785, 0.0782, 0.0785, 0.0779, 0.0657,\n",
              "         0.0778, 0.0756, 0.0699, 0.0828], device='cuda:0'),\n",
              " tensor(0., device='cuda:0'),\n",
              " tensor(12, device='cuda:0'),\n",
              " tensor(12, device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-HHAoXDZCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce45f3e5-ac44-4e64-8bec-8e2353ce7fe0"
      },
      "source": [
        "# 166693, len(test_data), len(test_df)\n",
        "all_ids = {x for (x, _) in test_data}\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "  if row['id'] not in all_ids:\n",
        "    test_data.append((row['id'], 1))\n",
        "    \n",
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCkYUGAMgvqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "22baab70-d698-426d-91cb-b8b4ac14201c"
      },
      "source": [
        "yy = df.sample(10)[['product_title', 'search_term', 'relevance', 'relevance_class', 'product_title_tokens', 'search_term_tokens']]\n",
        "yy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>relevance_class</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6952</th>\n",
              "      <td>Delta Porter 4 in. Centerset 2-Handle High-Arc Bathroom Faucet in Oil Rubbed Bronze</td>\n",
              "      <td>Bronze bath rug</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6394</th>\n",
              "      <td>Husky 8-Pocket Nail Pouch</td>\n",
              "      <td>nail bags</td>\n",
              "      <td>2.67</td>\n",
              "      <td>3</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34189</th>\n",
              "      <td>RIDGID JobMax 12-Volt Multi-Tool Starter Kit</td>\n",
              "      <td>ridgid 12 volt</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23924</th>\n",
              "      <td>MOEN Brantford Tank Lever in Brushed Nickel</td>\n",
              "      <td>moen brantford nickel</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14101</th>\n",
              "      <td>WeatherStar 36 in. x 55 in. 2-Track Storm Aluminum Window</td>\n",
              "      <td>Aluminum track for windows</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65139</th>\n",
              "      <td>DEWALT Harsh Condition Insulated Size Large Work Glove</td>\n",
              "      <td>Insulted work gloves</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33636</th>\n",
              "      <td>A-C Draftshields 12 in. x 12 in. Vent Cover</td>\n",
              "      <td>8x22 a/c vent</td>\n",
              "      <td>1.33</td>\n",
              "      <td>7</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70402</th>\n",
              "      <td>Commercial Electric 2 in. 45å¡ Sch. 40 Belled End Elbow</td>\n",
              "      <td>2 pipe 45</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57216</th>\n",
              "      <td>Commercial Electric 11 in. Cable Tie - Natural (100-Pack)</td>\n",
              "      <td>commercial smart tie</td>\n",
              "      <td>2.33</td>\n",
              "      <td>2</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20838</th>\n",
              "      <td>Nature Power Bayport 72 in. Black Outdoor Solar Lamp Post with Super Bright Natural White LED</td>\n",
              "      <td>post lamp tier</td>\n",
              "      <td>2.67</td>\n",
              "      <td>3</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                       product_title  ...                           search_term_tokens\n",
              "6952   Delta Porter 4 in. Centerset 2-Handle High-Arc Bathroom Faucet in Oil Rubbed Bronze            ...  [input_ids, token_type_ids, attention_mask]\n",
              "6394   Husky 8-Pocket Nail Pouch                                                                      ...  [input_ids, token_type_ids, attention_mask]\n",
              "34189  RIDGID JobMax 12-Volt Multi-Tool Starter Kit                                                   ...  [input_ids, token_type_ids, attention_mask]\n",
              "23924  MOEN Brantford Tank Lever in Brushed Nickel                                                    ...  [input_ids, token_type_ids, attention_mask]\n",
              "14101  WeatherStar 36 in. x 55 in. 2-Track Storm Aluminum Window                                      ...  [input_ids, token_type_ids, attention_mask]\n",
              "65139  DEWALT Harsh Condition Insulated Size Large Work Glove                                         ...  [input_ids, token_type_ids, attention_mask]\n",
              "33636  A-C Draftshields 12 in. x 12 in. Vent Cover                                                    ...  [input_ids, token_type_ids, attention_mask]\n",
              "70402  Commercial Electric 2 in. 45å¡ Sch. 40 Belled End Elbow                                        ...  [input_ids, token_type_ids, attention_mask]\n",
              "57216  Commercial Electric 11 in. Cable Tie - Natural (100-Pack)                                      ...  [input_ids, token_type_ids, attention_mask]\n",
              "20838  Nature Power Bayport 72 in. Black Outdoor Solar Lamp Post with Super Bright Natural White LED  ...  [input_ids, token_type_ids, attention_mask]\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6XfNPdDKx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18c4fd2a-77b5-40dc-b802-71af0983f330"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f1fa6b5d-807b-4df1-b82c-3b19b4724bfd\", \"test_res.csv\", 1850918)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrqzbWUODp-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0655e0a-327b-452d-b0e5-9ab2c912b494"
      },
      "source": [
        "i = 0\n",
        "yy.iloc[i]['product_title'], tokenizer.convert_ids_to_tokens(yy.iloc[i]['product_title_tokens']['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Delta Porter 4 in. Centerset 2-Handle High-Arc Bathroom Faucet in Oil Rubbed Bronze',\n",
              " ['[CLS]',\n",
              "  'delta',\n",
              "  'porter',\n",
              "  '4',\n",
              "  'in',\n",
              "  '.',\n",
              "  'centers',\n",
              "  '##et',\n",
              "  '2',\n",
              "  '-',\n",
              "  'handle',\n",
              "  'high',\n",
              "  '-',\n",
              "  'arc',\n",
              "  'bathroom',\n",
              "  'fa',\n",
              "  '##uce',\n",
              "  '##t',\n",
              "  'in',\n",
              "  'oil',\n",
              "  'rubbed',\n",
              "  'bronze',\n",
              "  '[SEP]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    }
  ]
}