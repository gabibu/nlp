{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4 - RC",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aab1172cbf25475fbe4a9ae8bab6068d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_39382161d0634221b4879648715e64f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0afd760f6d014055a40146e51073acf8",
              "IPY_MODEL_f99211ec91eb4a33b5c2e2296b777967"
            ]
          }
        },
        "39382161d0634221b4879648715e64f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0afd760f6d014055a40146e51073acf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f05eb457260e4d17a63022eef4e6c0a9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8c718ffdb014501bc478593bf442fb5"
          }
        },
        "f99211ec91eb4a33b5c2e2296b777967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_628fb3041a0547608962a93e360833f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:01&lt;00:00, 307B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb379eebe26e4b99a1f18ffb84028cf1"
          }
        },
        "f05eb457260e4d17a63022eef4e6c0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8c718ffdb014501bc478593bf442fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "628fb3041a0547608962a93e360833f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb379eebe26e4b99a1f18ffb84028cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92fa48e5a20341268331b8408a9f80f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_305c40846d6e450d9710a0a5fe0a9e7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_144ac1b6c2dc40798c4a39e0c4e76b1a",
              "IPY_MODEL_0023706cd1f247c591909424eb9a9cc1"
            ]
          }
        },
        "305c40846d6e450d9710a0a5fe0a9e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "144ac1b6c2dc40798c4a39e0c4e76b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e4a95967ed5458d872557274452a254",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b23188e136e8425f96ad1509c03d5ade"
          }
        },
        "0023706cd1f247c591909424eb9a9cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0b073d267a14a84af74198a9c064324",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 46.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9f236de84154ce29fed5590cb19f374"
          }
        },
        "0e4a95967ed5458d872557274452a254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b23188e136e8425f96ad1509c03d5ade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0b073d267a14a84af74198a9c064324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9f236de84154ce29fed5590cb19f374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS"
      },
      "source": [
        "# Assignment 4\n",
        "Training a simple neural net for relation classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enPCGBF8FlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0e7fbc-1933-48e8-803a-d8daf7ff3dcd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/d5/c6c23ad75491467a9a84e526ef2364e523d45e2b0fae28a7cbe8689e7e84/transformers-4.8.1-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 9.6MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QSIEoyDdWh"
      },
      "source": [
        "In this assignment you are required to build a full training and testing pipeline for a neural relation classification (RC), using BERT.\n",
        "\n",
        "The dataset that you will be working on is called SemEval Task 8 dataset (https://arxiv.org/pdf/1911.10422v1.pdf). The dataset contain only train and test split, but you are allowed to split the train dataset into dev if needed.\n",
        "\n",
        "\n",
        "The two files (train and test) are available from the course git repository (https://github.com/kfirbar/nlp-course)\n",
        "\n",
        "\n",
        "In this work we will use the hugingface framework for transformers training and inference. We recomand reading the documentation in https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification *before* you start coding. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8"
      },
      "source": [
        "**Task 1:** Write a funtion *read_data* for reading the data from a single file (either train or test). This function recieves a filepath and returns a list of sentence. Every sentence is encoded as a touple, where the first element is the sentence string and the second the label (also represented as a sting). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k91W8arHL6Y",
        "outputId": "3034b67f-ef37-4ac8-f63d-506b567b0dbc"
      },
      "source": [
        "!git clone https://github.com/kfirbar/nlp-course"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-course'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 71 (delta 29), reused 40 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ltCjA2-Z6L"
      },
      "source": [
        "FIRST_ENTITY_START_TOKEN = '<e1>'\n",
        "SECOND_ENTITY_START_TOKEN = '<e2>'\n",
        "entities_tags = [FIRST_ENTITY_START_TOKEN, '</e1>', SECOND_ENTITY_START_TOKEN, '</e2>']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y"
      },
      "source": [
        "\n",
        "def read_data(filepath):\n",
        "    data = []\n",
        "    # TODO... write your code accordingly\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        while True:         \n",
        "            sentense = next(f, None)\n",
        "            if sentense is None:\n",
        "                break\n",
        "\n",
        "            label = next(f)\n",
        "            _ = next(f)\n",
        "            _ = next(f)\n",
        "            data.append((sentense.strip(), label.strip()))\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "train = read_data('/content/nlp-course/TRAIN_FILE.TXT')\n",
        "#test = read_data('/content/nlp-course/TEST_FILE.txt')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGwk6OwRWGS"
      },
      "source": [
        "Pytorch require the labels to be integers. Create a mapper (dictionary) from the string labels to integers (starting zero). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKIB5o_vQO8"
      },
      "source": [
        "def create_label_mapper(data):\n",
        "  # TODO... write your code accordingly \n",
        "  label_mapper = {}\n",
        "  for _, label in data:\n",
        "    if label not in label_mapper:\n",
        "      label_mapper[label] = len(label_mapper)\n",
        "\n",
        "  return label_mapper\n",
        "  \n",
        "\n",
        "label_mapper = create_label_mapper(train)\n",
        "            "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6PXVz_RHv_J",
        "outputId": "670c6331-11e9-4d79-c357-f2633d666984"
      },
      "source": [
        "len(label_mapper), len(train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 8000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKYryfKfNdh"
      },
      "source": [
        "**Task 2:** Write a function *prepare_data* that takes one of the [train, test] datasets and convert each pair of (words,labels) to a pair of indexes. The function also aggregate the samples into batches. BERT Uses pretrained tokanization and embedding. you can access the tokanization and indexing using the BertTokenizer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noIY3zWKvhBd"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "import numpy as np\n",
        "\n",
        "def prepare_data(data, tokenizer, batch_size=8, remove_entities_tags = False):\n",
        "    data_sequences = []\n",
        "    # TODO - your code...\n",
        "\n",
        "    indexes = np.random.choice(range(0, len(data)), size = len(data) ,replace=False)\n",
        "    \n",
        "    current_batch_input = []\n",
        "    current_batch_labels = []\n",
        "    \n",
        "    for i in range(0, len(indexes), batch_size): #index in indexes:\n",
        "      curremt_indexes = indexes[i: i+ batch_size]\n",
        "      batch_data = [data[i] for i in curremt_indexes]\n",
        "      \n",
        "      sentenses = [row[0] for row in batch_data]\n",
        "\n",
        "      if remove_entities_tags:\n",
        "        for entity_tag in entities_tags:\n",
        "          sentenses = [sentense.replace(entity_tag, '') for sentense in sentenses]\n",
        "\n",
        "      labels = torch.from_numpy(np.array([label_mapper[row[1]] for row in batch_data]))\n",
        "      \n",
        "      sentenses_ids = tokenizer.batch_encode_plus(sentenses, padding = 'longest', return_tensors='pt')['input_ids']\n",
        "      \n",
        "      data_sequences.append((sentenses_ids, labels))\n",
        "    \n",
        "    return data_sequences\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', padding = 'max_length', truncation=True, return_tensors='pt')\n",
        "\n",
        "train_sequences = prepare_data(train, tokenizer, remove_entities_tags=True)\n",
        "\n",
        "# test_sequences = prepare_data(test, tokenizer)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FYc1wY0_MwL",
        "outputId": "4133c74e-33c4-4efb-f6d0-540f61d26707"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3n4cCb8wpXE"
      },
      "source": [
        "**Task 3:** In this part we classify the sentences using the BertForSequenceClassification model. To save resources, we initialize the optimizer with the final layer of the model. You are also allowed to change the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efvj5qvPxNJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "aab1172cbf25475fbe4a9ae8bab6068d",
            "39382161d0634221b4879648715e64f9",
            "0afd760f6d014055a40146e51073acf8",
            "f99211ec91eb4a33b5c2e2296b777967",
            "f05eb457260e4d17a63022eef4e6c0a9",
            "b8c718ffdb014501bc478593bf442fb5",
            "628fb3041a0547608962a93e360833f4",
            "cb379eebe26e4b99a1f18ffb84028cf1",
            "92fa48e5a20341268331b8408a9f80f8",
            "305c40846d6e450d9710a0a5fe0a9e7f",
            "144ac1b6c2dc40798c4a39e0c4e76b1a",
            "0023706cd1f247c591909424eb9a9cc1",
            "0e4a95967ed5458d872557274452a254",
            "b23188e136e8425f96ad1509c03d5ade",
            "e0b073d267a14a84af74198a9c064324",
            "f9f236de84154ce29fed5590cb19f374"
          ]
        },
        "outputId": "a0290370-1126-4a84-82d1-c51e5a0c2dbc"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "def get_parameters(params):\n",
        "  # TODO - your code...\n",
        "  fixed_params = []\n",
        "  for name, param in params:\n",
        "    if 'classifier' not in name:\n",
        "      param.requires_grad = False\n",
        "    fixed_params.append(param)\n",
        "\n",
        "  return fixed_params\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_mapper)).to(device)\n",
        "\n",
        "# Optimizer (ADAM is a fancy version of SGD)\n",
        "optimizer = torch.optim.Adam(get_parameters(model.named_parameters()), lr=0.001)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aab1172cbf25475fbe4a9ae8bab6068d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92fa48e5a20341268331b8408a9f80f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEGSQdeUkTP8"
      },
      "source": [
        "**Task 4:** Write a training loop, which takes a BertForSequenceClassification model and number of epochs to train on. The loss is always CrossEntropyLoss and the optimizer is always Adam. You are allowed to split the train to train and dev sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avkHfjT3k0HM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "92cca66c-9ac3-42c0-9add-5f248c363916"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def train_loop(model, n_epochs, train_data, dev_data):\n",
        "  # Loss function\n",
        "  model.train()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "  for e in range(1, n_epochs + 1):\n",
        "    batch_loss = 0.0 \n",
        "    for sentenses, labels in train_data:\n",
        "      sentenses = Variable(sentenses).to(device)\n",
        "      labels = Variable(labels).to(device)\n",
        "\n",
        "      logits = model(sentenses).logits\n",
        "      loss = criterion(logits, labels)\n",
        "\n",
        "      batch_loss += loss.item()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "     \n",
        "      \n",
        "    \n",
        "    print('batch {} loss {}'.format(e, batch_loss/len(train_data)))\n",
        "\n",
        "\n",
        "\n",
        "train_loop(model,100, train_sequences, None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch 1 loss 2.7332123152017593\n",
            "batch 2 loss 2.6692887511253356\n",
            "batch 3 loss 2.6196994042396544\n",
            "batch 4 loss 2.5933048094511033\n",
            "batch 5 loss 2.5591999559402465\n",
            "batch 6 loss 2.545403914690018\n",
            "batch 7 loss 2.5247345197200777\n",
            "batch 8 loss 2.497903301715851\n",
            "batch 9 loss 2.489982751727104\n",
            "batch 10 loss 2.489350494623184\n",
            "batch 11 loss 2.4793478957414625\n",
            "batch 12 loss 2.46604198551178\n",
            "batch 13 loss 2.4546597558259964\n",
            "batch 14 loss 2.442286616206169\n",
            "batch 15 loss 2.443987538218498\n",
            "batch 16 loss 2.432078175663948\n",
            "batch 17 loss 2.429134279727936\n",
            "batch 18 loss 2.429857209086418\n",
            "batch 19 loss 2.427776198267937\n",
            "batch 20 loss 2.4209993138313295\n",
            "batch 21 loss 2.4211116232872008\n",
            "batch 22 loss 2.4101237890720366\n",
            "batch 23 loss 2.407373149394989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-878fa12c6226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# inputs = train_sequences[0][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-166-878fa12c6226>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, n_epochs, train_data, dev_data)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentenses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m         )\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         )\n\u001b[1;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         )\n\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN1c_B7lTjb"
      },
      "source": [
        "**Task 5:** write an evaluation loop on a trained model, using the dev and test datasets. This function print the true positive rate (TPR), also known as Recall and the opposite to false positive rate (FPR), also known as precision, of each label seperately (10 labels in total), and for all labels together. The caption argument for the function should be served for printing, so that when you print include it as a prefix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQAjGaqmd8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58df87e5-a725-4183-ac4e-5599fe16296f"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def evaluate(model, test_data):\n",
        "  # TODO - your code goes here\n",
        "  model.eval()\n",
        "  all_predictions = []\n",
        "  all_labels = []\n",
        "  with torch.no_grad():\n",
        "    for sentenses, labels in test_data:\n",
        "      sentenses = Variable(sentenses).to(device)\n",
        "      labels = labels.numpy()\n",
        "\n",
        "      logits = model(sentenses).logits\n",
        "\n",
        "      prediction = torch.argmax(logits, 1).cpu().detach().numpy()\n",
        "\n",
        "      all_labels.extend(labels.tolist())\n",
        "      all_predictions.extend(prediction.tolist())\n",
        "\n",
        "    print(metrics.classification_report(labels, prediction, digits=3))\n",
        "      \n",
        "\n",
        "evaluate(model, train_sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      1.000     0.500     0.667         2\n",
            "           1      0.000     0.000     0.000         0\n",
            "           2      0.000     0.000     0.000         1\n",
            "           4      0.000     0.000     0.000         0\n",
            "           5      0.000     0.000     0.000         1\n",
            "           6      0.000     0.000     0.000         1\n",
            "           7      0.000     0.000     0.000         0\n",
            "           9      0.000     0.000     0.000         1\n",
            "          10      0.000     0.000     0.000         1\n",
            "          12      1.000     1.000     1.000         1\n",
            "\n",
            "    accuracy                          0.250         8\n",
            "   macro avg      0.200     0.150     0.167         8\n",
            "weighted avg      0.375     0.250     0.292         8\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjkeUfncUl42"
      },
      "source": [
        "**Task 6:** In this part we'll improve the model accuracy by using a method called \"entity markers - Entity start\". The main idea of this approch is to add special markers ([e1], [\\e1], ...) before and after each of the tagged entities. instead of using the CLS toekn for clasification, we will use the concatination of the embedding of [e1] and [e2] as shown in the image below. The complete method is described in details in the following paper - https://arxiv.org/pdf/1906.03158.pdf (specifically in Section 3.2). To use this method we'll need to create a new data load and a new model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKhIbJuzc_EE"
      },
      "source": [
        "![Capture.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTRk1T81VoXj"
      },
      "source": [
        "The new methods require the usage of special tokens. The following code will add the required tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU8jayVXYGsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43860a0-be64-42cd-8742-19dace0c11cb"
      },
      "source": [
        "tokenizer.add_tokens(entities_tags)\n",
        "first_entity_start_token_id, second_entity_start_token_id = tokenizer.convert_tokens_to_ids([FIRST_ENTITY_START_TOKEN, SECOND_ENTITY_START_TOKEN])\n",
        "first_entity_start_token_id, second_entity_start_token_id\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30522, 30524)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2UMaxjFYOB7"
      },
      "source": [
        "Create a new dataloader that add entity markers to the dataset and return their indexes as part of the new sample (the expected sample should be (s, l, i) where s is the sentence embedding, l is the label, and i is a touple with the indexes of the start entities)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMMMR1kSYnc3"
      },
      "source": [
        "def prepare_data_MTB(data, tokenizer, batch_size=8):\n",
        "    data_sequences = []\n",
        "    # TODO - your code...\n",
        "\n",
        "    indexes = np.random.choice(range(0, len(data)), size = len(data) ,replace=False)\n",
        "    \n",
        "    current_batch_input = []\n",
        "    current_batch_labels = []\n",
        "    \n",
        "    for i in range(0, len(indexes), batch_size): #index in indexes:\n",
        "      curremt_indexes = indexes[i: i+ batch_size]\n",
        "      batch_data = [data[i] for i in curremt_indexes]\n",
        "      \n",
        "      sentenses = [row[0] for row in batch_data]\n",
        "\n",
        "      labels = torch.from_numpy(np.array([label_mapper[row[1]] for row in batch_data]))\n",
        "      \n",
        "      sentenses_ids = tokenizer.batch_encode_plus(sentenses, padding = 'longest', return_tensors='pt')['input_ids']\n",
        "      \n",
        "      # print(sentenses_ids[0].numpy().tolist().index(102))\n",
        "      # break \n",
        "      first_send_entites_start_locations = [(sentense_ids.numpy().tolist().index(first_entity_start_token_id), sentense_ids.numpy().tolist().index(second_entity_start_token_id)) for sentense_ids in sentenses_ids]\n",
        "\n",
        "    #   data_sequences.append((sentenses_ids, labels, first_send_entites_start_locations))\n",
        "    \n",
        "    # return data_sequences\n",
        "\n",
        "\n",
        "    return data_sequences\n",
        "\n",
        "train_sequences = prepare_data_MTB(train, tokenizer)\n",
        "#test_sequences = prepare_data_MTB(test, tokenizer)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AztAwecuYyt3"
      },
      "source": [
        "Create a new model that uses the \"entity markers - Entity start\" method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADpFlxPFY5mD"
      },
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "\n",
        "class MTB(nn.Module):\n",
        "    def __init__(self, base_model_name):\n",
        "      nn.Module.__init__(self)\n",
        "      config = AutoConfig.from_pretrained(base_model_name)\n",
        "      self.model = AutoModel.from_config(config)\n",
        "      # TODO - your code...\n",
        "    def forward(self, input, index):\n",
        "      # TODO - your code...\n",
        "      pass\n",
        "\n",
        "\n",
        "model = MTB('bert-base-uncased')\n",
        "\n",
        "# config = AutoConfig.from_pretrained('bert-base-uncased')\n",
        "# model1 = AutoModel.from_config(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuwCczHeZjaw"
      },
      "source": [
        "Use the new dataloader and model to train and evaluate the new model as in task 4 and 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k46XVrTHZxcu"
      },
      "source": [
        "train_loop(model, n_epochs, train_data, dev_data)\n",
        "evaluate(model, test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaESRoco6bV"
      },
      "source": [
        "**Good luck!**"
      ]
    }
  ]
}