{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7vz0__2J7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b79e95-2f78-4392-bc2e-d61ab4399220"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 12.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H9Z4iZ2XPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a112a4e9-e593-49c9-ef20-05105111d0f5"
      },
      "source": [
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "h0uiWBjK2jtU",
        "outputId": "2e54fa83-468a-462b-8567-90c411a10201"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e7c74fc-42db-4e61-a96f-00e9a577f620\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e7c74fc-42db-4e61-a96f-00e9a577f620\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gabib3b\",\"key\":\"817d7e169db4cbef867b22907320144c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFkqZ-42pXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21fdfbc9-9969-4da9-c5c2-5a992e50b272"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c home-depot-product-search-relevance"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/227k [00:00<?, ?B/s]\n",
            "100% 227k/227k [00:00<00:00, 86.4MB/s]\n",
            "Downloading relevance_instructions.docx to /content\n",
            "  0% 0.00/105k [00:00<?, ?B/s]\n",
            "100% 105k/105k [00:00<00:00, 103MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/2.51M [00:00<?, ?B/s]\n",
            "100% 2.51M/2.51M [00:00<00:00, 83.1MB/s]\n",
            "Downloading product_descriptions.csv.zip to /content\n",
            " 72% 25.0M/34.8M [00:00<00:00, 37.6MB/s]\n",
            "100% 34.8M/34.8M [00:00<00:00, 70.7MB/s]\n",
            "Downloading attributes.csv.zip to /content\n",
            " 33% 9.00M/27.2M [00:00<00:00, 28.1MB/s]\n",
            "100% 27.2M/27.2M [00:00<00:00, 68.7MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            "100% 4.74M/4.74M [00:00<00:00, 34.1MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc3SPuZR366P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f6f3da-0386-4041-fc52-b7379b7ca7cf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "import nltk \n",
        "import unidecode\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FTp4EQn3Ai5",
        "outputId": "d4c45f75-caba-4684-b970-739f0553a60a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attributes.csv.zip\t      relevance_instructions.docx  test.csv.zip\n",
            "kaggle.json\t\t      sample_data\t\t   train.csv.zip\n",
            "product_descriptions.csv.zip  sample_submission.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5kTCLu3wPp"
      },
      "source": [
        "att_df= pd.read_csv('attributes.csv.zip')\n",
        "desc_df= pd.read_csv('product_descriptions.csv.zip')\n",
        "train_df= pd.read_csv('train.csv.zip', encoding='latin-1')\n",
        "test_df = pd.read_csv('test.csv.zip',encoding='latin-1')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtCnjkmEgB4"
      },
      "source": [
        "desc_df = desc_df.fillna(0)\n",
        "train_df = train_df.fillna(0)\n",
        "test_df = test_df.fillna(0)\n",
        "att_df = att_df.fillna(0)\n",
        "\n",
        "desc_df['product_uid'] = desc_df['product_uid'].astype(np.int64)\n",
        "train_df['product_uid'] = train_df['product_uid'].astype(np.int64)\n",
        "test_df['product_uid'] = test_df['product_uid'].astype(np.int64)\n",
        "att_df['product_uid'] = att_df['product_uid'].astype(np.int64)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "Wc9y_9xh39qp",
        "outputId": "d8d1b970-8d04-438c-a266-c0642c6221d0"
      },
      "source": [
        "train_df.sample(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36655</th>\n",
              "      <td>112068</td>\n",
              "      <td>136796</td>\n",
              "      <td>Household Essentials 12 in. Under Sink Sliding...</td>\n",
              "      <td>under cabinet storage</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20417</th>\n",
              "      <td>63007</td>\n",
              "      <td>117115</td>\n",
              "      <td>Home Styles Kitchen Cart in Natural Wood</td>\n",
              "      <td>spacer bar for kitchen cabinets</td>\n",
              "      <td>1.67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ...                      search_term relevance\n",
              "36655  112068       136796  ...            under cabinet storage      2.00\n",
              "20417   63007       117115  ...  spacer bar for kitchen cabinets      1.67\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVEuEm1CPBfa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LizRelmmMTOO",
        "outputId": "521f461a-0dcf-4c8b-851d-74d83cfc34fc"
      },
      "source": [
        "np.min(train_df['relevance'].tolist()), np.max(train_df['relevance'].tolist())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQMvnh9G6eUX",
        "outputId": "d41e4531-a4bc-462b-812e-ea28969557ea"
      },
      "source": [
        "sorted(pd.unique(train_df['relevance']).tolist())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.25, 1.33, 1.5, 1.67, 1.75, 2.0, 2.25, 2.33, 2.5, 2.67, 2.75, 3.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXIjvtz5O6F8"
      },
      "source": [
        "# train_df['my_relevance'] = train_df['relevance'].apply(lambda x: (x - 1.0)/2.0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEsYyEZdPNuC",
        "outputId": "7861602d-d756-4d15-da7b-be2943631a8f"
      },
      "source": [
        "# np.min(train_df['my_relevance'].tolist()), np.max(train_df['my_relevance'].tolist())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYhPgWl3PQ_7"
      },
      "source": [
        "# train_df['my_relevance2'] = train_df['my_relevance'].apply(lambda x: ((x - 0.0)/1.0) * 2.0 + 1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Lx1rYzOzPHYD",
        "outputId": "2f1c0d00-afa9-4e74-fd87-409306d63d7a"
      },
      "source": [
        "# train_df[['relevance', 'my_relevance', 'my_relevance2']].sample(4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relevance</th>\n",
              "      <th>my_relevance</th>\n",
              "      <th>my_relevance2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42392</th>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67764</th>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20523</th>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "      <td>2.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72001</th>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       relevance  my_relevance  my_relevance2\n",
              "42392       2.00         0.500           2.00\n",
              "67764       3.00         1.000           3.00\n",
              "20523       2.67         0.835           2.67\n",
              "72001       2.00         0.500           2.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "EcIh2Oqq4tQV",
        "outputId": "4fee35c7-9a82-46be-9091-15589c1ffce9"
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>relevance</th>\n",
              "      <th>my_relevance</th>\n",
              "      <th>my_relevance2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "      <td>74067.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>112385.709223</td>\n",
              "      <td>142331.911553</td>\n",
              "      <td>2.381634</td>\n",
              "      <td>0.690817</td>\n",
              "      <td>2.381634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>64016.573650</td>\n",
              "      <td>30770.774864</td>\n",
              "      <td>0.533984</td>\n",
              "      <td>0.266992</td>\n",
              "      <td>0.533984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>100001.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>57163.500000</td>\n",
              "      <td>115128.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>113228.000000</td>\n",
              "      <td>137334.000000</td>\n",
              "      <td>2.330000</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>168275.500000</td>\n",
              "      <td>166883.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>221473.000000</td>\n",
              "      <td>206650.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id    product_uid     relevance  my_relevance  my_relevance2\n",
              "count   74067.000000   74067.000000  74067.000000  74067.000000   74067.000000\n",
              "mean   112385.709223  142331.911553      2.381634      0.690817       2.381634\n",
              "std     64016.573650   30770.774864      0.533984      0.266992       0.533984\n",
              "min         2.000000  100001.000000      1.000000      0.000000       1.000000\n",
              "25%     57163.500000  115128.500000      2.000000      0.500000       2.000000\n",
              "50%    113228.000000  137334.000000      2.330000      0.665000       2.330000\n",
              "75%    168275.500000  166883.500000      3.000000      1.000000       3.000000\n",
              "max    221473.000000  206650.000000      3.000000      1.000000       3.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ZgdzI4DeUR",
        "outputId": "708aae07-1e61-40c2-835f-5453e8e8dab4"
      },
      "source": [
        "# train_df.drop_duplicates([\"product_uid\"]).shape[0]/len(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7380749861611784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoiInP_e5LJw",
        "outputId": "c8582c97-1e15-47d3-a821-7272412af794"
      },
      "source": [
        "# pd.merge(train_df, desc_df, how='left', on='product_uid').shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GSioO4uDVOs",
        "outputId": "de4f2ca3-2be4-43be-e506-ee1a00e6aebe"
      },
      "source": [
        "train_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VZQCATBHsLL"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "MAX_SEARCH_TERM_LENGTH = 5\n",
        "MAX_TITLE_LENGTH = 15"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knD9_juYJh-2"
      },
      "source": [
        "def tokenize(text, max_length):\n",
        "  \n",
        "  return tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length = max_length, \n",
        "            padding = 'max_length',\n",
        "            truncation = True, \n",
        "            return_attention_mask = False, \n",
        "            add_special_tokens = True, \n",
        "            )['input_ids']\n",
        "  \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSXhO_yKJ78V",
        "outputId": "5829e55a-eca5-4e47-9da2-8721fe75f5b3"
      },
      "source": [
        "# tokenize(\"he went home 123 times, before we --gabi op. -;[]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['went', 'home', '###', 'time', 'befor', 'gabi', 'op']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWbi3atuLKEU",
        "outputId": "02e326cc-c712-4f1b-e09a-ab0855c64f13"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997299742125373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBmOPW8hJAC7",
        "outputId": "c3de02b2-6d9e-4765-c66c-2ed1d7c59015"
      },
      "source": [
        "train_df['product_title_tokens'] = train_df['product_title'].progress_apply(lambda text: tokenize(text, MAX_TITLE_LENGTH))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 74067/74067 [00:36<00:00, 2024.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWEyqUS_JITR",
        "outputId": "fc63629a-7944-4600-a109-cb9b3ef11b35"
      },
      "source": [
        "train_df['search_term_tokens'] = train_df['search_term'].progress_apply(lambda text: tokenize(text, MAX_SEARCH_TERM_LENGTH))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 74067/74067 [00:17<00:00, 4151.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlqKW3Pqjosz",
        "outputId": "499147c6-9d7b-4c84-a478-90efe9f609a3"
      },
      "source": [
        "\n",
        "test_df['product_title_tokens'] = test_df['product_title'].progress_apply(lambda text: tokenize(text, MAX_TITLE_LENGTH))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 166693/166693 [01:24<00:00, 1975.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGbOT4XBjxm7",
        "outputId": "824e2e6f-930b-48bb-f251-3d469ec9cf19"
      },
      "source": [
        "test_df['search_term_tokens'] = test_df['search_term'].progress_apply(lambda text: tokenize(text, MAX_SEARCH_TERM_LENGTH))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 166693/166693 [00:38<00:00, 4276.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3gp5t6lL4Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7f5b20-6700-49ed-8053-cd327c088537"
      },
      "source": [
        "pd.set_option(\"max_colwidth\", -1)\n",
        "\n",
        "original_train_df_length = len(train_df)\n",
        "train_df = train_df[train_df['search_term_tokens'].notnull()]\n",
        "len(train_df)/original_train_df_length"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "f3eVXii3JfNI",
        "outputId": "9cb2d019-0a6b-46c6-c54f-d5ddf475787c"
      },
      "source": [
        "train_df.sample(3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7715</th>\n",
              "      <td>24056</td>\n",
              "      <td>104770</td>\n",
              "      <td>Slant/Fin Fine/Line 30 8 ft. Fully Assembled Enclosure and Element Hydronic Baseboard</td>\n",
              "      <td>furnace for baseboard heating</td>\n",
              "      <td>1.00</td>\n",
              "      <td>[101, 27474, 1013, 10346, 2986, 1013, 2240, 2382, 1022, 3027, 1012, 3929, 9240, 17539, 102]</td>\n",
              "      <td>[101, 17533, 2005, 2918, 102]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2539</th>\n",
              "      <td>7801</td>\n",
              "      <td>101314</td>\n",
              "      <td>House of Fara 3/4 in. x 3 in. x 7 ft. Oak Door Trim Casing Set</td>\n",
              "      <td>door trim</td>\n",
              "      <td>2.33</td>\n",
              "      <td>[101, 2160, 1997, 2521, 2050, 1017, 1013, 1018, 1999, 1012, 1060, 1017, 1999, 1012, 102]</td>\n",
              "      <td>[101, 2341, 12241, 102, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41219</th>\n",
              "      <td>125574</td>\n",
              "      <td>143218</td>\n",
              "      <td>Sumner Street Home Hardware Elon 13/16 in. Satin Nickel Pull</td>\n",
              "      <td>satin nickel pull</td>\n",
              "      <td>3.00</td>\n",
              "      <td>[101, 23922, 2395, 2188, 8051, 3449, 2239, 2410, 1013, 2385, 1999, 1012, 19412, 15519, 102]</td>\n",
              "      <td>[101, 19412, 15519, 4139, 102]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...              search_term_tokens\n",
              "7715   24056   ...  [101, 17533, 2005, 2918, 102] \n",
              "2539   7801    ...  [101, 2341, 12241, 102, 0]    \n",
              "41219  125574  ...  [101, 19412, 15519, 4139, 102]\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avWAdjfoKyoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde7d40d-2fec-4b78-f525-fd93cad92c04"
      },
      "source": [
        "\n",
        "relevance_values = pd.unique(train_df['relevance']).tolist()\n",
        "\n",
        "relevance_map = {relevance: index for (index, relevance) in enumerate(relevance_values)}\n",
        "num_of_classes = len(relevance_map)\n",
        "relevance_map, num_of_classes"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({1.0: 5,\n",
              "  1.25: 8,\n",
              "  1.33: 7,\n",
              "  1.5: 11,\n",
              "  1.67: 6,\n",
              "  1.75: 10,\n",
              "  2.0: 4,\n",
              "  2.25: 12,\n",
              "  2.33: 2,\n",
              "  2.5: 1,\n",
              "  2.67: 3,\n",
              "  2.75: 9,\n",
              "  3.0: 0},\n",
              " 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoNQJXA_NcFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27662e0d-c88d-4095-b01e-f0e627c68947"
      },
      "source": [
        "cls_to_score = {cls: score for (score, cls) in relevance_map.items()}\n",
        "cls_to_score\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 3.0,\n",
              " 1: 2.5,\n",
              " 2: 2.33,\n",
              " 3: 2.67,\n",
              " 4: 2.0,\n",
              " 5: 1.0,\n",
              " 6: 1.67,\n",
              " 7: 1.33,\n",
              " 8: 1.25,\n",
              " 9: 2.75,\n",
              " 10: 1.75,\n",
              " 11: 1.5,\n",
              " 12: 2.25}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyjfyQmxMA28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fd9383-f4f8-4a34-ef8e-963fba595624"
      },
      "source": [
        "\n",
        "train_df['relevance_class'] = train_df['relevance'].apply(lambda relevance: relevance_map[relevance])\n",
        "pd.unique(train_df['relevance_class'])\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0DjFymeMqeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "83f34eac-4d6e-49f6-eda0-358808c1d770"
      },
      "source": [
        "ax = sns.countplot(x=\"relevance_class\", data=train_df)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MnkT1xzONVQ",
        "outputId": "6487e234-853b-4255-99de-9bd2b9daebf8"
      },
      "source": [
        "num_of_classes = len(pd.unique(train_df['relevance_class']))\n",
        "num_of_classes"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYRLs4MfNRpz"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlitDkeYNk0u"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_abuT7Gj3Ag"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV7N4GDYNt70"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-RIhiikNx0N"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC-_3NcFN6vt"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBWR3ogxzlgr"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuiD695l1sa"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz-SXcFvCGkw"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3w-Ti9Ll4ty"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkY6UFlomBmQ"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIrQMC_njbh3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J08IiqM0Yoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98ea219-03f9-4b55-b4f2-f42241095128"
      },
      "source": [
        "1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysvXuI-DaYNR"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhr-sK-Ja4hS"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlXHvpSaxhcv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw3XOMq7ceR4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HGajw9zcWWT"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccgT0RxIx9xg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UtpFLaO0eGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cC_PmSZxzpX"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGydTxu0O58b"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdCgrrWaPKyy"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "935RIRNYPVmH"
      },
      "source": [
        "test_df['relevance_class'] = -1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "PhuWDnLF44ly",
        "outputId": "b3282a02-e72c-4ce7-b6dc-c3272e20bd67"
      },
      "source": [
        "train_df.sample(1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16245</th>\n",
              "      <td>50141</td>\n",
              "      <td>112776</td>\n",
              "      <td>Moto Shade 10 ft. x 20 ft. Multi-Purpose Canopy</td>\n",
              "      <td>car canopy</td>\n",
              "      <td>2.67</td>\n",
              "      <td>[101, 9587, 3406, 8703, 2184, 3027, 1012, 1060, 2322, 3027, 1012, 4800, 1011, 3800, 102]</td>\n",
              "      <td>[101, 2482, 14582, 102, 0]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  product_uid  ...          search_term_tokens relevance_class\n",
              "16245  50141  112776       ...  [101, 2482, 14582, 102, 0]  3             \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ITAnaPU7P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8fGj-0COjWj"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(int(time.time()))\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "from torch import nn, utils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable \n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self._df = df\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self._df.iloc[idx]\n",
        "\n",
        "        search_term = np.array(row['search_term_tokens'])\n",
        "        product_title = np.array(row['product_title_tokens'])\n",
        "\n",
        "   \n",
        "\n",
        "        return row['id'], search_term, product_title, row['relevance_class']\n",
        "    \n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "NRSLuzN1kqe7",
        "outputId": "b9aef73b-6460-4210-97f6-be26c727afde"
      },
      "source": [
        "train_df.sample(1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37754</th>\n",
              "      <td>115393</td>\n",
              "      <td>138330</td>\n",
              "      <td>Oakland Living Mississippi Patio Service Cart</td>\n",
              "      <td>service cart</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[101, 9182, 2542, 5900, 19404, 2326, 11122, 102, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[101, 2326, 11122, 102, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ...          search_term_tokens relevance_class\n",
              "37754  115393  138330       ...  [101, 2326, 11122, 102, 0]  0             \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTudx3_9QEOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62da0cc-6871-499c-f947-442314d3729e"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_data_df = train_df[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class', 'relevance']]\n",
        "data_loader = DatasetLoader(train_data_df)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(data_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "test_df_fixed = test_df[(test_df['search_term_tokens'].map(len) > 0) & (test_df['product_title_tokens'].map(len) > 0)]\n",
        "\n",
        "\n",
        "\n",
        "test_loader = DatasetLoader(test_df_fixed[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class']])\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=False, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "len(data_loader), len(test_loader)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74067, 166693)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "hYKG8QQEAXLS",
        "outputId": "d1f71c8a-7142-47a2-a9e4-c90a5a4e8329"
      },
      "source": [
        "train_data_df.sample(1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39466</th>\n",
              "      <td>120409</td>\n",
              "      <td>[101, 20868, 12173, 2937, 2102, 4293, 3027, 1012, 4658, 2317, 2419, 8164, 2422, 8934, 102]</td>\n",
              "      <td>[101, 4029, 3027, 2419, 102]</td>\n",
              "      <td>2</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... relevance\n",
              "39466  120409  ...  2.33    \n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ti4DjnB3AC2K",
        "outputId": "7dc13d34-2646-42f2-c0ef-871aba6f5cbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>my_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35646</th>\n",
              "      <td>52729</td>\n",
              "      <td>113622</td>\n",
              "      <td>AT&amp;amp;T Trimline Telephone With Memory - Black</td>\n",
              "      <td>at</td>\n",
              "      <td>[amp, &lt;word&gt;, telephon, memori, black]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  product_uid  ... search_term_tokens my_relevance\n",
              "35646  52729  113622       ...  []                 1          \n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg9ZjtvyQYYj"
      },
      "source": [
        "for ids, search_term, product_title, target_relevance_score in test_data_loader:\n",
        "  break"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAb7Xrshd-Ap"
      },
      "source": [
        ""
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaU8p0SBalql"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wcUGHjMcBXu"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PREwU_6bclh"
      },
      "source": [
        "for ids, search_term, product_title, target_relevance_score in train_data_loader:\n",
        "  break\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv4iT_xlBNeY"
      },
      "source": [
        "# from transformers import BertConfig\n",
        "\n",
        "# config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "#                                     output_hidden_states=True)\n",
        "\n",
        "# bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                          config=config)\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDYpQzBNRhe3",
        "outputId": "2d54efad-3dd8-4367-ba4f-655f8436b92f"
      },
      "source": [
        "# bb = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_of_labels = 10)\n",
        "# tt = torch.from_numpy(np.array(tokenize(\"he weny home for dinner\", 10)))\n",
        "\n",
        "# dd = tokenizer.encode_plus(\n",
        "#             text,\n",
        "#             max_length = max_length, \n",
        "#             padding = 'max_length',\n",
        "#             truncation = True, \n",
        "#             return_attention_mask = True, \n",
        "#             add_special_tokens = True, \n",
        "#             )\n",
        "\n",
        "# x1 = torch.from_numpy(np.ndarray([]]))\n",
        "# x2 = torch.from_numpy(np.array([dd['attention_mask']]))\n",
        "\n",
        "\n",
        "# torch.tensor(product_title)\n",
        "i1 = torch.tensor([[7,8,9],[10,11,12]])\n",
        "bert_model(i1)['hidden_states'][-1][:, -1,:].shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnTv4wTQRn--"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "class RelevanceModel(nn.Module):\n",
        "\n",
        "  def __init__(self, num_of_classes):\n",
        "    super(RelevanceModel, self).__init__()\n",
        "    config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "                                    output_hidden_states=True)\n",
        "\n",
        "    self.bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "\n",
        "    for param in self.bert_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    self.fc = nn.Linear(768 * 2, num_of_classes)\n",
        "\n",
        "  def  forward(self, queries, titles):\n",
        "    encoded_queries = self.bert_model(queries)['hidden_states'][-1][:, 0,:]\n",
        "    #last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "    encoded_titles = self.bert_model(titles)['hidden_states'][-1][:, 0,:]\n",
        "\n",
        "    out = torch.cat((encoded_queries, encoded_titles), 1)\n",
        "\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out \n",
        "\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.uniform_(self.fc.weight)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VMlZG21ZCK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4559ba7-c22e-4aeb-d0b1-039442bf9236"
      },
      "source": [
        "\n",
        "# # for x in model.parameters():\n",
        "# #   if not x.is_cuda:\n",
        "# #     print(x) \n",
        "\n",
        "# # e1 = EncoderModel(len(vocab)).to(device)\n",
        "# # r = e1(product_title.to(device), product_title_length)\n",
        "# output.shape, product_title_length\n",
        "# #output = r \n",
        "\n",
        "# #8\n",
        "# #out_forward = output[range(len(output)), lengths - 1, :self.embedding_dim ]\n",
        "\n",
        "# # output[range(len(output)), product_title_length - 1, :300][0]\n",
        "# product_title_length\n",
        "#output[0][14], product_title_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14, 12, 10, 15,  8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpN5VHYENQJ",
        "outputId": "5fdb6a9e-27b4-4018-d550-1631392db324"
      },
      "source": [
        "# output[0][13][300:]\n",
        "# output[:, 0, 300 :].shape, output[:, 0,]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 300]), torch.Size([5, 15, 600]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFR-SouFR5PB"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# query_encoder = EncoderModel(len(vocab))\n",
        "# title_encoder = EncoderModel(len(vocab))\n",
        "\n",
        "# query_encoder.reset_parameters()\n",
        "# title_encoder.reset_parameters()\n",
        "\n",
        "# #search_term, search_term_length, product_title, product_title_length\n",
        "# query_encoded = query_encoder(search_term, search_term_length)\n",
        "# title_encoded = query_encoder(product_title, product_title_length)\n",
        "# torch.cat((query_encoded, title_encoded), 1)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWnKAQe_WQyF",
        "outputId": "dfae549c-9aa3-45c9-b1a4-6af73790b088"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEpPTJGLoi1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbaa3c02-8434-4e00-fb31-0cf81988a459"
      },
      "source": [
        "counts = train_df.groupby(\"relevance_class\").size().reset_index()\n",
        "#total = np.sum(counts[0].tolist())\n",
        "\n",
        "# [(row['relevance_class'],  row[0]/total) for (_, row) in counts[['relevance_class', 0]].iterrows()]\n",
        "\n",
        "total = 0.0\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  total += row[0]\n",
        "total \n",
        "weights = []\n",
        "print(total)\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  #print(row[0])\n",
        "  cls = row['relevance_class']\n",
        "  # print((cls, row[0]))\n",
        "  sampeples_weight = (row[0] / total)\n",
        "  required_weight = 1.0/len(counts)\n",
        "\n",
        "  # print('-----')\n",
        "  # print(sampeples_weight)\n",
        "  # print(required_weight)\n",
        "  x = required_weight/sampeples_weight\n",
        "  # print(x)\n",
        "\n",
        "  weight_for_class_a = (1 / row[0]) * total/len(counts)\n",
        "  \n",
        "\n",
        "   \n",
        "  # weight = x * sampeples_weight\n",
        "  # print(weight)\n",
        "  # print('-------')\n",
        "\n",
        "  weights.append((cls, x))\n",
        "\n",
        "\n",
        "\n",
        "weights = sorted(weights, key = lambda x: x[0])\n",
        "weights = [w[1] for w in weights]\n",
        "weights\n",
        "\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74067.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2979064856711916,\n",
              " 299.8663967611337,\n",
              " 0.35476099243222536,\n",
              " 0.37478368230900794,\n",
              " 0.4857170962030298,\n",
              " 2.7066325598392105,\n",
              " 0.8403335602450647,\n",
              " 1.8953631199140182,\n",
              " 1424.3653846153848,\n",
              " 517.951048951049,\n",
              " 633.0512820512821,\n",
              " 1139.4923076923078,\n",
              " 517.951048951049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu2VvCcmyVy1",
        "outputId": "6a47000e-e476-4ffd-f824-46b399437436"
      },
      "source": [
        "weights"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2979064856711916,\n",
              " 299.8663967611337,\n",
              " 0.35476099243222536,\n",
              " 0.37478368230900794,\n",
              " 0.4857170962030298,\n",
              " 2.7066325598392105,\n",
              " 0.8403335602450647,\n",
              " 1.8953631199140182,\n",
              " 1424.3653846153848,\n",
              " 517.951048951049,\n",
              " 633.0512820512821,\n",
              " 1139.4923076923078,\n",
              " 517.951048951049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEK66lCTIt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4990da-34d3-49ad-82ea-de0dab3fe29b"
      },
      "source": [
        "model = RelevanceModel(num_of_classes)\n",
        "model.reset_parameters()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "class_weights=torch.tensor(weights,dtype=torch.float)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight = class_weights, reduction='sum').to(device)\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJiU_nc8WP8l",
        "outputId": "7037bf4d-823f-40ae-f8c6-ce81a8a99388"
      },
      "source": [
        "class_weights[2].numpy(), weights[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(0.35470936, dtype=float32), 0.3547093708384031)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knnaKV2bWAA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba92c33-f6fc-4da1-ef76-e787ca259a58"
      },
      "source": [
        "\n",
        "model.train()\n",
        "\n",
        "for epoc in range(1000):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  counter = 0.0\n",
        "\n",
        "  for ids, search_term, product_title, target_relevance_score  in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    target_relevance_score = Variable(target_relevance_score).long().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    scores = model(search_term, product_title)\n",
        "    loss = criterion(scores, target_relevance_score)\n",
        "\n",
        "    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    counter += search_term.shape[0]\n",
        "  #   break\n",
        "  \n",
        "  # break\n",
        "  \n",
        "  print('epoc {} loss {} counter {}'.format(epoc, running_loss/counter, counter))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoc 0 loss 5.904211499163197 counter 74067.0\n",
            "epoc 1 loss 4.721187067969865 counter 74067.0\n",
            "epoc 2 loss 4.33463868285345 counter 74067.0\n",
            "epoc 3 loss 3.456758809993866 counter 74067.0\n",
            "epoc 4 loss 3.2386129801780044 counter 74067.0\n",
            "epoc 5 loss 3.0206837696153364 counter 74067.0\n",
            "epoc 6 loss 2.9152826146479325 counter 74067.0\n",
            "epoc 7 loss 2.78654564420181 counter 74067.0\n",
            "epoc 8 loss 2.383195352694024 counter 74067.0\n",
            "epoc 9 loss 2.420729046698926 counter 74067.0\n",
            "epoc 10 loss 2.1488469628688867 counter 74067.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j23Rz5eLleqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ad98cc-2bb6-4239-c34f-33999dd2e8d4"
      },
      "source": [
        "# mse_loss(scores.view(1, -1), target_relevance_score.view(1, -1))\n",
        "# counter\n",
        "torch.argmax(scores, dim=1), target_relevance_score"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  0,  4,  4,  6,  0,  0,  6,  4,  0,  7,  1,  4,  4,  7,  5,  6,  6,\n",
              "          1,  4,  6,  0,  6,  4,  4, 10,  4,  4,  6, 10,  6,  6,  0,  0,  0,  4,\n",
              "          4,  0,  6,  0,  6, 10,  0,  1, 10,  0,  4,  7,  0,  5,  0,  5,  4, 10,\n",
              "         10,  4,  4,  0,  7,  7,  6,  4,  6,  0], device='cuda:0'),\n",
              " tensor([2, 0, 2, 0, 0, 6, 0, 6, 2, 6, 0, 4, 7, 2, 4, 2, 2, 6, 4, 4, 5, 6, 4, 3,\n",
              "         6, 0, 0, 2, 0, 0, 6, 3, 2, 4, 3, 0, 0, 4, 0, 0, 4, 4, 4, 0, 0, 0, 2, 4,\n",
              "         0, 3, 4, 5, 3, 3, 0, 3, 4, 0, 3, 3, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B5hKqKGe-y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40ac4d6-11ad-4d5b-c20a-b111868f38a1"
      },
      "source": [
        "np.sum(torch.argmax(scores, dim=1).detach().cpu().numpy() == target_relevance_score.numpy())"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTBEJ3CasIks",
        "outputId": "2417d084-a94d-400a-9c14-5b7addf87a4e"
      },
      "source": [
        "r1, scores.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, torch.Size([64, 13]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgvd78qCkW8m"
      },
      "source": [
        "\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, product_title, target_relevance_score in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    \n",
        "\n",
        "    scores = model(search_term, product_title)\n",
        "\n",
        "    test_scores.extend(scores.detach().cpu().numpy().flatten().tolist())\n",
        "    test_ids.extend(ids.numpy().tolist())\n",
        "    tt.extend(target_relevance_score.numpy().tolist())\n",
        "\n",
        "    break\n",
        "  \n",
        "\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdxRw_b_LTq"
      },
      "source": [
        "for _ in test_data_loader:\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "iYqvaAVNk6pY",
        "outputId": "aa4c6775-8edf-4135-a1cb-6d285b45b7e9"
      },
      "source": [
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "test_data = []\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, product_title, target_relevance_score in test_data_loader:\n",
        "     \n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    \n",
        "\n",
        "    scores = model(search_term, product_title)\n",
        "\n",
        "    vals = torch.argmax(scores, dim=1).flatten().detach().cpu().numpy().tolist()\n",
        "    ids = ids.numpy().tolist()\n",
        "\n",
        "    test_data.extend(zip(ids, vals))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  "
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-cfd8370ac520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_relevance_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msearch_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-HHAoXDZCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce45f3e5-ac44-4e64-8bec-8e2353ce7fe0"
      },
      "source": [
        "# 166693, len(test_data), len(test_df)\n",
        "all_ids = {x for (x, _) in test_data}\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "  if row['id'] not in all_ids:\n",
        "    test_data.append((row['id'], 1))\n",
        "    \n",
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCkYUGAMgvqF"
      },
      "source": [
        "pd.DataFrame([(id, cls_to_score[cls]) for (id, cls) in test_data], columns = [\"id\", \"relevance\"]).to_csv(\"test_res.csv\", index=  False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6XfNPdDKx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18c4fd2a-77b5-40dc-b802-71af0983f330"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('test_res.csv') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f1fa6b5d-807b-4df1-b82c-3b19b4724bfd\", \"test_res.csv\", 1850918)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrqzbWUODp-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "3afbb0ac-512f-4b76-e5a1-a8d59f96d5fb"
      },
      "source": [
        "test_df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>my_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107023</th>\n",
              "      <td>159578</td>\n",
              "      <td>161578</td>\n",
              "      <td>Speedi-Products 7 in. 24-Gauge Single Wall Stove Pipe 90 Degree Adjustable Elbow in Black Matte</td>\n",
              "      <td>singel wall stove pipe</td>\n",
              "      <td>[speedi, product, #, ##, gaug, singl, wall, stove, pipe, ##, degre, adjust, elbow, black, matt]</td>\n",
              "      <td>[singel, wall, stove, pipe]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  product_uid  ...           search_term_tokens my_relevance\n",
              "107023  159578  161578       ...  [singel, wall, stove, pipe]  1          \n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    }
  ]
}