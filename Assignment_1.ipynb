{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabibu/nlp/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce5pQK3bFn_"
      },
      "source": [
        "# Assignment 1\n",
        "In this assignment you will be creating tools for learning and testing language models.\n",
        "The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwG8v-Ll49KM"
      },
      "source": [
        "*As a preparation for this task, download the data files from the course git repository.\n",
        "\n",
        "The relevant files are under **lm-languages-data-new**:\n",
        "\n",
        "\n",
        "*   en.csv (or the equivalent JSON file)\n",
        "*   es.csv (or the equivalent JSON file)\n",
        "*   fr.csv (or the equivalent JSON file)\n",
        "*   in.csv (or the equivalent JSON file)\n",
        "*   it.csv (or the equivalent JSON file)\n",
        "*   nl.csv (or the equivalent JSON file)\n",
        "*   pt.csv (or the equivalent JSON file)\n",
        "*   tl.csv (or the equivalent JSON file)\n",
        "*   test.csv (or the equivalent JSON file)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xC-87z2GWMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "631a163e-f03c-440a-8d70-baa238214e3c"
      },
      "source": [
        "!git clone https://github.com/kfirbar/nlp-course.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-course'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 53 (delta 23), reused 32 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOVb4IhsqimJ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Important note: please use only the files under lm-languages-data-new and NOT under lm-languages-data**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYdhPfbAGkip",
        "outputId": "1f3b1e38-530f-428e-d3c2-c0b2868c3f77"
      },
      "source": [
        "\n",
        "!ls nlp-course/lm-languages-data-new\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en.csv\t es.json  in.csv   it.json  pt.csv    test.json   tl.csv\n",
            "en.json  fr.csv   in.json  nl.csv   pt.json   tests.csv   tl.json\n",
            "es.csv\t fr.json  it.csv   nl.json  test.csv  tests.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ashyu_mT28o6"
      },
      "source": [
        "**Part 1**\n",
        "\n",
        "Write a function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. **Our token definition is a single UTF-8 encoded character**. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCfzsITW8Yaj"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "pd.set_option(\"max_colwidth\", 140)\n",
        "import json \n",
        "\n",
        "folder = 'nlp-course/lm-languages-data-new'\n",
        "\n",
        "def read_tweets(file_path):\n",
        "  file_suffix = pathlib.Path(file_path).suffix\n",
        "  if file_suffix == '.json':\n",
        "    with open(file_path) as f:\n",
        "      data = json.load(f)\n",
        "      return [tweet.lower() for tweet in data['tweet_text'].values()]\n",
        "      \n",
        "        \n",
        "  elif file_suffix == '.csv':\n",
        "    df = pd.read_csv(file_path, header=0)\n",
        "    return [tweet.lower() for tweet in df['tweet_text'].tolist()]\n",
        "\n",
        "def preprocess():\n",
        "\n",
        "  vocab = set()\n",
        "  for file_name in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, file_name)\n",
        "    tweets = read_tweets(file_path)\n",
        "\n",
        "    vocab.update({word for tweet in tweets for word in tweet.lower()})\n",
        "\n",
        "  return vocab\n",
        "        "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb2PGj0Yc2TY"
      },
      "source": [
        "**Part 2**\n",
        "\n",
        "Write a function lm that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant n-1 sequences, and the values are dictionaries with the n_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
        "\n",
        "{\n",
        "  \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25},\n",
        "  \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1}\n",
        "}\n",
        "\n",
        "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
        "\n",
        "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMC_u8eQbVvZ"
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np \n",
        "\n",
        "start = '<S>'\n",
        "end = '<E>'\n",
        "\n",
        "def build_probs_model(n, vocabulary, tweets, add_one):\n",
        "\n",
        "    counts = {}\n",
        "\n",
        "    num_of_tokens = 0.0\n",
        "    for tweet in tweets:\n",
        "      \n",
        "        characters = list(tweet)\n",
        "\n",
        "        tokens = [start] + characters + [end] if n > 1 else characters\n",
        "\n",
        "        num_of_tokens += len(tokens)\n",
        "\n",
        "        if len(tokens) < n:\n",
        "            continue\n",
        "\n",
        "        for i in range(n, len(tokens)):\n",
        "            current_tokens = tokens[i - n: i]\n",
        "\n",
        "            character = current_tokens[-1]\n",
        "\n",
        "            if n > 1:\n",
        "                n_key = ''.join(current_tokens[0: -1])\n",
        "\n",
        "                if n_key not in counts:\n",
        "                    counts[n_key] = {}\n",
        "\n",
        "                if character not in counts[n_key]:\n",
        "                    counts[n_key][character] = 0.0\n",
        "\n",
        "                counts[n_key][character] += 1.0\n",
        "            else:\n",
        "                if character not in counts:\n",
        "                    counts[character] = 0.0\n",
        "\n",
        "                counts[character] += 1\n",
        "\n",
        "\n",
        "    if n == 1:\n",
        "        \n",
        "        if add_one:\n",
        "            model = defaultdict(lambda : 1.0/len(vocabulary), {word: (count + 1.0) / (num_of_tokens + len(vocabulary)) for (word, count) in counts.items()})\n",
        "        else:\n",
        "          model = defaultdict(lambda : 0.0, {word: count / num_of_tokens for (word, count) in counts.items()})\n",
        "    else:\n",
        "            \n",
        "        default_model = defaultdict(lambda :0.0) if not add_one else defaultdict(lambda :1.0/len(vocabulary))\n",
        "        model = defaultdict(lambda : default_model)\n",
        "        for gram, next_character_counts in counts.items():\n",
        "            n = np.sum(list(next_character_counts.values()))\n",
        "\n",
        "            if add_one:\n",
        "              model[gram] = defaultdict(lambda: 1.0/(n + len(vocabulary)), {word: (count +1.0) / (n + len(vocabulary)) for (word, count) in next_character_counts.items()})\n",
        "            else:\n",
        "              model[gram] = defaultdict(lambda : 0.0, {word: count / n for (word, count) in next_character_counts.items()})\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def lm(n, vocabulary, data_file_path, add_one):\n",
        "  # n - the n-gram to use (e.g., 1 - unigram, 2 - bigram, etc.)\n",
        "  # vocabulary - the vocabulary list (which you should use for calculating add_one smoothing)\n",
        "  # data_file_path - the data_file from which we record probabilities for our model\n",
        "  # add_one - True/False (use add_one smoothing or not)\n",
        "\n",
        "  # TODO\n",
        "  tweets = read_tweets(data_file_path)\n",
        "  return build_probs_model(n, vocabulary, tweets, add_one)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8TchtI22I3"
      },
      "source": [
        "**Part 3**\n",
        "\n",
        "Write a function *eval* that returns the perplexity of a model (dictionary) running over a given data file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0kkMn328-lJ"
      },
      "source": [
        "unk_prob = 0.000000001\n",
        "def eval(n, model, data_file):\n",
        "    # n - the n-gram that you used to build your model (must be the same number)\n",
        "    # model - the dictionary (model) to use for calculating perplexity\n",
        "    # data_file - the tweets file that you wish to claculate a perplexity score for\n",
        "\n",
        "    # TODO\n",
        "    tweets = read_tweets(data_file)\n",
        "\n",
        "    tweets_perplexity = []\n",
        "    for tweet in tweets:\n",
        "        probs_n = 0.0\n",
        "        entropy_sum = 0.0\n",
        "        if n == 1:\n",
        "            for token in tweet:\n",
        "                prob = model[token]\n",
        "                \n",
        "                entropy_sum += unk_prob * np.log2(unk_prob) if prob == 0 else prob * np.log2(prob)\n",
        "                probs_n += 1\n",
        "        else:\n",
        "            for index in range(0, len(tweet)):\n",
        "                to_index = index + n\n",
        "                tokens = tweet[index: to_index]\n",
        "                if len(tokens) < n:\n",
        "                    break\n",
        "                prev = tokens[0: -1]\n",
        "                to_token = tokens[-1]\n",
        "                prob = model[prev][to_token]\n",
        "                entropy_sum += unk_prob * np.log2(unk_prob) if prob == 0 else prob * np.log2(prob)\n",
        "               \n",
        "                probs_n += 1\n",
        "\n",
        "        entropy = (-1 / probs_n) * entropy_sum\n",
        "        tweet_perplexity = np.power(2, entropy)\n",
        "        tweets_perplexity.append(tweet_perplexity)\n",
        "\n",
        "    return np.mean(tweets_perplexity)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enGmtLE3921p"
      },
      "source": [
        "**Part 4**\n",
        "\n",
        "Write a function *match* that creates a model for every relevant language, using a specific value of *n* and *add_one*. Then, calculate the perplexity of all possible pairs (e.g., en model applied on the data files en ,es, fr, in, it, nl, pt, tl; es model applied on the data files en, es...). This function should return a pandas DataFrame with columns [en ,es, fr, in, it, nl, pt, tl] and every row should be labeled with one of the languages. Then, the values are the relevant perplexity values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caAxLE9s_fvn"
      },
      "source": [
        "def match(n, add_one):\n",
        "  # n - the n-gram to use for creating n-gram models\n",
        "  # add_one - use add_one smoothing or not\n",
        "\n",
        "  vocabulary = preprocess()\n",
        "\n",
        "  language_to_model = {}\n",
        "  language_to_data_file = {}\n",
        "  for file_name in os.listdir(folder):\n",
        "    language = os.path.splitext(file_name)[0]\n",
        "    if language in language_to_model or 'test' in language:\n",
        "      continue\n",
        "\n",
        "    file_path = os.path.join(folder, file_name)\n",
        "    language_to_data_file[language] = file_path\n",
        "\n",
        "    model = lm(n, vocabulary, file_path, add_one)\n",
        "    language_to_model[language] = model\n",
        "\n",
        "  languages = sorted(list(language_to_model.keys()))\n",
        "\n",
        "  rows = []\n",
        "  for index, language1 in enumerate(languages):\n",
        "    current_res = []\n",
        "    for index, language2 in enumerate(languages):\n",
        "      perplexity = eval(n, language_to_model[language1], language_to_data_file[language2])\n",
        "      current_res.append(perplexity)\n",
        "    \n",
        "    current_res.append(n)\n",
        "    current_res.append(add_one)\n",
        "    \n",
        "    rows.append(current_res)\n",
        "  \n",
        "  return pd.DataFrame(rows, columns =languages + [\"n\", \"add_one\"], index=languages)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waGMwA8H_n17"
      },
      "source": [
        "**Part 5**\n",
        "\n",
        "Run match with *n* values 1-4, once with add_one and once without, and print the 8 tables to this notebook, one after another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk32naXyAMdl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "723c76d0-e2de-4acd-f4d5-58f74b7d4b5b"
      },
      "source": [
        "frames = []\n",
        "for n in range(1,5):\n",
        "  for add_one in [True, False]:\n",
        "    frames.append(match(n, add_one))\n",
        "    \n",
        "all_frames = pd.concat(frames)\n",
        "all_frames"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>es</th>\n",
              "      <th>fr</th>\n",
              "      <th>in</th>\n",
              "      <th>it</th>\n",
              "      <th>nl</th>\n",
              "      <th>pt</th>\n",
              "      <th>tl</th>\n",
              "      <th>n</th>\n",
              "      <th>add_one</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>1.151613</td>\n",
              "      <td>1.153592</td>\n",
              "      <td>1.150387</td>\n",
              "      <td>1.144434</td>\n",
              "      <td>1.150451</td>\n",
              "      <td>1.147355</td>\n",
              "      <td>1.152866</td>\n",
              "      <td>1.146226</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>es</th>\n",
              "      <td>1.150314</td>\n",
              "      <td>1.159726</td>\n",
              "      <td>1.153757</td>\n",
              "      <td>1.146553</td>\n",
              "      <td>1.154292</td>\n",
              "      <td>1.147915</td>\n",
              "      <td>1.158623</td>\n",
              "      <td>1.148209</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr</th>\n",
              "      <td>1.148823</td>\n",
              "      <td>1.155337</td>\n",
              "      <td>1.153364</td>\n",
              "      <td>1.142092</td>\n",
              "      <td>1.150591</td>\n",
              "      <td>1.146594</td>\n",
              "      <td>1.154142</td>\n",
              "      <td>1.141728</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>1.144004</td>\n",
              "      <td>1.149176</td>\n",
              "      <td>1.143402</td>\n",
              "      <td>1.153630</td>\n",
              "      <td>1.146235</td>\n",
              "      <td>1.141741</td>\n",
              "      <td>1.149750</td>\n",
              "      <td>1.154152</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>it</th>\n",
              "      <td>1.149675</td>\n",
              "      <td>1.156892</td>\n",
              "      <td>1.151586</td>\n",
              "      <td>1.146016</td>\n",
              "      <td>1.155480</td>\n",
              "      <td>1.146792</td>\n",
              "      <td>1.156340</td>\n",
              "      <td>1.147953</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>1.162569</td>\n",
              "      <td>1.141125</td>\n",
              "      <td>1.132623</td>\n",
              "      <td>1.238862</td>\n",
              "      <td>1.145076</td>\n",
              "      <td>1.126326</td>\n",
              "      <td>1.136304</td>\n",
              "      <td>1.168208</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>it</th>\n",
              "      <td>1.149051</td>\n",
              "      <td>1.165271</td>\n",
              "      <td>1.140862</td>\n",
              "      <td>1.114180</td>\n",
              "      <td>1.236818</td>\n",
              "      <td>1.113411</td>\n",
              "      <td>1.156911</td>\n",
              "      <td>1.136072</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nl</th>\n",
              "      <td>1.167539</td>\n",
              "      <td>1.139856</td>\n",
              "      <td>1.143432</td>\n",
              "      <td>1.126287</td>\n",
              "      <td>1.143758</td>\n",
              "      <td>1.233318</td>\n",
              "      <td>1.132736</td>\n",
              "      <td>1.141531</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pt</th>\n",
              "      <td>1.134598</td>\n",
              "      <td>1.168281</td>\n",
              "      <td>1.128880</td>\n",
              "      <td>1.105841</td>\n",
              "      <td>1.155399</td>\n",
              "      <td>1.103840</td>\n",
              "      <td>1.235598</td>\n",
              "      <td>1.130311</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tl</th>\n",
              "      <td>1.175613</td>\n",
              "      <td>1.150394</td>\n",
              "      <td>1.132174</td>\n",
              "      <td>1.148288</td>\n",
              "      <td>1.151992</td>\n",
              "      <td>1.123438</td>\n",
              "      <td>1.141774</td>\n",
              "      <td>1.228937</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          en        es        fr        in  ...        pt        tl  n  add_one\n",
              "en  1.151613  1.153592  1.150387  1.144434  ...  1.152866  1.146226  1     True\n",
              "es  1.150314  1.159726  1.153757  1.146553  ...  1.158623  1.148209  1     True\n",
              "fr  1.148823  1.155337  1.153364  1.142092  ...  1.154142  1.141728  1     True\n",
              "in  1.144004  1.149176  1.143402  1.153630  ...  1.149750  1.154152  1     True\n",
              "it  1.149675  1.156892  1.151586  1.146016  ...  1.156340  1.147953  1     True\n",
              "..       ...       ...       ...       ...  ...       ...       ... ..      ...\n",
              "in  1.162569  1.141125  1.132623  1.238862  ...  1.136304  1.168208  4    False\n",
              "it  1.149051  1.165271  1.140862  1.114180  ...  1.156911  1.136072  4    False\n",
              "nl  1.167539  1.139856  1.143432  1.126287  ...  1.132736  1.141531  4    False\n",
              "pt  1.134598  1.168281  1.128880  1.105841  ...  1.235598  1.130311  4    False\n",
              "tl  1.175613  1.150394  1.132174  1.148288  ...  1.141774  1.228937  4    False\n",
              "\n",
              "[64 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg4h5Cl0q2nR"
      },
      "source": [
        "**Part 6**\n",
        "\n",
        "Each line in the file test.csv contains a sentence and the language it belongs to. Write a function that uses your language models to classify the correct language of each sentence.\n",
        "\n",
        "Important note regarding the grading of this section: this is an open question, where a different solution will yield different accuracy scores. any solution that is not trivial (e.g. returning 'en' in all cases) will be excepted. We do reserve the right to give bonus points to exceptionally good/creative solutions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYyZ6Y_0VR_g"
      },
      "source": [
        "def build_languages_models(n, add_one):\n",
        "\n",
        "  vocabulary = preprocess()\n",
        "\n",
        "  language_to_model = {}\n",
        "  for file_name in os.listdir(folder):\n",
        "    language = os.path.splitext(file_name)[0]\n",
        "    if language in language_to_model or 'test' in language:\n",
        "      continue\n",
        "      \n",
        "    \n",
        "    file_path = os.path.join(folder, file_name)\n",
        "\n",
        "    model = lm(n, vocabulary, file_path, add_one)\n",
        "    language_to_model[language] = model\n",
        "  return language_to_model\n",
        "\n",
        "two_gram_language_to_model = build_languages_models(2, True)\n",
        "unigram_gram_language_to_model = build_languages_models(1, True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l0I_hA4VsIx"
      },
      "source": [
        "TEST_FILE = 'test.csv'\n",
        "test_df = pd.read_csv(os.path.join(folder, TEST_FILE))[['tweet_text', 'label']]\n",
        "test_df[\"tweet_text\"] = test_df[\"tweet_text\"].str.lower()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N5oy3fK5mLZ"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def clean_text(tweet):\n",
        "\n",
        "  if tweet.startswith('rt'):\n",
        "    tweet = tweet.replace('rt', '')\n",
        "\n",
        "  seen = False\n",
        "  \n",
        "  xx = ''\n",
        "  for x in tweet:\n",
        "    if seen:\n",
        "      if x == ' ':\n",
        "        seen = False\n",
        "      else:\n",
        "        continue\n",
        "    else:\n",
        "     \n",
        "      if x in ['😂', '😓', '👌🏽','🕋','💎','😌', '🆘', '🔴','#', '😍','🔥','💙','😻','💔', '🙌🏾','👙','☀️','🍾','🎈','%', '😈','💦','!', '🤘🏼',\n",
        "               '0','1','2','3','4','5','6','7','8','9', '💨', '🙋🏻', '❤', '😆', '😲', '🤦‍♀️']:\n",
        "        xx +=''\n",
        "        continue\n",
        "\n",
        "      if x == '@':\n",
        "        seen = True\n",
        "      else:\n",
        "        xx += x\n",
        "\n",
        "  g = re.findall(r'(https?://\\S+)', xx)\n",
        "\n",
        "  for x in g:\n",
        "    xx = xx.replace(x, '')\n",
        "  \n",
        "  xx = xx.replace(' ', ' ')\n",
        "  return xx.strip()\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R-H5_Hhulh_"
      },
      "source": [
        "\n",
        "test_df['clean_tweet_text'] = test_df['tweet_text'].apply(clean_text)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD6IRIQLrlZF"
      },
      "source": [
        "\n",
        "def classify_language(tweet, n):\n",
        "  \n",
        "  best_language_prob = float('-inf')\n",
        "  best_language = None\n",
        "\n",
        "  for language, model in two_gram_language_to_model.items():\n",
        "    if language in {'en', 'nl'}:\n",
        "      print('lan: {}'.format(language))\n",
        "    unigram_model = unigram_gram_language_to_model[language]\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    language_log_prob = 0.0\n",
        "    while index + n <= len(tweet):\n",
        "\n",
        "      if n == 1:\n",
        "        token = tweet[index: index + 1]\n",
        "        prob = model[token]\n",
        "        prob = prob if prob > 0 else 0.0000001\n",
        "        language_log_prob += np.log(prob)\n",
        "      else:\n",
        "        tokens = tweet[index: index + n]\n",
        "        prev = tokens[0:-1]\n",
        "        next = tokens[-1]\n",
        "\n",
        "        prob = model[prev][next]\n",
        "        if language in {'en', 'nl'}:\n",
        "          print('tokens {} prob {}'.format(tokens, prob))\n",
        "        prob = prob if prob > 0 else 0.0000001\n",
        "        uni_prob = unigram_model[next] if unigram_model[next] > 0 else 0.0000001\n",
        "        language_log_prob += np.log((0.8 * prob)+ (uni_prob * 0.2))\n",
        "      index += 1\n",
        "    \n",
        "   \n",
        "    if language_log_prob > best_language_prob:\n",
        "      best_language_prob = language_log_prob\n",
        "      best_language = language\n",
        "    \n",
        "\n",
        "  return best_language"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGOHsmCefTP6",
        "outputId": "fe655854-4f3e-478c-c799-7d7807240718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "\n",
        "correct_df = test_df[test_df['label'] == test_df['predicted_label']]\n",
        "\n",
        "\n",
        "\n",
        "correct_size_df = correct_df.groupby('label').size().reset_index()\n",
        "correct_size_df.sort_values(by= 0, ascending=False)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fr</td>\n",
              "      <td>925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en</td>\n",
              "      <td>901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>es</td>\n",
              "      <td>898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pt</td>\n",
              "      <td>893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in</td>\n",
              "      <td>870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it</td>\n",
              "      <td>865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>nl</td>\n",
              "      <td>852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tl</td>\n",
              "      <td>782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label    0\n",
              "2    fr  925\n",
              "0    en  901\n",
              "1    es  898\n",
              "6    pt  893\n",
              "3    in  870\n",
              "4    it  865\n",
              "5    nl  852\n",
              "7    tl  782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhxbgG5iblJn",
        "outputId": "6780bc0b-c0cd-4e27-f9a3-4a23ed405a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "missed_df = test_df[test_df['label'] != test_df['predicted_label']]\n",
        "\n",
        "missed_df['pair'] = missed_df.apply(lambda r: (r['predicted_label'], r['label']), axis=1)\n",
        "\n",
        "missed__size_df = missed_df.groupby('pair').size().reset_index()\n",
        "missed__size_df.sort_values(by= 0, ascending=False)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pair</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>(nl, tl)</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>(in, tl)</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(en, nl)</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(es, pt)</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>(tl, in)</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(en, tl)</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(es, it)</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(en, in)</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>(pt, es)</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>(tl, nl)</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>(it, es)</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>(nl, en)</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(fr, nl)</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(en, fr)</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>(tl, it)</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(en, it)</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(fr, en)</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>(nl, it)</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>(it, en)</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>(it, pt)</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(es, fr)</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(fr, pt)</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>(pt, it)</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(fr, it)</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>(nl, in)</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>(in, nl)</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(fr, es)</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>(in, en)</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>(it, in)</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>(in, it)</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(es, en)</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(en, es)</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(fr, in)</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>(it, fr)</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(in, pt)</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(es, nl)</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(in, es)</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>(tl, en)</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>(it, nl)</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(es, in)</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>(tl, es)</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>(tl, fr)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(es, tl)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>(pt, fr)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>(nl, fr)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>(it, tl)</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>(pt, in)</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>(nl, pt)</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(fr, tl)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>(pt, nl)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>(pt, en)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>(in, fr)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(en, pt)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>(tl, pt)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>(pt, tl)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>(nl, es)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        pair   0\n",
              "41  (nl, tl)  80\n",
              "27  (in, tl)  78\n",
              "4   (en, nl)  56\n",
              "12  (es, pt)  54\n",
              "52  (tl, in)  47\n",
              "6   (en, tl)  39\n",
              "10  (es, it)  35\n",
              "2   (en, in)  34\n",
              "43  (pt, es)  31\n",
              "54  (tl, nl)  31\n",
              "29  (it, es)  29\n",
              "35  (nl, en)  28\n",
              "18  (fr, nl)  26\n",
              "1   (en, fr)  25\n",
              "53  (tl, it)  23\n",
              "3   (en, it)  22\n",
              "14  (fr, en)  18\n",
              "39  (nl, it)  17\n",
              "28  (it, en)  16\n",
              "33  (it, pt)  16\n",
              "8   (es, fr)  15\n",
              "19  (fr, pt)  14\n",
              "46  (pt, it)  14\n",
              "17  (fr, it)  13\n",
              "38  (nl, in)  13\n",
              "25  (in, nl)  13\n",
              "15  (fr, es)  13\n",
              "21  (in, en)  12\n",
              "31  (it, in)  12\n",
              "24  (in, it)  11\n",
              "7   (es, en)  11\n",
              "0   (en, es)  10\n",
              "16  (fr, in)  10\n",
              "30  (it, fr)  10\n",
              "26  (in, pt)   9\n",
              "11  (es, nl)   9\n",
              "22  (in, es)   9\n",
              "49  (tl, en)   9\n",
              "32  (it, nl)   8\n",
              "9   (es, in)   8\n",
              "50  (tl, es)   8\n",
              "51  (tl, fr)   7\n",
              "13  (es, tl)   7\n",
              "44  (pt, fr)   7\n",
              "37  (nl, fr)   7\n",
              "34  (it, tl)   7\n",
              "45  (pt, in)   6\n",
              "40  (nl, pt)   6\n",
              "20  (fr, tl)   5\n",
              "47  (pt, nl)   5\n",
              "42  (pt, en)   4\n",
              "23  (in, fr)   4\n",
              "5   (en, pt)   4\n",
              "55  (tl, pt)   4\n",
              "48  (pt, tl)   2\n",
              "36  (nl, es)   2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUtxs1sybj4Z"
      },
      "source": [
        "test_df[\"predicted_label\"] = test_df[\"clean_tweet_text\"].apply(lambda t: classify_language(t, 2))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNwD2Qn6c0pG",
        "outputId": "5621d6ec-23a3-4039-b066-0aa942655385"
      },
      "source": [
        "len(test_df[test_df['label'] == test_df['predicted_label']])/len(test_df)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8733591698962371"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "EfytFgnpVQ6R",
        "outputId": "3eaa38d8-096a-4587-fb72-70cb8746a1a4"
      },
      "source": [
        "test_df[test_df['label'] != test_df['predicted_label']].sample(3)[['clean_tweet_text', 'tweet_text', 'predicted_label', 'label']]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_tweet_text</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4375</th>\n",
              "      <td>no sirvo ni para hacer arroz🤦‍♀️</td>\n",
              "      <td>no sirvo ni para hacer arroz🤦‍♀️</td>\n",
              "      <td>it</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4583</th>\n",
              "      <td>beep beep</td>\n",
              "      <td>@clemstaldim beep beep https://t.co/sxcnwsxun8</td>\n",
              "      <td>nl</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2175</th>\n",
              "      <td>trop</td>\n",
              "      <td>@godshesacrybaby trop 😂😂</td>\n",
              "      <td>nl</td>\n",
              "      <td>fr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      clean_tweet_text  ... label\n",
              "4375  no sirvo ni para hacer arroz🤦‍♀️  ...    es\n",
              "4583                         beep beep  ...    en\n",
              "2175                              trop  ...    fr\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5ECmLd3rktZ"
      },
      "source": [
        "**Part 7**\n",
        "\n",
        "Calculate the F1 score of your output from part 6. (hint: you can use https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOBO3YQls66r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1400f8-195d-4814-83a3-9b87057668e8"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(test_df['label'].tolist(), test_df['predicted_label'].tolist(), average='micro')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.873359169896237"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEtckSWNANqW"
      },
      "source": [
        "# **Good luck!**"
      ]
    }
  ]
}