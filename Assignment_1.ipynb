{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabibu/nlp/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce5pQK3bFn_"
      },
      "source": [
        "# Assignment 1\n",
        "In this assignment you will be creating tools for learning and testing language models.\n",
        "The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwG8v-Ll49KM"
      },
      "source": [
        "*As a preparation for this task, download the data files from the course git repository.\n",
        "\n",
        "The relevant files are under **lm-languages-data-new**:\n",
        "\n",
        "\n",
        "*   en.csv (or the equivalent JSON file)\n",
        "*   es.csv (or the equivalent JSON file)\n",
        "*   fr.csv (or the equivalent JSON file)\n",
        "*   in.csv (or the equivalent JSON file)\n",
        "*   it.csv (or the equivalent JSON file)\n",
        "*   nl.csv (or the equivalent JSON file)\n",
        "*   pt.csv (or the equivalent JSON file)\n",
        "*   tl.csv (or the equivalent JSON file)\n",
        "*   test.csv (or the equivalent JSON file)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xC-87z2GWMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf83569-c371-4c79-ef95-19a54976767b"
      },
      "source": [
        "!git clone https://github.com/kfirbar/nlp-course.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-course'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 53 (delta 23), reused 32 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOVb4IhsqimJ"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Important note: please use only the files under lm-languages-data-new and NOT under lm-languages-data**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYdhPfbAGkip",
        "outputId": "90aa1a8e-fd88-4762-b787-5ce786b1e343"
      },
      "source": [
        "\n",
        "!ls nlp-course/lm-languages-data-new\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en.csv\t es.json  in.csv   it.json  pt.csv    test.json   tl.csv\n",
            "en.json  fr.csv   in.json  nl.csv   pt.json   tests.csv   tl.json\n",
            "es.csv\t fr.json  it.csv   nl.json  test.csv  tests.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ashyu_mT28o6"
      },
      "source": [
        "**Part 1**\n",
        "\n",
        "Write a function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. **Our token definition is a single UTF-8 encoded character**. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCfzsITW8Yaj"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import json \n",
        "\n",
        "folder = 'nlp-course/lm-languages-data-new'\n",
        "\n",
        "def read_tweets(file_path):\n",
        "  file_suffix = pathlib.Path(file_path).suffix\n",
        "  if file_suffix == '.json':\n",
        "    with open(file_path) as f:\n",
        "      data = json.load(f)\n",
        "      return [tweet.lower() for tweet in data['tweet_text'].values()]\n",
        "      \n",
        "        \n",
        "  elif file_suffix == '.csv':\n",
        "    df = pd.read_csv(file_path, header=0)\n",
        "    return [tweet.lower() for tweet in df['tweet_text'].tolist()]\n",
        "\n",
        "def preprocess():\n",
        "  \n",
        "  vocab = set()\n",
        "  for file_name in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, file_name)\n",
        "    tweets = read_tweets(file_path)\n",
        "\n",
        "    vocab.update({word for tweet in tweets for word in tweet.lower()})\n",
        "\n",
        "  return vocab\n",
        "        "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb2PGj0Yc2TY"
      },
      "source": [
        "**Part 2**\n",
        "\n",
        "Write a function lm that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant n-1 sequences, and the values are dictionaries with the n_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
        "\n",
        "{\n",
        "  \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25},\n",
        "  \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1}\n",
        "}\n",
        "\n",
        "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
        "\n",
        "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMC_u8eQbVvZ"
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np \n",
        "\n",
        "start = '<S>'\n",
        "end = '<E>'\n",
        "\n",
        "def build_probs_model(n, vocabulary, tweets, add_one):\n",
        "\n",
        "    counts = {}\n",
        "\n",
        "    num_of_tokens = 0.0\n",
        "    for tweet in tweets:\n",
        "      \n",
        "        characters = list(tweet)\n",
        "\n",
        "        tokens = [start] + characters + [end] if n > 1 else characters\n",
        "\n",
        "        num_of_tokens += len(tokens)\n",
        "\n",
        "        if len(tokens) < n:\n",
        "            continue\n",
        "\n",
        "        for i in range(n, len(tokens)):\n",
        "            current_tokens = tokens[i - n: i]\n",
        "\n",
        "            character = current_tokens[-1]\n",
        "\n",
        "            if n > 1:\n",
        "                n_key = ''.join(current_tokens[0: -1])\n",
        "\n",
        "                if n_key not in counts:\n",
        "                    counts[n_key] = {}\n",
        "\n",
        "                if character not in counts[n_key]:\n",
        "                    counts[n_key][character] = 0.0\n",
        "\n",
        "                counts[n_key][character] += 1.0\n",
        "            else:\n",
        "                if character not in counts:\n",
        "                    counts[character] = 0.0\n",
        "\n",
        "                counts[character] += 1\n",
        "\n",
        "\n",
        "    if n == 1:\n",
        "        \n",
        "        if add_one:\n",
        "            model = defaultdict(lambda : 1.0/len(vocabulary), {word: (count + 1.0) / (num_of_tokens + len(vocabulary)) for (word, count) in counts.items()})\n",
        "        else:\n",
        "          model = defaultdict(lambda : 0.0, {word: count / num_of_tokens for (word, count) in counts.items()})\n",
        "    else:\n",
        "            \n",
        "        default_model = defaultdict(lambda :0.0) if not add_one else defaultdict(lambda :1.0/len(vocabulary))\n",
        "        model = defaultdict(lambda : default_model)\n",
        "        for gram, next_character_counts in counts.items():\n",
        "            n = np.sum(list(next_character_counts.values()))\n",
        "\n",
        "            if add_one:\n",
        "              model[gram] = defaultdict(lambda: 1.0/(n + len(vocabulary)), {word: (count +1.0) / (n + len(vocabulary)) for (word, count) in next_character_counts.items()})\n",
        "            else:\n",
        "              model[gram] = defaultdict(lambda : 0.0, {word: count / n for (word, count) in next_character_counts.items()})\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def lm(n, vocabulary, data_file_path, add_one):\n",
        "  # n - the n-gram to use (e.g., 1 - unigram, 2 - bigram, etc.)\n",
        "  # vocabulary - the vocabulary list (which you should use for calculating add_one smoothing)\n",
        "  # data_file_path - the data_file from which we record probabilities for our model\n",
        "  # add_one - True/False (use add_one smoothing or not)\n",
        "\n",
        "  # TODO\n",
        "  tweets = read_tweets(data_file_path)\n",
        "  return build_probs_model(n, vocabulary, tweets, add_one)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8TchtI22I3"
      },
      "source": [
        "**Part 3**\n",
        "\n",
        "Write a function *eval* that returns the perplexity of a model (dictionary) running over a given data file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0kkMn328-lJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc1765b-35d0-41a5-c952-cfc02a5b67d7"
      },
      "source": [
        "def eval(n, model, data_file):\n",
        "    # n - the n-gram that you used to build your model (must be the same number)\n",
        "    # model - the dictionary (model) to use for calculating perplexity\n",
        "    # data_file - the tweets file that you wish to claculate a perplexity score for\n",
        "\n",
        "    # TODO\n",
        "    tweets = read_tweets(data_file)\n",
        "\n",
        "    tweets_perplexity = []\n",
        "    for tweet in tweets:\n",
        "        probs_n = 0.0\n",
        "        entropy_sum = 0.0\n",
        "        if n == 1:\n",
        "            for token in tweet:\n",
        "                prob = model[token]\n",
        "                if prob == 0:\n",
        "                    entropy_sum += 1 * np.log2(0.000000001)\n",
        "                else:\n",
        "                    entropy_sum += prob * np.log2(prob)\n",
        "                probs_n += 1\n",
        "        else:\n",
        "            for index in range(0, len(tweet)):\n",
        "                to_index = index + n\n",
        "                tokens = tweet[index: to_index]\n",
        "                if len(tokens) < n:\n",
        "                    break\n",
        "                prev = tokens[0: -1]\n",
        "\n",
        "                to_token = tokens[-1]\n",
        "\n",
        "                prob = model[prev][to_token]\n",
        "                if prob == 0:\n",
        "                    entropy_sum += 1 * np.log2(0.000000001)\n",
        "                else:\n",
        "                    entropy_sum += prob * np.log2(prob)\n",
        "                probs_n += 1\n",
        "\n",
        "        entropy = (-1 / probs_n) * entropy_sum\n",
        "        tweet_perplexity = np.power(2, entropy)\n",
        "        tweets_perplexity.append(tweet_perplexity)\n",
        "\n",
        "    return np.mean(tweets_perplexity)\n",
        "    \n",
        "# vocab = preprocess()\n",
        "# model = lm(2, vocab, 'nlp-course/lm-languages-data-new/en.csv', False)\n",
        "# eval(2, model, 'nlp-course/lm-languages-data-new/es.csv')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "580.0844998344301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enGmtLE3921p"
      },
      "source": [
        "**Part 4**\n",
        "\n",
        "Write a function *match* that creates a model for every relevant language, using a specific value of *n* and *add_one*. Then, calculate the perplexity of all possible pairs (e.g., en model applied on the data files en ,es, fr, in, it, nl, pt, tl; es model applied on the data files en, es...). This function should return a pandas DataFrame with columns [en ,es, fr, in, it, nl, pt, tl] and every row should be labeled with one of the languages. Then, the values are the relevant perplexity values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caAxLE9s_fvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "b8343ece-bf7e-4aa2-8fc4-7ba877514b5d"
      },
      "source": [
        "def match(n, add_one):\n",
        "  # n - the n-gram to use for creating n-gram models\n",
        "  # add_one - use add_one smoothing or not\n",
        "\n",
        "  vocabulary = preprocess()\n",
        "\n",
        "  language_to_model = {}\n",
        "  language_to_data_file = {}\n",
        "  for file_name in os.listdir(folder):\n",
        "    language = os.path.splitext(file_name)[0]\n",
        "    if language in language_to_model or 'test' in language:\n",
        "      continue\n",
        "\n",
        "    file_path = os.path.join(folder, file_name)\n",
        "    language_to_data_file[language] = file_path\n",
        "\n",
        "    model = lm(n, vocabulary, file_path, add_one)\n",
        "    language_to_model[language] = model\n",
        "\n",
        "  languages = sorted(list(language_to_model.keys()))\n",
        "\n",
        "  rows = []\n",
        "  for index, language1 in enumerate(languages):\n",
        "    current_res = []\n",
        "    for index, language2 in enumerate(languages):\n",
        "      #perplexity = calc_perplexity(n, language_to_model[language1], language_to_model[language2])\n",
        "      perplexity = eval(n, language_to_model[language1], language_to_data_file[language2])\n",
        "      current_res.append(perplexity)\n",
        "    \n",
        "    rows.append(current_res)\n",
        "  \n",
        "  return pd.DataFrame(rows, columns =languages, index=languages)\n",
        "\n",
        "match(2, False) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>es</th>\n",
              "      <th>fr</th>\n",
              "      <th>in</th>\n",
              "      <th>it</th>\n",
              "      <th>nl</th>\n",
              "      <th>pt</th>\n",
              "      <th>tl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>1.217270</td>\n",
              "      <td>580.084500</td>\n",
              "      <td>4.599724</td>\n",
              "      <td>1315.648613</td>\n",
              "      <td>3.360552</td>\n",
              "      <td>760.082728</td>\n",
              "      <td>655.469301</td>\n",
              "      <td>1734.693461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>es</th>\n",
              "      <td>289.056752</td>\n",
              "      <td>1.231016</td>\n",
              "      <td>4.056581</td>\n",
              "      <td>1326.930346</td>\n",
              "      <td>15.520342</td>\n",
              "      <td>27721.105140</td>\n",
              "      <td>2653.111915</td>\n",
              "      <td>114522.871187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr</th>\n",
              "      <td>718.535807</td>\n",
              "      <td>3007.488901</td>\n",
              "      <td>1.220492</td>\n",
              "      <td>2394.099623</td>\n",
              "      <td>15.364691</td>\n",
              "      <td>55753.908597</td>\n",
              "      <td>3839.709300</td>\n",
              "      <td>114772.869760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>140.344924</td>\n",
              "      <td>332.118673</td>\n",
              "      <td>4.242320</td>\n",
              "      <td>1.218189</td>\n",
              "      <td>44.289797</td>\n",
              "      <td>19593.936101</td>\n",
              "      <td>2873.163966</td>\n",
              "      <td>112102.410661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>it</th>\n",
              "      <td>335.229626</td>\n",
              "      <td>3010.433071</td>\n",
              "      <td>4.076182</td>\n",
              "      <td>1208.983847</td>\n",
              "      <td>1.227589</td>\n",
              "      <td>3281.066055</td>\n",
              "      <td>3840.630578</td>\n",
              "      <td>112804.337580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nl</th>\n",
              "      <td>441.140692</td>\n",
              "      <td>1895.781820</td>\n",
              "      <td>3.286142</td>\n",
              "      <td>1739.885654</td>\n",
              "      <td>3.005452</td>\n",
              "      <td>1.218804</td>\n",
              "      <td>3814.072488</td>\n",
              "      <td>111546.301161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pt</th>\n",
              "      <td>143.968670</td>\n",
              "      <td>102.913132</td>\n",
              "      <td>3.887172</td>\n",
              "      <td>1557.970792</td>\n",
              "      <td>44.459766</td>\n",
              "      <td>55677.157295</td>\n",
              "      <td>1.224135</td>\n",
              "      <td>113528.685159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tl</th>\n",
              "      <td>298.473850</td>\n",
              "      <td>2999.141287</td>\n",
              "      <td>4.306378</td>\n",
              "      <td>3968.717602</td>\n",
              "      <td>10.196380</td>\n",
              "      <td>43.805729</td>\n",
              "      <td>3825.059178</td>\n",
              "      <td>1.220652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            en           es        fr  ...            nl           pt             tl\n",
              "en    1.217270   580.084500  4.599724  ...    760.082728   655.469301    1734.693461\n",
              "es  289.056752     1.231016  4.056581  ...  27721.105140  2653.111915  114522.871187\n",
              "fr  718.535807  3007.488901  1.220492  ...  55753.908597  3839.709300  114772.869760\n",
              "in  140.344924   332.118673  4.242320  ...  19593.936101  2873.163966  112102.410661\n",
              "it  335.229626  3010.433071  4.076182  ...   3281.066055  3840.630578  112804.337580\n",
              "nl  441.140692  1895.781820  3.286142  ...      1.218804  3814.072488  111546.301161\n",
              "pt  143.968670   102.913132  3.887172  ...  55677.157295     1.224135  113528.685159\n",
              "tl  298.473850  2999.141287  4.306378  ...     43.805729  3825.059178       1.220652\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waGMwA8H_n17"
      },
      "source": [
        "**Part 5**\n",
        "\n",
        "Run match with *n* values 1-4, once with add_one and once without, and print the 8 tables to this notebook, one after another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk32naXyAMdl"
      },
      "source": [
        "for n in range(1,5):\n",
        "  for add_one in [True, False]:\n",
        "    print(match(n, add_one))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg4h5Cl0q2nR"
      },
      "source": [
        "**Part 6**\n",
        "\n",
        "Each line in the file test.csv contains a sentence and the language it belongs to. Write a function that uses your language models to classify the correct language of each sentence.\n",
        "\n",
        "Important note regarding the grading of this section: this is an open question, where a different solution will yield different accuracy scores. any solution that is not trivial (e.g. returning 'en' in all cases) will be excepted. We do reserve the right to give bonus points to exceptionally good/creative solutions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYyZ6Y_0VR_g"
      },
      "source": [
        "def build_languages_models(n, add_one):\n",
        "\n",
        "  vocabulary = preprocess()\n",
        "\n",
        "  language_to_model = {}\n",
        "  for file_name in os.listdir(folder):\n",
        "    language = os.path.splitext(file_name)[0]\n",
        "    if language in language_to_model or 'test' in language:\n",
        "      continue\n",
        "      \n",
        "    \n",
        "    file_path = os.path.join(folder, file_name)\n",
        "\n",
        "    model = lm(n, vocabulary, file_path, add_one)\n",
        "    language_to_model[language] = model\n",
        "  return language_to_model\n",
        "\n",
        "language_to_model = build_languages_models(2, False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l0I_hA4VsIx"
      },
      "source": [
        "TEST_FILE = 'test.csv'\n",
        "test_df = pd.read_csv(os.path.join(folder, TEST_FILE))[['tweet_text', 'label']]\n",
        "test_df[\"tweet_text\"] = test_df[\"tweet_text\"].str.lower()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R-H5_Hhulh_"
      },
      "source": [
        "# test_df.sample(10)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD6IRIQLrlZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f295e700-a2ec-47cc-e721-cd2eb491c816"
      },
      "source": [
        "import string\n",
        "\n",
        "def classify_language(tweet, n):\n",
        "  \n",
        "\n",
        "  seen = False\n",
        "  \n",
        "  xx = ''\n",
        "  for x in tweet:\n",
        "    if seen:\n",
        "      if x == ' ':\n",
        "        seen = False\n",
        "      else:\n",
        "        continue\n",
        "    else:\n",
        "      if x in ['😂','👌🏽','🕋','💎','😌', '🆘', '🔴','#', '😍','🔥','💙','😻','💔','@', '🙌🏾','👙','☀️','🍾','🎈','%']:\n",
        "        xx +=''\n",
        "\n",
        "      if x == '@':\n",
        "        seen = True\n",
        "      else:\n",
        "        xx += x\n",
        "      \n",
        "\n",
        "\n",
        "  g = re.findall(r'(https?://\\S+)', xx)\n",
        "\n",
        "  for x in g:\n",
        "    xx = xx.replace(x, '')\n",
        "  \n",
        "  xx = xx.replace(' ', ' ')\n",
        "  tweet = xx\n",
        "\n",
        "\n",
        "  best_language_prob = float('-inf')\n",
        "  best_language = None\n",
        "\n",
        "  for language, model in language_to_model.items():\n",
        "    index = 0\n",
        "\n",
        "    # if language in ['en', 'fr']:\n",
        "    #   print(language)\n",
        "    language_log_prob = 0.0\n",
        "    while index + n < len(tweet):\n",
        "      if n == 1:\n",
        "        token = tweet[index: index + 1]\n",
        "        prob = model[token]\n",
        "        prob = prob if prob > 0 else 0.0000001\n",
        "        language_log_prob += np.log(prob)\n",
        "      else:\n",
        "        tokens = tweet[index: index + n]\n",
        "        prev = tokens[0:-1]\n",
        "        next = tokens[-1]\n",
        "\n",
        "        prob = model[prev][next]\n",
        "        # if language in ['en', 'fr']:\n",
        "          # print('---')\n",
        "          # print(prev)\n",
        "          # print(next)\n",
        "          # print(prob)\n",
        "          # print('---')\n",
        "\n",
        "        prob = prob if prob > 0 else 0.0000001\n",
        "        language_log_prob += np.log(prob)\n",
        "      index += 1\n",
        "    \n",
        "    # print(language)\n",
        "    # print(language_log_prob)\n",
        "    if language_log_prob > best_language_prob:\n",
        "      best_language_prob = language_log_prob\n",
        "      best_language = language\n",
        "    \n",
        "\n",
        "  return best_language\n",
        "\n",
        "\n",
        "# import string\n",
        "# s = \"string. With. .x,x. Punctuation?\" # Sample string \n",
        "# translator = str.maketrans('', '', string.punctuation)\n",
        "# s.translate(translator)\n",
        "\n",
        "# #type(language_to_model['en'])\n",
        "\n",
        "ind = 484\n",
        "xx = classify_language(test_df.iloc[ind]['tweet_text'], 2)\n",
        "xx, test_df.iloc[ind]['label'], test_df.iloc[ind]['tweet_text']\n",
        "\n",
        "# #test_df[\"predicted_label\"] = test_df[\"tweet_text\"].apply(lambda t: classify_language(t, 1))\n",
        "# import re \n",
        "# tt = 'rt [#transfert🛫] selon sport, http://walla.com marco verratti aurait choisi de rejoindre le barça cet été. https://t.co/prhien6xwn'\n",
        "# g = re.findall(r'(https?://\\S+)', tt)\n",
        "\n",
        "# for x in g:\n",
        "#   tt = tt.replace(x, '')\n",
        "\n",
        "# tt"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fr',\n",
              " 'fr',\n",
              " 'rt @footballogue: [#transfert🛫] selon sport, marco verratti aurait choisi de rejoindre le barça cet été. https://t.co/prhien6xwn')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUtxs1sybj4Z"
      },
      "source": [
        "test_df[\"predicted_label\"] = test_df[\"tweet_text\"].apply(lambda t: classify_language(t, 2))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNwD2Qn6c0pG",
        "outputId": "2ef5c18b-94bb-4ab4-df8e-5befef9a42aa"
      },
      "source": [
        "len(test_df[test_df['label'] == test_df['predicted_label']])/len(test_df)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8739842480310038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "EfytFgnpVQ6R",
        "outputId": "fa19057c-c3aa-4af2-c0ff-29f6bc63b503"
      },
      "source": [
        "test_df[test_df['label'] != test_df['predicted_label']].sample(3)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6543</th>\n",
              "      <td>rt @actufoot_: cette photo... ❤ https://t.co/q...</td>\n",
              "      <td>fr</td>\n",
              "      <td>it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5406</th>\n",
              "      <td>rt @fabkimk: mayward plans:  oplan a ilaglag c...</td>\n",
              "      <td>tl</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4180</th>\n",
              "      <td>rt @bts_twt: jm + jk #rm https://t.co/vx7tnmok5i</td>\n",
              "      <td>tl</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text label predicted_label\n",
              "6543  rt @actufoot_: cette photo... ❤ https://t.co/q...    fr              it\n",
              "5406  rt @fabkimk: mayward plans:  oplan a ilaglag c...    tl              in\n",
              "4180   rt @bts_twt: jm + jk #rm https://t.co/vx7tnmok5i    tl              nl"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5ECmLd3rktZ"
      },
      "source": [
        "**Part 7**\n",
        "\n",
        "Calculate the F1 score of your output from part 6. (hint: you can use https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOBO3YQls66r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f0a12d-1faf-4464-b899-aad245645d10"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(test_df['label'].tolist(), test_df['predicted_label'].tolist(), average='micro')\n",
        "#test_df['predicted_label'].tolist()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7709713714214276"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEtckSWNANqW"
      },
      "source": [
        "# **Good luck!**"
      ]
    }
  ]
}