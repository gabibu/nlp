{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7vz0__2J7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb454a4f-6c37-4693-c073-cc8af89429e8"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 7.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H9Z4iZ2XPb"
      },
      "source": [
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "h0uiWBjK2jtU",
        "outputId": "035587e0-044a-47e2-faa3-b4c4ca6a5429"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fe6369ec-2832-4461-915b-3a0e55f33331\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fe6369ec-2832-4461-915b-3a0e55f33331\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gabib3b\",\"key\":\"817d7e169db4cbef867b22907320144c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFkqZ-42pXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f35487e-0276-414e-8f6b-c6f9328e75c2"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 19% 5.00M/26.3M [00:00<00:01, 11.2MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 48.9MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 94% 22.0M/23.4M [00:00<00:00, 48.7MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 93.0MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 199MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 210MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnbKHLMmrX5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3225039b-d434-415e-8d6d-61a10969e181"
      },
      "source": [
        "! ls  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sample_submission.csv.zip\ttest_labels.csv.zip\n",
            "sample_data  test.csv.zip\t\ttrain.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjfnT_W9EE-p",
        "outputId": "5e7e8785-7f6b-4333-c973-205ef43bf868"
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWqYvAjmEb34",
        "outputId": "1b34e1fe-ce1e-4e3c-e963-b230051e767e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sample_submission.csv.zip\ttest_labels.csv.zip  train.csv.zip\n",
            "sample_data  test.csv.zip\t\ttrain.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc3SPuZR366P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c20e84c-ccd3-4ca3-8261-94c88b7f6847"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "import nltk \n",
        "import unidecode\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5kTCLu3wPp"
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")[['id', 'comment_text', 'toxic']].sample(1000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "rg4nBRckEjh0",
        "outputId": "f433ed3c-38b3-47c3-b2d5-39bb652ed045"
      },
      "source": [
        "train_df.sample(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75655</th>\n",
              "      <td>ca700ec661b22033</td>\n",
              "      <td>\"\\nSince some users have caused problems in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32605</th>\n",
              "      <td>56c31e0fea9d50fb</td>\n",
              "      <td>\"\\n\\n While I can almost understand your block...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57056</th>\n",
              "      <td>98884029d8b57c3a</td>\n",
              "      <td>(UTC)\\n You spend too much tim eon the interne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ... toxic\n",
              "75655  ca700ec661b22033  ...     0\n",
              "32605  56c31e0fea9d50fb  ...     1\n",
              "57056  98884029d8b57c3a  ...     0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lxkLY0FTFOUD",
        "outputId": "274a8c1a-fa4b-414b-fa66-3e73b948cb78"
      },
      "source": [
        "ax = sns.countplot(x=\"toxic\", data=train_df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VZQCATBHsLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3598becc-8ffd-4564-89ae-cf0c38f27635"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch \n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def get_text_hidden_states(text: str):\n",
        "\n",
        "  marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)[0: 512]\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "  segments_ids = [1] * len(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "  with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2]\n",
        "    \n",
        "    return [torch.mean(hs, dim=1) for hs in hidden_states]\n",
        "    \n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1UW2--BOcRV"
      },
      "source": [
        "# text = \"Here is the sentence I want embeddings for\"\n",
        "# hs = get_text_hidden_states(text)\n",
        "# # len(hs)\n",
        "# # hs[0].shape \n",
        "# len(hs)\n",
        "# hs[2].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ0X0ZnVY78z",
        "outputId": "e9cec633-aba3-4565-db03-12478af39b8e"
      },
      "source": [
        "# text = train_df.iloc[218]['comment_text']\n",
        "\n",
        "# # pp = get_text_hidden_states(text)\n",
        "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "# tokenized_text = tokenizer.tokenize(marked_text)\n",
        "# indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "# segments_ids = [1] * len(tokenized_text)\n",
        "# tokens_tensor = torch.tensor([indexed_tokens])\n",
        "# segments_tensors = torch.tensor([segments_ids])\n",
        "# with torch.no_grad():\n",
        "\n",
        "#   outputs = model(tokens_tensor, segments_tensors)\n",
        "#   hidden_states = outputs[2]\n",
        "# pp = [torch.mean(hs, dim=1) for hs in hidden_states]\n",
        "# # tokens_tensor.shape, segments_tensors.shape\n",
        "# len(tokenized_text)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "349"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBmOPW8hJAC7",
        "outputId": "e911655b-aef7-41eb-e189-c0689c2b6332"
      },
      "source": [
        "train_df['comment_text_layers_embeddingds'] = train_df['comment_text'].progress_apply(get_text_hidden_states)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:31<00:00,  4.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdbzxon5RXzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31beeabe-10d4-44f7-e854-cb0638d1bcbf"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "X = [x[0].flatten().numpy() for x in train_df['comment_text_layers_embeddingds'].tolist()]\n",
        "y = train_df['toxic'].tolist()\n",
        "neigh.fit(X, y)\n",
        "# len(X), len(y)\n",
        "\n",
        "np.sum(neigh.predict(X) == y)/len(y)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.937"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ITAnaPU7P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8fGj-0COjWj"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(int(time.time()))\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "from torch import nn, utils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable \n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self._df = df\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self._df.iloc[idx]\n",
        "\n",
        "        search_term = np.array(row['search_term_tokens'])\n",
        "        product_title = np.array(row['product_title_tokens'])\n",
        "\n",
        "   \n",
        "\n",
        "        return row['id'], search_term, product_title, row['relevance_class']\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "NRSLuzN1kqe7",
        "outputId": "b9aef73b-6460-4210-97f6-be26c727afde"
      },
      "source": [
        "train_df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37754</th>\n",
              "      <td>115393</td>\n",
              "      <td>138330</td>\n",
              "      <td>Oakland Living Mississippi Patio Service Cart</td>\n",
              "      <td>service cart</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[101, 9182, 2542, 5900, 19404, 2326, 11122, 102, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[101, 2326, 11122, 102, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ...          search_term_tokens relevance_class\n",
              "37754  115393  138330       ...  [101, 2326, 11122, 102, 0]  0             \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTudx3_9QEOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62da0cc-6871-499c-f947-442314d3729e"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_data_df = train_df[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class', 'relevance']]\n",
        "data_loader = DatasetLoader(train_data_df)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(data_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "test_df_fixed = test_df[(test_df['search_term_tokens'].map(len) > 0) & (test_df['product_title_tokens'].map(len) > 0)]\n",
        "\n",
        "\n",
        "\n",
        "test_loader = DatasetLoader(test_df_fixed[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class']])\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=False, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "len(data_loader), len(test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74067, 166693)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "hYKG8QQEAXLS",
        "outputId": "d1f71c8a-7142-47a2-a9e4-c90a5a4e8329"
      },
      "source": [
        "train_data_df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39466</th>\n",
              "      <td>120409</td>\n",
              "      <td>[101, 20868, 12173, 2937, 2102, 4293, 3027, 1012, 4658, 2317, 2419, 8164, 2422, 8934, 102]</td>\n",
              "      <td>[101, 4029, 3027, 2419, 102]</td>\n",
              "      <td>2</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... relevance\n",
              "39466  120409  ...  2.33    \n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ti4DjnB3AC2K",
        "outputId": "7dc13d34-2646-42f2-c0ef-871aba6f5cbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>my_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35646</th>\n",
              "      <td>52729</td>\n",
              "      <td>113622</td>\n",
              "      <td>AT&amp;amp;T Trimline Telephone With Memory - Black</td>\n",
              "      <td>at</td>\n",
              "      <td>[amp, &lt;word&gt;, telephon, memori, black]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  product_uid  ... search_term_tokens my_relevance\n",
              "35646  52729  113622       ...  []                 1          \n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg9ZjtvyQYYj"
      },
      "source": [
        "for ids, search_term, product_title, target_relevance_score in test_data_loader:\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAb7Xrshd-Ap"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaU8p0SBalql"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wcUGHjMcBXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PREwU_6bclh"
      },
      "source": [
        "for ids, search_term, product_title, target_relevance_score in train_data_loader:\n",
        "  break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv4iT_xlBNeY"
      },
      "source": [
        "# from transformers import BertConfig\n",
        "\n",
        "# config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "#                                     output_hidden_states=True)\n",
        "\n",
        "# bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                          config=config)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDYpQzBNRhe3",
        "outputId": "2d54efad-3dd8-4367-ba4f-655f8436b92f"
      },
      "source": [
        "# bb = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_of_labels = 10)\n",
        "# tt = torch.from_numpy(np.array(tokenize(\"he weny home for dinner\", 10)))\n",
        "\n",
        "# dd = tokenizer.encode_plus(\n",
        "#             text,\n",
        "#             max_length = max_length, \n",
        "#             padding = 'max_length',\n",
        "#             truncation = True, \n",
        "#             return_attention_mask = True, \n",
        "#             add_special_tokens = True, \n",
        "#             )\n",
        "\n",
        "# x1 = torch.from_numpy(np.ndarray([]]))\n",
        "# x2 = torch.from_numpy(np.array([dd['attention_mask']]))\n",
        "\n",
        "\n",
        "# torch.tensor(product_title)\n",
        "i1 = torch.tensor([[7,8,9],[10,11,12]])\n",
        "bert_model(i1)['hidden_states'][-1][:, -1,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnTv4wTQRn--"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "class RelevanceModel(nn.Module):\n",
        "\n",
        "  def __init__(self, num_of_classes):\n",
        "    super(RelevanceModel, self).__init__()\n",
        "    config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "                                    output_hidden_states=True)\n",
        "\n",
        "    self.bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "\n",
        "    for param in self.bert_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    self.fc = nn.Linear(768 * 2, num_of_classes)\n",
        "\n",
        "  def  forward(self, queries, titles):\n",
        "    encoded_queries = self.bert_model(queries)['hidden_states'][-1][:, -1,:]\n",
        "    encoded_titles = self.bert_model(titles)['hidden_states'][-1][:, -1,:]\n",
        "\n",
        "    out = torch.cat((encoded_queries, encoded_titles), 1)\n",
        "\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out \n",
        "\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.uniform_(self.fc.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VMlZG21ZCK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4559ba7-c22e-4aeb-d0b1-039442bf9236"
      },
      "source": [
        "\n",
        "# # for x in model.parameters():\n",
        "# #   if not x.is_cuda:\n",
        "# #     print(x) \n",
        "\n",
        "# # e1 = EncoderModel(len(vocab)).to(device)\n",
        "# # r = e1(product_title.to(device), product_title_length)\n",
        "# output.shape, product_title_length\n",
        "# #output = r \n",
        "\n",
        "# #8\n",
        "# #out_forward = output[range(len(output)), lengths - 1, :self.embedding_dim ]\n",
        "\n",
        "# # output[range(len(output)), product_title_length - 1, :300][0]\n",
        "# product_title_length\n",
        "#output[0][14], product_title_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14, 12, 10, 15,  8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpN5VHYENQJ",
        "outputId": "5fdb6a9e-27b4-4018-d550-1631392db324"
      },
      "source": [
        "# output[0][13][300:]\n",
        "# output[:, 0, 300 :].shape, output[:, 0,]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 300]), torch.Size([5, 15, 600]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFR-SouFR5PB"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# query_encoder = EncoderModel(len(vocab))\n",
        "# title_encoder = EncoderModel(len(vocab))\n",
        "\n",
        "# query_encoder.reset_parameters()\n",
        "# title_encoder.reset_parameters()\n",
        "\n",
        "# #search_term, search_term_length, product_title, product_title_length\n",
        "# query_encoded = query_encoder(search_term, search_term_length)\n",
        "# title_encoded = query_encoder(product_title, product_title_length)\n",
        "# torch.cat((query_encoded, title_encoded), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWnKAQe_WQyF",
        "outputId": "dfae549c-9aa3-45c9-b1a4-6af73790b088"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEpPTJGLoi1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbaa3c02-8434-4e00-fb31-0cf81988a459"
      },
      "source": [
        "counts = train_df.groupby(\"relevance_class\").size().reset_index()\n",
        "#total = np.sum(counts[0].tolist())\n",
        "\n",
        "# [(row['relevance_class'],  row[0]/total) for (_, row) in counts[['relevance_class', 0]].iterrows()]\n",
        "\n",
        "total = 0.0\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  total += row[0]\n",
        "total \n",
        "weights = []\n",
        "print(total)\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  #print(row[0])\n",
        "  cls = row['relevance_class']\n",
        "  # print((cls, row[0]))\n",
        "  sampeples_weight = (row[0] / total)\n",
        "  required_weight = 1.0/len(counts)\n",
        "\n",
        "  # print('-----')\n",
        "  # print(sampeples_weight)\n",
        "  # print(required_weight)\n",
        "  x = required_weight/sampeples_weight\n",
        "  # print(x)\n",
        "\n",
        "  weight_for_class_a = (1 / row[0]) * total/len(counts)\n",
        "  \n",
        "\n",
        "   \n",
        "  # weight = x * sampeples_weight\n",
        "  # print(weight)\n",
        "  # print('-------')\n",
        "\n",
        "  weights.append((cls, x))\n",
        "\n",
        "\n",
        "\n",
        "weights = sorted(weights, key = lambda x: x[0])\n",
        "weights = [w[1] for w in weights]\n",
        "weights\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74067.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2979064856711916,\n",
              " 299.8663967611337,\n",
              " 0.35476099243222536,\n",
              " 0.37478368230900794,\n",
              " 0.4857170962030298,\n",
              " 2.7066325598392105,\n",
              " 0.8403335602450647,\n",
              " 1.8953631199140182,\n",
              " 1424.3653846153848,\n",
              " 517.951048951049,\n",
              " 633.0512820512821,\n",
              " 1139.4923076923078,\n",
              " 517.951048951049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu2VvCcmyVy1",
        "outputId": "6a47000e-e476-4ffd-f824-46b399437436"
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2979064856711916,\n",
              " 299.8663967611337,\n",
              " 0.35476099243222536,\n",
              " 0.37478368230900794,\n",
              " 0.4857170962030298,\n",
              " 2.7066325598392105,\n",
              " 0.8403335602450647,\n",
              " 1.8953631199140182,\n",
              " 1424.3653846153848,\n",
              " 517.951048951049,\n",
              " 633.0512820512821,\n",
              " 1139.4923076923078,\n",
              " 517.951048951049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEK66lCTIt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85810dfd-3d41-41db-9d99-611e85c1dc7d"
      },
      "source": [
        "model = RelevanceModel(num_of_classes)\n",
        "model.reset_parameters()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "class_weights=torch.tensor(weights,dtype=torch.float)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight = class_weights, reduction='sum').to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJiU_nc8WP8l",
        "outputId": "7037bf4d-823f-40ae-f8c6-ce81a8a99388"
      },
      "source": [
        "class_weights[2].numpy(), weights[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(0.35470936, dtype=float32), 0.3547093708384031)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knnaKV2bWAA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b9c6a0-2086-4eb4-eac8-a7dcb909e545"
      },
      "source": [
        "\n",
        "model.train()\n",
        "\n",
        "for epoc in range(1000):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  counter = 0.0\n",
        "\n",
        "  for ids, search_term, product_title, target_relevance_score  in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    target_relevance_score = Variable(target_relevance_score).long().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    scores = model(search_term, product_title)\n",
        "    loss = criterion(scores, target_relevance_score)\n",
        "\n",
        "    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    counter += search_term.shape[0]\n",
        "  #   break\n",
        "  \n",
        "  # break\n",
        "  \n",
        "  print('epoc {} loss {} counter {}'.format(epoc, running_loss/counter, counter))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoc 0 loss 6.462625524785163 counter 74067.0\n",
            "epoc 1 loss 5.558418554361422 counter 74067.0\n",
            "epoc 2 loss 4.873910256250517 counter 74067.0\n",
            "epoc 3 loss 5.541181676479559 counter 74067.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j23Rz5eLleqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cbe8a2-2a16-4070-9b49-439552699ad3"
      },
      "source": [
        "# mse_loss(scores.view(1, -1), target_relevance_score.view(1, -1))\n",
        "# counter\n",
        "torch.argmax(scores, dim=1), target_relevance_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3, 6, 3, 4, 0, 2, 7, 6, 2, 0, 6, 2, 7, 4, 0, 2, 2, 2, 7, 6, 2, 0, 6, 6,\n",
              "         3, 3, 2, 3, 4, 4, 4, 2, 3, 3, 0, 4, 2, 2, 2, 2, 2, 3, 0, 4, 0, 4, 2, 6,\n",
              "         0, 2, 2, 4, 2, 7, 3, 6, 6, 2, 0, 5, 7, 0, 3, 2], device='cuda:0'),\n",
              " tensor([3, 6, 3, 4, 0, 2, 7, 6, 2, 0, 0, 2, 7, 4, 4, 4, 2, 2, 7, 3, 2, 0, 6, 6,\n",
              "         3, 3, 2, 3, 4, 0, 4, 2, 3, 3, 0, 3, 3, 2, 2, 2, 7, 3, 0, 4, 3, 4, 3, 6,\n",
              "         0, 2, 2, 4, 2, 7, 3, 6, 6, 2, 0, 5, 7, 0, 3, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B5hKqKGe-y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518aaaa8-6e11-4e0a-a503-d463b5bda17b"
      },
      "source": [
        "scores.detach().cpu().numpy() , target_relevance_score.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2.4221616],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.4221613],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ]], dtype=float32),\n",
              " array([2.67, 2.  , 2.  , 2.  , 1.67, 1.67, 3.  , 2.67, 1.33, 3.  , 3.  ,\n",
              "        2.33, 2.33, 3.  , 3.  , 2.67, 2.33, 2.67, 3.  , 2.33, 3.  , 2.  ,\n",
              "        2.  , 3.  , 1.67, 2.67, 3.  , 3.  , 3.  , 2.33, 3.  , 2.67, 2.67,\n",
              "        3.  , 3.  , 2.67, 1.  , 2.  , 3.  , 2.33, 2.  , 2.  , 2.  , 2.33,\n",
              "        1.  , 1.67, 2.33, 1.67, 2.  , 1.67, 3.  , 1.67, 2.67, 2.  , 2.33,\n",
              "        3.  , 2.33, 3.  , 3.  , 3.  , 1.67, 2.67, 1.  , 2.33]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTBEJ3CasIks",
        "outputId": "2417d084-a94d-400a-9c14-5b7addf87a4e"
      },
      "source": [
        "r1, scores.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, torch.Size([64, 13]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgvd78qCkW8m"
      },
      "source": [
        "\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, search_term_length, product_title, product_title_length, target_relevance_score in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    \n",
        "\n",
        "    scores = model(search_term, product_title, search_term_length,  product_title_length)\n",
        "\n",
        "    test_scores.extend(scores.detach().cpu().numpy().flatten().tolist())\n",
        "    test_ids.extend(ids.numpy().tolist())\n",
        "    tt.extend(target_relevance_score.numpy().tolist())\n",
        "\n",
        "    break\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdxRw_b_LTq"
      },
      "source": [
        "for _ in test_data_loader:\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYqvaAVNk6pY",
        "outputId": "af0cc2b4-97d8-4c87-d719-aea61982e064"
      },
      "source": [
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "test_data = []\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, search_term_length, product_title, product_title_length, target_relevance_score in test_data_loader:\n",
        "     \n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    \n",
        "\n",
        "    scores = model(search_term, product_title, search_term_length,  product_title_length)\n",
        "\n",
        "    vals = torch.argmax(scores, dim=1).flatten().detach().cpu().numpy().tolist()\n",
        "    ids = ids.numpy().tolist()\n",
        "\n",
        "    test_data.extend(zip(ids, vals))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-HHAoXDZCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce45f3e5-ac44-4e64-8bec-8e2353ce7fe0"
      },
      "source": [
        "# 166693, len(test_data), len(test_df)\n",
        "all_ids = {x for (x, _) in test_data}\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "  if row['id'] not in all_ids:\n",
        "    test_data.append((row['id'], 1))\n",
        "    \n",
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCkYUGAMgvqF"
      },
      "source": [
        "pd.DataFrame([(id, cls_to_score[cls]) for (id, cls) in test_data], columns = [\"id\", \"relevance\"]).to_csv(\"test_res.csv\", index=  False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6XfNPdDKx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18c4fd2a-77b5-40dc-b802-71af0983f330"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('test_res.csv') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f1fa6b5d-807b-4df1-b82c-3b19b4724bfd\", \"test_res.csv\", 1850918)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrqzbWUODp-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "3afbb0ac-512f-4b76-e5a1-a8d59f96d5fb"
      },
      "source": [
        "test_df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>my_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107023</th>\n",
              "      <td>159578</td>\n",
              "      <td>161578</td>\n",
              "      <td>Speedi-Products 7 in. 24-Gauge Single Wall Stove Pipe 90 Degree Adjustable Elbow in Black Matte</td>\n",
              "      <td>singel wall stove pipe</td>\n",
              "      <td>[speedi, product, #, ##, gaug, singl, wall, stove, pipe, ##, degre, adjust, elbow, black, matt]</td>\n",
              "      <td>[singel, wall, stove, pipe]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  product_uid  ...           search_term_tokens my_relevance\n",
              "107023  159578  161578       ...  [singel, wall, stove, pipe]  1          \n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    }
  ]
}