{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7vz0__2J7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2785b95-53c1-4999-8426-7758edae0285"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 9.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 55.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 8.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H9Z4iZ2XPb"
      },
      "source": [
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "h0uiWBjK2jtU",
        "outputId": "849184a5-251c-407e-eecd-ba9260433fc7"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4fbd462d-9908-465d-814a-f01d23cfa6a8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4fbd462d-9908-465d-814a-f01d23cfa6a8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gabib3b\",\"key\":\"817d7e169db4cbef867b22907320144c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFkqZ-42pXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c04692-f3ad-47e4-fd16-8c1123d52f84"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 94.4MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 212MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 73% 17.0M/23.4M [00:00<00:00, 28.4MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 34.4MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 65% 17.0M/26.3M [00:00<00:00, 33.1MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 48.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnbKHLMmrX5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57982419-9689-427d-ed01-319c256d5b3f"
      },
      "source": [
        "! ls  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sample_submission.csv.zip\ttest_labels.csv.zip\n",
            "sample_data  test.csv.zip\t\ttrain.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjfnT_W9EE-p",
        "outputId": "6ae80c1c-8011-4661-bc8e-447218c85792"
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWqYvAjmEb34",
        "outputId": "be6e3ece-a299-45cd-9b68-e407833d99bc"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sample_submission.csv.zip\ttest_labels.csv.zip  train.csv.zip\n",
            "sample_data  test.csv.zip\t\ttrain.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc3SPuZR366P"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "import string\n",
        "import seaborn as sns"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5kTCLu3wPp"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")[['id', 'comment_text', 'toxic']].sample(1000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "rg4nBRckEjh0",
        "outputId": "463ca8c9-91b3-4d9e-b81d-0359ea549f5c"
      },
      "source": [
        "df.sample(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144877</th>\n",
              "      <td>13e1198f2be29963</td>\n",
              "      <td>\"\\n\\nComments at Wikipedia talk:WikiProject Na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12434</th>\n",
              "      <td>20fa20c5151eb406</td>\n",
              "      <td>\"\\n\\nThanks for correcting. I clicked on \"\"van...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143138</th>\n",
              "      <td>fd7304fac4ee6b67</td>\n",
              "      <td>Davkal?????\\n\\nNow some say he's doing the obi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... toxic\n",
              "144877  13e1198f2be29963  ...     0\n",
              "12434   20fa20c5151eb406  ...     0\n",
              "143138  fd7304fac4ee6b67  ...     0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lxkLY0FTFOUD",
        "outputId": "cad75885-e0ac-4de4-f384-46db3ade3b31"
      },
      "source": [
        "ax = sns.countplot(x=\"toxic\", data=df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2V7clK9x-oW",
        "outputId": "1de65fd1-61f7-4b6f-9340-a31599e34cad"
      },
      "source": [
        "train_df, validation_df = train_test_split(df, test_size = 0.2)\n",
        "train_df.shape[0], validation_df.shape[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VZQCATBHsLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1b6c1b-f842-4bcb-bc41-7c276e286bef"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch \n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "MAX_NUMBER_OF_WORDS_IN_SENTENSE = 512\n",
        "CLS = \"[CLS] \"\n",
        "SEP = \" [SEP]\"\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# model.eval()\n",
        "\n",
        "# def get_text_hidden_states(text: str):\n",
        "\n",
        "#   marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "#   tokenized_text = tokenizer.tokenize(marked_text)[0: 512]\n",
        "#   indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "#   segments_ids = [1] * len(tokenized_text)\n",
        "#   tokens_tensor = torch.tensor([indexed_tokens])\n",
        "#   segments_tensors = torch.tensor([segments_ids])\n",
        "#   with torch.no_grad():\n",
        "\n",
        "#     outputs = model(tokens_tensor, segments_tensors)\n",
        "#     hidden_states = outputs[2]\n",
        "    \n",
        "#     return [torch.mean(hs, dim=1) for hs in hidden_states]\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t2Eu2VQq6f7",
        "outputId": "672342fb-a708-43d1-bc23-ef2d95b9b9e7"
      },
      "source": [
        "train_df[['comment_text_tokens_ids', 'comment_text_segments_ids']] = train_df['comment_text'].progress_apply(text_to_tokens_ids)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:01<00:00, 513.25it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "1x1U5HuvtaIn",
        "outputId": "c1bfb893-968f-49a2-9693-a06944bd82ec"
      },
      "source": [
        "text = \"he went home\"\n",
        "marked_text = CLS + text + SEP\n",
        "tokenized_text = tokenizer.tokenize(marked_text)[0: MAX_NUMBER_OF_WORDS_IN_SENTENSE]\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "mask1 = [1] * len(indexed_tokens) + [0] * 5\n",
        "indexed_tokens1= indexed_tokens + [0] * 5\n",
        "\n",
        "mask2 = [1] * len(indexed_tokens[0:3]) + [0] * 7\n",
        "indexed_tokens2= indexed_tokens[0:3] + [0] * 7\n",
        "len(indexed_tokens2), len(indexed_tokens1)\n",
        "\n",
        "in1 = torch.tensor([indexed_tokens1, indexed_tokens2])\n",
        "# segments_ids = [1] * len(indexed_tokens)\n",
        "# segments_tensors = torch.tensor([segments_ids])\n",
        "mask = torch.tensor([mask1, mask2])\n",
        "outputs = model(in1, attention_mask = mask)\n",
        "\n",
        "hidden_states = outputs[2]\n",
        "\n",
        "hidden_states[-1].shape\n",
        "\n",
        "ss = torch.IntTensor([5,3])\n",
        "\n",
        "pp = hidden_states[-1][:, :ss, :]\n",
        "\n",
        "\n",
        "#torch.mean(hidden_states[-1])\n",
        "#-0.0128 \n",
        "# hidden_states[-1][0][-2].shape, len(indexed_tokens), mask"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-7fbfbaed9a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hiwyptrtlf"
      },
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from typing import List \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "class BaseClassifier(ABC):\n",
        "  \n",
        "  def __init__(self, bert_model, tokenizer):\n",
        "    self._bert_model = bert_model\n",
        "    self._bert_model.eval()\n",
        "    self._tokenizer = tokenizer\n",
        "\n",
        "  @abstractmethod\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    pass \n",
        "\n",
        "  @abstractmethod\n",
        "  def predict(self, df: pd.DataFrame):\n",
        "    pass \n",
        "  \n",
        "  def text_to_tokens_ids(self, text):\n",
        "\n",
        "    marked_text = CLS + text + SEP\n",
        "    tokenized_text = self._tokenizer.tokenize(marked_text)[0: MAX_NUMBER_OF_WORDS_IN_SENTENSE]\n",
        "    indexed_tokens = self._tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    #segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "    return indexed_tokens\n",
        "\n",
        "  def text_to_sentense_embeddingds(self, text: str, embeddings_layer: int):\n",
        "    indexed_tokens = self.text_to_tokens_ids(text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_ids = [1] * len(indexed_tokens)\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = self._bert_model(tokens_tensor, segments_tensors)\n",
        "      hidden_states = outputs[2]\n",
        "      \n",
        "    return torch.mean(hidden_states[embeddings_layer], dim=1).numpy().flatten()\n",
        "  \n",
        "  def evaluate(self, df):\n",
        "    predictions = self.predict(df)\n",
        "    targets = df['toxic'].tolist()\n",
        "\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(targets, predictions, average='binary')\n",
        "\n",
        "    return pd.DataFrame([(precision, recall, fscore)], columns = ['precision','recall', 'fscore'])\n",
        "\n",
        "  \n",
        "class NearestNeiborClassifier(BaseClassifier):\n",
        "  def __init__(self, bert_model, tokenizer, embeddings_layer, n_neighbors):\n",
        "    BaseClassifier.__init__(self, bert_model, tokenizer)\n",
        "    self._embeddings_layer = embeddings_layer\n",
        "    self._n_neighbors = n_neighbors\n",
        "    self._model = None\n",
        "\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    \n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    y = df['toxic'].tolist()\n",
        "\n",
        "    self._model = KNeighborsClassifier(n_neighbors = self._n_neighbors)\n",
        "    self._model.fit(X, y)\n",
        "\n",
        "  def predict(self, df):\n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    \n",
        "    return self._model.predict(X)\n",
        "  \n",
        "\n",
        "class TorchClassifier(BaseClassifier):\n",
        "  def __init__(self, bert_model, tokenizer, embeddings_layer, n_neighbors):\n",
        "    BaseClassifier.__init__(self, bert_model, tokenizer)\n",
        "    self._embeddings_layer = embeddings_layer\n",
        "    self._n_neighbors = n_neighbors\n",
        "    self._model = None\n",
        "\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    \n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    y = df['toxic'].tolist()\n",
        "\n",
        "    self._model = KNeighborsClassifier(n_neighbors = self._n_neighbors)\n",
        "    self._model.fit(X, y)\n",
        "\n",
        "  def predict(self, df):\n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    \n",
        "    return self._model.predict(X)\n",
        "  \n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7AZmLoBwM7p",
        "outputId": "307f058e-1378-4e8e-91f8-f318a8a110d4"
      },
      "source": [
        "# precision_recall_fscore_support([1,0,1,0], [1,1,1,1], average='binary')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 1.0, 0.6666666666666666, None)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddI9xpimvT86",
        "outputId": "790d72be-ce9b-45c4-e7d3-be31d72717e0"
      },
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True)\n",
        "\n",
        "model.eval()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "nn = NearestNeiborClassifier(model, tokenizer, -1, 3)\n",
        "nn.fit(train_df)\n",
        "nn.evaluate(test_size)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [03:22<00:00,  3.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "pCFGoFB13O7i",
        "outputId": "cabce4c6-98c5-44a4-9987-9508f722878e"
      },
      "source": [
        ""
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:46<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>fscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.6875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision    recall  fscore\n",
              "0   0.785714  0.611111  0.6875"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1UW2--BOcRV"
      },
      "source": [
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "X = [x[0].flatten().numpy() for x in train_df['comment_text_layers_embeddingds'].tolist()]\n",
        "y = train_df['toxic'].tolist()\n",
        "neigh.fit(X, y)\n",
        "# len(X), len(y)\n",
        "\n",
        "np.sum(neigh.predict(X) == y)/len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ0X0ZnVY78z",
        "outputId": "e9cec633-aba3-4565-db03-12478af39b8e"
      },
      "source": [
        "# text = train_df.iloc[218]['comment_text']\n",
        "\n",
        "# # pp = get_text_hidden_states(text)\n",
        "# marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "# tokenized_text = tokenizer.tokenize(marked_text)\n",
        "# indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "# segments_ids = [1] * len(tokenized_text)\n",
        "# tokens_tensor = torch.tensor([indexed_tokens])\n",
        "# segments_tensors = torch.tensor([segments_ids])\n",
        "# with torch.no_grad():\n",
        "\n",
        "#   outputs = model(tokens_tensor, segments_tensors)\n",
        "#   hidden_states = outputs[2]\n",
        "# pp = [torch.mean(hs, dim=1) for hs in hidden_states]\n",
        "# # tokens_tensor.shape, segments_tensors.shape\n",
        "# len(tokenized_text)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "349"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBmOPW8hJAC7",
        "outputId": "e911655b-aef7-41eb-e189-c0689c2b6332"
      },
      "source": [
        "train_df['comment_text_layers_embeddingds'] = train_df['comment_text'].progress_apply(get_text_hidden_states)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:31<00:00,  4.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdbzxon5RXzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31beeabe-10d4-44f7-e854-cb0638d1bcbf"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "X = [x[0].flatten().numpy() for x in train_df['comment_text_layers_embeddingds'].tolist()]\n",
        "y = train_df['toxic'].tolist()\n",
        "neigh.fit(X, y)\n",
        "# len(X), len(y)\n",
        "\n",
        "np.sum(neigh.predict(X) == y)/len(y)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.937"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ITAnaPU7P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8fGj-0COjWj"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(int(time.time()))\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "from torch import nn, utils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable \n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self._df = df\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self._df.iloc[idx]\n",
        "\n",
        "        search_term = np.array(row['search_term_tokens'])\n",
        "        product_title = np.array(row['product_title_tokens'])\n",
        "\n",
        "   \n",
        "\n",
        "        return row['id'], search_term, product_title, row['relevance_class']\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "NRSLuzN1kqe7",
        "outputId": "b9aef73b-6460-4210-97f6-be26c727afde"
      },
      "source": [
        "train_df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37754</th>\n",
              "      <td>115393</td>\n",
              "      <td>138330</td>\n",
              "      <td>Oakland Living Mississippi Patio Service Cart</td>\n",
              "      <td>service cart</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[101, 9182, 2542, 5900, 19404, 2326, 11122, 102, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[101, 2326, 11122, 102, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ...          search_term_tokens relevance_class\n",
              "37754  115393  138330       ...  [101, 2326, 11122, 102, 0]  0             \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTudx3_9QEOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62da0cc-6871-499c-f947-442314d3729e"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_data_df = train_df[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class', 'relevance']]\n",
        "data_loader = DatasetLoader(train_data_df)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(data_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=True, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "\n",
        "test_df_fixed = test_df[(test_df['search_term_tokens'].map(len) > 0) & (test_df['product_title_tokens'].map(len) > 0)]\n",
        "\n",
        "\n",
        "\n",
        "test_loader = DatasetLoader(test_df_fixed[['id', 'product_title_tokens', 'search_term_tokens', 'relevance_class']])\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(test_loader,\n",
        "                                                 batch_size=BATCH_SIZE, shuffle=False, \n",
        "                                                 num_workers=4,drop_last=False)\n",
        "\n",
        "len(data_loader), len(test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74067, 166693)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "hYKG8QQEAXLS",
        "outputId": "d1f71c8a-7142-47a2-a9e4-c90a5a4e8329"
      },
      "source": [
        "train_data_df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>relevance_class</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39466</th>\n",
              "      <td>120409</td>\n",
              "      <td>[101, 20868, 12173, 2937, 2102, 4293, 3027, 1012, 4658, 2317, 2419, 8164, 2422, 8934, 102]</td>\n",
              "      <td>[101, 4029, 3027, 2419, 102]</td>\n",
              "      <td>2</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... relevance\n",
              "39466  120409  ...  2.33    \n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ti4DjnB3AC2K",
        "outputId": "7dc13d34-2646-42f2-c0ef-871aba6f5cbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>my_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35646</th>\n",
              "      <td>52729</td>\n",
              "      <td>113622</td>\n",
              "      <td>AT&amp;amp;T Trimline Telephone With Memory - Black</td>\n",
              "      <td>at</td>\n",
              "      <td>[amp, &lt;word&gt;, telephon, memori, black]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  product_uid  ... search_term_tokens my_relevance\n",
              "35646  52729  113622       ...  []                 1          \n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg9ZjtvyQYYj"
      },
      "source": [
        "for ids, search_term, product_title, target_relevance_score in test_data_loader:\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAb7Xrshd-Ap"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaU8p0SBalql"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wcUGHjMcBXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PREwU_6bclh"
      },
      "source": [
        "for ids, search_term, product_title, target_relevance_score in train_data_loader:\n",
        "  break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv4iT_xlBNeY"
      },
      "source": [
        "# from transformers import BertConfig\n",
        "\n",
        "# config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "#                                     output_hidden_states=True)\n",
        "\n",
        "# bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                          config=config)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDYpQzBNRhe3",
        "outputId": "2d54efad-3dd8-4367-ba4f-655f8436b92f"
      },
      "source": [
        "# bb = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_of_labels = 10)\n",
        "# tt = torch.from_numpy(np.array(tokenize(\"he weny home for dinner\", 10)))\n",
        "\n",
        "# dd = tokenizer.encode_plus(\n",
        "#             text,\n",
        "#             max_length = max_length, \n",
        "#             padding = 'max_length',\n",
        "#             truncation = True, \n",
        "#             return_attention_mask = True, \n",
        "#             add_special_tokens = True, \n",
        "#             )\n",
        "\n",
        "# x1 = torch.from_numpy(np.ndarray([]]))\n",
        "# x2 = torch.from_numpy(np.array([dd['attention_mask']]))\n",
        "\n",
        "\n",
        "# torch.tensor(product_title)\n",
        "i1 = torch.tensor([[7,8,9],[10,11,12]])\n",
        "bert_model(i1)['hidden_states'][-1][:, -1,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnTv4wTQRn--"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "class RelevanceModel(nn.Module):\n",
        "\n",
        "  def __init__(self, num_of_classes):\n",
        "    super(RelevanceModel, self).__init__()\n",
        "    config = BertConfig.from_pretrained(\"bert-base-uncased\",\n",
        "                                    output_hidden_states=True)\n",
        "\n",
        "    self.bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "\n",
        "    for param in self.bert_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    self.fc = nn.Linear(768 * 2, num_of_classes)\n",
        "\n",
        "  def  forward(self, queries, titles):\n",
        "    encoded_queries = self.bert_model(queries)['hidden_states'][-1][:, -1,:]\n",
        "    encoded_titles = self.bert_model(titles)['hidden_states'][-1][:, -1,:]\n",
        "\n",
        "    out = torch.cat((encoded_queries, encoded_titles), 1)\n",
        "\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out \n",
        "\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    nn.init.uniform_(self.fc.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VMlZG21ZCK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4559ba7-c22e-4aeb-d0b1-039442bf9236"
      },
      "source": [
        "\n",
        "# # for x in model.parameters():\n",
        "# #   if not x.is_cuda:\n",
        "# #     print(x) \n",
        "\n",
        "# # e1 = EncoderModel(len(vocab)).to(device)\n",
        "# # r = e1(product_title.to(device), product_title_length)\n",
        "# output.shape, product_title_length\n",
        "# #output = r \n",
        "\n",
        "# #8\n",
        "# #out_forward = output[range(len(output)), lengths - 1, :self.embedding_dim ]\n",
        "\n",
        "# # output[range(len(output)), product_title_length - 1, :300][0]\n",
        "# product_title_length\n",
        "#output[0][14], product_title_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14, 12, 10, 15,  8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpN5VHYENQJ",
        "outputId": "5fdb6a9e-27b4-4018-d550-1631392db324"
      },
      "source": [
        "# output[0][13][300:]\n",
        "# output[:, 0, 300 :].shape, output[:, 0,]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 300]), torch.Size([5, 15, 600]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFR-SouFR5PB"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# query_encoder = EncoderModel(len(vocab))\n",
        "# title_encoder = EncoderModel(len(vocab))\n",
        "\n",
        "# query_encoder.reset_parameters()\n",
        "# title_encoder.reset_parameters()\n",
        "\n",
        "# #search_term, search_term_length, product_title, product_title_length\n",
        "# query_encoded = query_encoder(search_term, search_term_length)\n",
        "# title_encoded = query_encoder(product_title, product_title_length)\n",
        "# torch.cat((query_encoded, title_encoded), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWnKAQe_WQyF",
        "outputId": "dfae549c-9aa3-45c9-b1a4-6af73790b088"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEpPTJGLoi1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbaa3c02-8434-4e00-fb31-0cf81988a459"
      },
      "source": [
        "counts = train_df.groupby(\"relevance_class\").size().reset_index()\n",
        "#total = np.sum(counts[0].tolist())\n",
        "\n",
        "# [(row['relevance_class'],  row[0]/total) for (_, row) in counts[['relevance_class', 0]].iterrows()]\n",
        "\n",
        "total = 0.0\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  total += row[0]\n",
        "total \n",
        "weights = []\n",
        "print(total)\n",
        "for _, row in counts[['relevance_class', 0]].iterrows():\n",
        "  #print(row[0])\n",
        "  cls = row['relevance_class']\n",
        "  # print((cls, row[0]))\n",
        "  sampeples_weight = (row[0] / total)\n",
        "  required_weight = 1.0/len(counts)\n",
        "\n",
        "  # print('-----')\n",
        "  # print(sampeples_weight)\n",
        "  # print(required_weight)\n",
        "  x = required_weight/sampeples_weight\n",
        "  # print(x)\n",
        "\n",
        "  weight_for_class_a = (1 / row[0]) * total/len(counts)\n",
        "  \n",
        "\n",
        "   \n",
        "  # weight = x * sampeples_weight\n",
        "  # print(weight)\n",
        "  # print('-------')\n",
        "\n",
        "  weights.append((cls, x))\n",
        "\n",
        "\n",
        "\n",
        "weights = sorted(weights, key = lambda x: x[0])\n",
        "weights = [w[1] for w in weights]\n",
        "weights\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74067.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2979064856711916,\n",
              " 299.8663967611337,\n",
              " 0.35476099243222536,\n",
              " 0.37478368230900794,\n",
              " 0.4857170962030298,\n",
              " 2.7066325598392105,\n",
              " 0.8403335602450647,\n",
              " 1.8953631199140182,\n",
              " 1424.3653846153848,\n",
              " 517.951048951049,\n",
              " 633.0512820512821,\n",
              " 1139.4923076923078,\n",
              " 517.951048951049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu2VvCcmyVy1",
        "outputId": "6a47000e-e476-4ffd-f824-46b399437436"
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2979064856711916,\n",
              " 299.8663967611337,\n",
              " 0.35476099243222536,\n",
              " 0.37478368230900794,\n",
              " 0.4857170962030298,\n",
              " 2.7066325598392105,\n",
              " 0.8403335602450647,\n",
              " 1.8953631199140182,\n",
              " 1424.3653846153848,\n",
              " 517.951048951049,\n",
              " 633.0512820512821,\n",
              " 1139.4923076923078,\n",
              " 517.951048951049]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEK66lCTIt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85810dfd-3d41-41db-9d99-611e85c1dc7d"
      },
      "source": [
        "model = RelevanceModel(num_of_classes)\n",
        "model.reset_parameters()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "class_weights=torch.tensor(weights,dtype=torch.float)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight = class_weights, reduction='sum').to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJiU_nc8WP8l",
        "outputId": "7037bf4d-823f-40ae-f8c6-ce81a8a99388"
      },
      "source": [
        "class_weights[2].numpy(), weights[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(0.35470936, dtype=float32), 0.3547093708384031)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knnaKV2bWAA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b9c6a0-2086-4eb4-eac8-a7dcb909e545"
      },
      "source": [
        "\n",
        "model.train()\n",
        "\n",
        "for epoc in range(1000):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  counter = 0.0\n",
        "\n",
        "  for ids, search_term, product_title, target_relevance_score  in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    target_relevance_score = Variable(target_relevance_score).long().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    scores = model(search_term, product_title)\n",
        "    loss = criterion(scores, target_relevance_score)\n",
        "\n",
        "    \n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    counter += search_term.shape[0]\n",
        "  #   break\n",
        "  \n",
        "  # break\n",
        "  \n",
        "  print('epoc {} loss {} counter {}'.format(epoc, running_loss/counter, counter))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoc 0 loss 6.462625524785163 counter 74067.0\n",
            "epoc 1 loss 5.558418554361422 counter 74067.0\n",
            "epoc 2 loss 4.873910256250517 counter 74067.0\n",
            "epoc 3 loss 5.541181676479559 counter 74067.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j23Rz5eLleqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cbe8a2-2a16-4070-9b49-439552699ad3"
      },
      "source": [
        "# mse_loss(scores.view(1, -1), target_relevance_score.view(1, -1))\n",
        "# counter\n",
        "torch.argmax(scores, dim=1), target_relevance_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3, 6, 3, 4, 0, 2, 7, 6, 2, 0, 6, 2, 7, 4, 0, 2, 2, 2, 7, 6, 2, 0, 6, 6,\n",
              "         3, 3, 2, 3, 4, 4, 4, 2, 3, 3, 0, 4, 2, 2, 2, 2, 2, 3, 0, 4, 0, 4, 2, 6,\n",
              "         0, 2, 2, 4, 2, 7, 3, 6, 6, 2, 0, 5, 7, 0, 3, 2], device='cuda:0'),\n",
              " tensor([3, 6, 3, 4, 0, 2, 7, 6, 2, 0, 0, 2, 7, 4, 4, 4, 2, 2, 7, 3, 2, 0, 6, 6,\n",
              "         3, 3, 2, 3, 4, 0, 4, 2, 3, 3, 0, 3, 3, 2, 2, 2, 7, 3, 0, 4, 3, 4, 3, 6,\n",
              "         0, 2, 2, 4, 2, 7, 3, 6, 6, 2, 0, 5, 7, 0, 3, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B5hKqKGe-y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518aaaa8-6e11-4e0a-a503-d463b5bda17b"
      },
      "source": [
        "scores.detach().cpu().numpy() , target_relevance_score.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2.4221616],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.4221613],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.4221616],\n",
              "        [2.4221616],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ],\n",
              "        [2.390806 ]], dtype=float32),\n",
              " array([2.67, 2.  , 2.  , 2.  , 1.67, 1.67, 3.  , 2.67, 1.33, 3.  , 3.  ,\n",
              "        2.33, 2.33, 3.  , 3.  , 2.67, 2.33, 2.67, 3.  , 2.33, 3.  , 2.  ,\n",
              "        2.  , 3.  , 1.67, 2.67, 3.  , 3.  , 3.  , 2.33, 3.  , 2.67, 2.67,\n",
              "        3.  , 3.  , 2.67, 1.  , 2.  , 3.  , 2.33, 2.  , 2.  , 2.  , 2.33,\n",
              "        1.  , 1.67, 2.33, 1.67, 2.  , 1.67, 3.  , 1.67, 2.67, 2.  , 2.33,\n",
              "        3.  , 2.33, 3.  , 3.  , 3.  , 1.67, 2.67, 1.  , 2.33]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTBEJ3CasIks",
        "outputId": "2417d084-a94d-400a-9c14-5b7addf87a4e"
      },
      "source": [
        "r1, scores.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, torch.Size([64, 13]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgvd78qCkW8m"
      },
      "source": [
        "\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, search_term_length, product_title, product_title_length, target_relevance_score in train_data_loader:\n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    \n",
        "\n",
        "    scores = model(search_term, product_title, search_term_length,  product_title_length)\n",
        "\n",
        "    test_scores.extend(scores.detach().cpu().numpy().flatten().tolist())\n",
        "    test_ids.extend(ids.numpy().tolist())\n",
        "    tt.extend(target_relevance_score.numpy().tolist())\n",
        "\n",
        "    break\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdxRw_b_LTq"
      },
      "source": [
        "for _ in test_data_loader:\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYqvaAVNk6pY",
        "outputId": "af0cc2b4-97d8-4c87-d719-aea61982e064"
      },
      "source": [
        "model.eval()\n",
        "test_scores = []\n",
        "test_ids =[]\n",
        "tt = []\n",
        "test_data = []\n",
        "with torch.no_grad():\n",
        "  for ids, search_term, search_term_length, product_title, product_title_length, target_relevance_score in test_data_loader:\n",
        "     \n",
        "    search_term = Variable(search_term).to(device)\n",
        "    product_title = Variable(product_title).to(device)\n",
        "    \n",
        "\n",
        "    scores = model(search_term, product_title, search_term_length,  product_title_length)\n",
        "\n",
        "    vals = torch.argmax(scores, dim=1).flatten().detach().cpu().numpy().tolist()\n",
        "    ids = ids.numpy().tolist()\n",
        "\n",
        "    test_data.extend(zip(ids, vals))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5061e734d0>\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k-HHAoXDZCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce45f3e5-ac44-4e64-8bec-8e2353ce7fe0"
      },
      "source": [
        "# 166693, len(test_data), len(test_df)\n",
        "all_ids = {x for (x, _) in test_data}\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "  if row['id'] not in all_ids:\n",
        "    test_data.append((row['id'], 1))\n",
        "    \n",
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCkYUGAMgvqF"
      },
      "source": [
        "pd.DataFrame([(id, cls_to_score[cls]) for (id, cls) in test_data], columns = [\"id\", \"relevance\"]).to_csv(\"test_res.csv\", index=  False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6XfNPdDKx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "18c4fd2a-77b5-40dc-b802-71af0983f330"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('test_res.csv') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f1fa6b5d-807b-4df1-b82c-3b19b4724bfd\", \"test_res.csv\", 1850918)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrqzbWUODp-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "3afbb0ac-512f-4b76-e5a1-a8d59f96d5fb"
      },
      "source": [
        "test_df.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>product_title_tokens</th>\n",
              "      <th>search_term_tokens</th>\n",
              "      <th>my_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107023</th>\n",
              "      <td>159578</td>\n",
              "      <td>161578</td>\n",
              "      <td>Speedi-Products 7 in. 24-Gauge Single Wall Stove Pipe 90 Degree Adjustable Elbow in Black Matte</td>\n",
              "      <td>singel wall stove pipe</td>\n",
              "      <td>[speedi, product, #, ##, gaug, singl, wall, stove, pipe, ##, degre, adjust, elbow, black, matt]</td>\n",
              "      <td>[singel, wall, stove, pipe]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  product_uid  ...           search_term_tokens my_relevance\n",
              "107023  159578  161578       ...  [singel, wall, stove, pipe]  1          \n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    }
  ]
}