{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7vz0__2J7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a3a096-83a4-414e-84ef-535cbd3e017b"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H9Z4iZ2XPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5356024d-8abc-48b9-83a0-90225d8dadb2"
      },
      "source": [
        "from google.colab import files\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List \n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn, utils\n",
        "from torch.utils.data import TensorDataset, RandomSampler, Dataset\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "h0uiWBjK2jtU",
        "outputId": "a3f661ba-c470-4868-b3a3-57d8f49ae7f4"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad27b448-2494-4f97-bb8d-3bf207b6455d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ad27b448-2494-4f97-bb8d-3bf207b6455d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gabib3b\",\"key\":\"817d7e169db4cbef867b22907320144c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFkqZ-42pXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a785c0-0e0d-4655-80dd-cd85d0448c2e"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_labels.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnbKHLMmrX5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c877249-64b7-44e7-fa1a-f0e5c0afb921"
      },
      "source": [
        "! ls  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'kaggle (1).json'   sample_submission.csv.zip   train.csv\n",
            " kaggle.json\t    test.csv.zip\t        train.csv.zip\n",
            " sample_data\t    test_labels.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjfnT_W9EE-p",
        "outputId": "e311d041-ca62-43c1-b1e3-872c518d622b"
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.csv.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWqYvAjmEb34",
        "outputId": "021081ea-75ab-443b-c809-cdfc244bf266"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'kaggle (1).json'   sample_submission.csv.zip   train.csv\n",
            " kaggle.json\t    test.csv.zip\t        train.csv.zip\n",
            " sample_data\t    test_labels.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5kTCLu3wPp"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")[['id', 'comment_text', 'toxic']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN_i6XAGgR0W",
        "outputId": "272e3e81-1226-445b-969d-4596cfd49734"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   id            159571 non-null  object\n",
            " 1   comment_text  159571 non-null  object\n",
            " 2   toxic         159571 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "rg4nBRckEjh0",
        "outputId": "22a60e4e-f0c7-4f58-b32d-9eb67216c082"
      },
      "source": [
        "df.sample(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69395</th>\n",
              "      <td>b9a155884df4de57</td>\n",
              "      <td>Please stop with your vandalizing of the Jim C...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28520</th>\n",
              "      <td>4b85fdafee74b2b1</td>\n",
              "      <td>\"::::::::1) The \"\"Dual-pane vs. tri-pane\"\" arg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14889</th>\n",
              "      <td>2757fcd573baa8af</td>\n",
              "      <td>that requires a response</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ... toxic\n",
              "69395  b9a155884df4de57  ...     0\n",
              "28520  4b85fdafee74b2b1  ...     0\n",
              "14889  2757fcd573baa8af  ...     0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5-wJY-sCCT9",
        "outputId": "6e6394fd-c162-449d-961c-21edc930947b"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159571"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lxkLY0FTFOUD",
        "outputId": "2103aa3b-bcd2-44ae-c822-45703f32275e"
      },
      "source": [
        "ax = sns.countplot(x=\"toxic\", data=df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2V7clK9x-oW",
        "outputId": "b4596562-c88b-4924-ec70-23e6366fabd9"
      },
      "source": [
        "df.rename(columns={'toxic': 'target'}, inplace = True)\n",
        "\n",
        "train_df, validation_df = train_test_split(df, test_size = 0.2)\n",
        "train_df.shape[0], validation_df.shape[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127656, 31915)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hiwyptrtlf"
      },
      "source": [
        "class BaseClassifier(ABC):\n",
        "  \n",
        "  def __init__(self, bert_model, tokenizer):\n",
        "    self._bert_model = bert_model\n",
        "    self._bert_model.eval()\n",
        "    self._tokenizer = tokenizer\n",
        "\n",
        "  @abstractmethod\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    pass \n",
        "\n",
        "  @abstractmethod\n",
        "  def predict(self, df: pd.DataFrame):\n",
        "    pass \n",
        "  \n",
        "  def text_to_tokens_ids(self, text):\n",
        "\n",
        "    marked_text = CLS + text + SEP\n",
        "    tokenized_text = self._tokenizer.tokenize(marked_text)[0: MAX_NUMBER_OF_WORDS_IN_SENTENSE]\n",
        "    indexed_tokens = self._tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    return indexed_tokens\n",
        "\n",
        "  def text_to_sentense_embeddingds(self, text: str, embeddings_layer: int):\n",
        "    indexed_tokens = self.text_to_tokens_ids(text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "    segments_ids = [1] * len(indexed_tokens)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = self._bert_model(tokens_tensor, segments_tensors)\n",
        "      hidden_states = outputs[2]\n",
        "      \n",
        "    return torch.mean(hidden_states[embeddings_layer], dim=1).detach().cpu().numpy().flatten() if embeddings_layer is not None else hidden_states\n",
        "  \n",
        "  def evaluate(self, df):\n",
        "    predictions = self.predict(df)\n",
        "    targets = df['target'].tolist()\n",
        "\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(targets, predictions, average='binary')\n",
        "\n",
        "    return pd.DataFrame([(precision, recall, fscore)], columns = ['precision','recall', 'fscore'])\n",
        "\n",
        "  \n",
        "class NearestNeiborClassifier(BaseClassifier):\n",
        "  def __init__(self, bert_model, tokenizer, embeddings_layer, n_neighbors):\n",
        "    BaseClassifier.__init__(self, bert_model, tokenizer)\n",
        "    self._embeddings_layer = embeddings_layer\n",
        "    self._n_neighbors = n_neighbors\n",
        "    self._model = None\n",
        "\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    \n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    y = df['target'].tolist()\n",
        "\n",
        "    self._model = KNeighborsClassifier(n_neighbors = self._n_neighbors)\n",
        "    self._model.fit(X, y)\n",
        "\n",
        "  def predict(self, df):\n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    \n",
        "    return self._model.predict(X)\n",
        "  \n",
        "\n",
        "class TorchClassifier(BaseClassifier):\n",
        "  def __init__(self, bert_model, tokenizer, embeddings_layer, n_neighbors):\n",
        "    BaseClassifier.__init__(self, bert_model, tokenizer)\n",
        "    self._embeddings_layer = embeddings_layer\n",
        "    self._n_neighbors = n_neighbors\n",
        "    self._model = None\n",
        "\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    \n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    y = df['target'].tolist()\n",
        "\n",
        "    self._model = KNeighborsClassifier(n_neighbors = self._n_neighbors)\n",
        "    self._model.fit(X, y)\n",
        "\n",
        "  def predict(self, df):\n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    \n",
        "    return self._model.predict(X)\n",
        "  \n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddI9xpimvT86",
        "outputId": "c98b6728-5c8e-4866-9994-cff8fa704042"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True).to(device)\n",
        "\n",
        "bert.eval()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS5RDSfjAzd8",
        "outputId": "38f8ad4d-e16e-499f-e6e2-b2a12b229d01"
      },
      "source": [
        "CLS = \"{} \".format(tokenizer.cls_token)\n",
        "SEP = \" {}\".format(tokenizer.sep_token)\n",
        "MAX_NUMBER_OF_WORDS_IN_SENTENSE = 512\n",
        "SEP, CLS"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' [SEP]', '[CLS] ')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "YBUx2_Y5-Gy9",
        "outputId": "983df53f-68d5-4965-838f-a2816a69f701"
      },
      "source": [
        "N_NEIGHBORS = 3\n",
        "\n",
        "nearestNeiborClassifier = NearestNeiborClassifier(bert, tokenizer, 12, N_NEIGHBORS)\n",
        "nearestNeiborClassifier.fit(train_df)\n",
        "nearestNeiborClassifier.evaluate(validation_df)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:02<00:00, 74.15it/s]\n",
            "100%|██████████| 200/200 [00:02<00:00, 85.44it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>fscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  recall  fscore\n",
              "0        0.0     0.0     0.0"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8xbBAO4Oh5j"
      },
      "source": [
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self._df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        row = self._df.iloc[idx]\n",
        "        return row['id'], row['comment_text_tokens_ids'], row['target'] if 'target' in self._df.columns else -1"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz6z_dmAOrOs"
      },
      "source": [
        "def group_rows(rows):\n",
        "\n",
        "    max_length = np.max([len(tokenes_ids) for _, tokenes_ids, _ in rows])\n",
        "\n",
        "    ids = [id for id, _, _ in rows]\n",
        "\n",
        "    tokenes_ids = torch.LongTensor([np.concatenate([tokenes_ids, np.repeat(tokenizer.pad_token_id, max_length - len(tokenes_ids))])\n",
        "                   for id, tokenes_ids, target in rows])\n",
        "\n",
        "\n",
        "    targets = [target for _, _, target in rows]\n",
        "\n",
        "    masks = torch.LongTensor([np.concatenate([np.repeat(1, len(tokenes_ids)), np.repeat(0, max_length - len(tokenes_ids))])\n",
        "          for _, tokenes_ids, _ in rows])\n",
        "    \n",
        "    return ids, tokenes_ids, masks, torch.FloatTensor(targets).reshape(-1, 1)\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRFYXTYIO601"
      },
      "source": [
        "class RelevanceModel(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, embeddings_layer):\n",
        "\n",
        "        super(RelevanceModel, self).__init__()\n",
        "\n",
        "        self._embeddings_layer = embeddings_layer\n",
        "        self._bert = bert\n",
        "\n",
        "        self._bert.eval()\n",
        "\n",
        "        for param in self._bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.af1 = nn.LeakyReLU()\n",
        "        self.fc1 = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, tokens, attention_mask):\n",
        "        hidden_states = self._bert(tokens, attention_mask)[2]\n",
        "\n",
        "\n",
        "        sentense_embeddingds = torch.mean(hidden_states[self._embeddings_layer], dim=1)\n",
        "\n",
        "        out = self.af1(sentense_embeddingds)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        initrange = 0.5\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        return self"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9jQmEZjPJU_"
      },
      "source": [
        "class DeepModel(BaseClassifier):\n",
        "\n",
        "\n",
        "    def __init__(self, bert, tokenizer, embeddings_layer, batch_size,\n",
        "                 prediction_threshold, learnning_rate = 0.001):\n",
        "        BaseClassifier.__init__(self, bert, tokenizer)\n",
        "        bert.to(device)\n",
        "        self._model  = RelevanceModel(bert, embeddings_layer).reset_parameters()\n",
        "        self._model.to(device)\n",
        "        self._batch_size = batch_size\n",
        "        self._prediction_threshold = prediction_threshold\n",
        "        self._learnning_rate = learnning_rate\n",
        "\n",
        "    def _calc_positive_weight(self, df: pd.DataFrame) -> float:\n",
        "      weights = compute_class_weight('balanced', np.unique(train_df.target),  train_df.target)\n",
        "      pos_weight = weights[1]/weights[0]\n",
        "      return pos_weight   \n",
        "\n",
        "\n",
        "    def _preprocessing(self, df):\n",
        "      df['comment_text_tokens_ids'] = df['comment_text'].progress_apply(lambda text: self.text_to_tokens_ids(text))\n",
        "\n",
        "    def fit(self, df: pd.DataFrame):\n",
        "\n",
        "        self._model.train()\n",
        "\n",
        "        positive_weight = self._calc_positive_weight(df)\n",
        "        pos_weights_tensor = torch.Tensor([positive_weight])\n",
        "       \n",
        "        self._preprocessing(df)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self._model.parameters(), lr=self._learnning_rate)\n",
        "        train_dataset = DatasetLoader(df)\n",
        "        sampler = RandomSampler(train_dataset)\n",
        "\n",
        "        train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                        batch_size=self._batch_size,\n",
        "                                                        shuffle=False,\n",
        "                                                        num_workers=4,\n",
        "                                                        drop_last=False,\n",
        "                                                        sampler=sampler,\n",
        "                                                        collate_fn=group_rows)\n",
        "\n",
        "        loss_fn  = nn.BCEWithLogitsLoss(pos_weight = pos_weights_tensor).to(device)\n",
        "\n",
        "        for batch in range(1000):\n",
        "          total_loss = 0.0\n",
        "          for ids, tokends_ids, attention_mask, targets in train_data_loader:\n",
        "                \n",
        "              tokends_ids = tokends_ids.to(device)\n",
        "              attention_mask = attention_mask.to(device)\n",
        "              targets = targets.to(device)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              output = self._model(tokends_ids, attention_mask)\n",
        "              loss = loss_fn(output, targets)\n",
        "    \n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              total_loss += loss.item()\n",
        "            \n",
        "          print('batch {} loss {}'.format(batch, total_loss/len(train_dataset)))\n",
        "\n",
        "    def predict(self, df: pd.DataFrame):\n",
        "\n",
        "      self._preprocessing(df)\n",
        "      \n",
        "      self._model.eval()\n",
        "\n",
        "      predict_dataset_loader = DatasetLoader(df)\n",
        "\n",
        "      predict_data_loader = torch.utils.data.DataLoader(predict_dataset_loader,\n",
        "                                                              batch_size=self._batch_size,\n",
        "                                                              shuffle=False,\n",
        "                                                              num_workers=4,\n",
        "                                                              drop_last=False,\n",
        "                                                              collate_fn=group_rows)\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        predictions = {}\n",
        "        \n",
        "        for ids, tokends_ids, attention_mask, _ in predict_data_loader:\n",
        "          tokends_ids = tokends_ids.to(device)\n",
        "          attention_mask = attention_mask.to(device)\n",
        "          \n",
        "          logit = dm._model(tokends_ids, attention_mask)\n",
        "\n",
        "          probs = torch.sigmoid(logit).detach().cpu().numpy().flatten()\n",
        "          batch_predictions = probs > self._prediction_threshold\n",
        "\n",
        "          for id, prediction in zip(ids, batch_predictions):\n",
        "            predictions[id] = prediction \n",
        "          \n",
        "      return df['id'].apply(lambda id: predictions[id]).tolist()\n",
        "      "
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woWgCg3OPM1X"
      },
      "source": [
        "dm = DeepModel(bert, tokenizer, -1, 32, 0.65)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd2BRTnoszmH",
        "outputId": "52da7a11-9ad9-4370-8119-666b8f1eb551"
      },
      "source": [
        "dm.fit(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 127656/127656 [03:39<00:00, 581.71it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ITAnaPU7P"
      },
      "source": [
        ""
      ]
    }
  ]
}