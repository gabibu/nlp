{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7vz0__2J7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e944e22-0f57-4705-90d2-f49db20e42fb"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install transformers\n",
        "!pip install unidecode\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 58.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 70.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H9Z4iZ2XPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411a7975-1b9c-4b75-b4f7-bd39a856d972"
      },
      "source": [
        "from google.colab import files\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List \n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn, utils\n",
        "from torch.utils.data import TensorDataset, RandomSampler, Dataset\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "h0uiWBjK2jtU",
        "outputId": "1a7ad465-46d0-49df-b329-f0a9f0a84759"
      },
      "source": [
        "#upload kaggle.json file with permission ro download jigsaw-toxic-comment-classification-challenge dataset\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96a772e3-b456-4b71-a93a-de062e25f2bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-96a772e3-b456-4b71-a93a-de062e25f2bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gabib3b\",\"key\":\"817d7e169db4cbef867b22907320144c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFkqZ-42pXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fd7375-1be4-4513-de55-d83c35663ce1"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "test_labels.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnbKHLMmrX5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a54ac3-d101-471c-e469-91bca1e24210"
      },
      "source": [
        "! ls  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'kaggle (1).json'   sample_submission.csv.zip   train.csv\n",
            " kaggle.json\t    test.csv.zip\t        train.csv.zip\n",
            " sample_data\t    test_labels.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjfnT_W9EE-p",
        "outputId": "e924a318-b10a-469b-fd80-25a2d868379e"
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.csv.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWqYvAjmEb34",
        "outputId": "e063234c-3bb9-4169-9563-152047935fce"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'kaggle (1).json'   sample_submission.csv.zip   train.csv\n",
            " kaggle.json\t    test.csv.zip\t        train.csv.zip\n",
            " sample_data\t    test_labels.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIIqvWYAuRxa"
      },
      "source": [
        "SAMPLE_SIZE = 100000"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z5kTCLu3wPp"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")[['id', 'comment_text', 'toxic']].sample(SAMPLE_SIZE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN_i6XAGgR0W",
        "outputId": "22d93bc1-8f00-4e69-d2dd-c540e5c488d2"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 100000 entries, 157641 to 80559\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   id            100000 non-null  object\n",
            " 1   comment_text  100000 non-null  object\n",
            " 2   target        100000 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 3.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "rg4nBRckEjh0",
        "outputId": "6fa58107-64b9-46f0-dda8-31c325616a15"
      },
      "source": [
        "df.sample(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28752</th>\n",
              "      <td>4c283d31bb71e900</td>\n",
              "      <td>:Template:Picasso works\\nAs posted on User tal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125928</th>\n",
              "      <td>a18a1d1ac1983db4</td>\n",
              "      <td>{{unblock| Oxymoron is a moron in an Oxymoron ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156478</th>\n",
              "      <td>cec912b114c460c4</td>\n",
              "      <td>. Instead of using and abusing administrator p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... toxic\n",
              "28752   4c283d31bb71e900  ...     0\n",
              "125928  a18a1d1ac1983db4  ...     1\n",
              "156478  cec912b114c460c4  ...     0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lxkLY0FTFOUD",
        "outputId": "9726d8b1-1aa1-458e-9a1f-c35879a99b3c"
      },
      "source": [
        "ax = sns.countplot(x=\"toxic\", data=df)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2V7clK9x-oW",
        "outputId": "3b453add-3e62-4963-f121-8981adc63b89"
      },
      "source": [
        "df.rename(columns={'toxic': 'target'}, inplace = True)\n",
        "\n",
        "train_df, validation_df = train_test_split(df, test_size = 0.2)\n",
        "train_df.shape[0], validation_df.shape[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 20000)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLui7QIWupVk",
        "outputId": "db86834a-45c4-408b-849f-f9352343399a"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True).to(device)\n",
        "\n",
        "bert.eval()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9SG0iZKumAK",
        "outputId": "6c983eaf-ddc8-46d5-f0dc-af53d4bd01eb"
      },
      "source": [
        "CLS = \"{} \".format(tokenizer.cls_token)\n",
        "SEP = \" {}\".format(tokenizer.sep_token)\n",
        "MAX_NUMBER_OF_WORDS_IN_SENTENSE = 512\n",
        "SEP, CLS"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' [SEP]', '[CLS] ')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hiwyptrtlf"
      },
      "source": [
        "class BaseClassifier(ABC):\n",
        "  \n",
        "  def __init__(self, bert_model, tokenizer):\n",
        "    self._bert_model = bert_model\n",
        "    self._bert_model.eval()\n",
        "    self._tokenizer = tokenizer\n",
        "\n",
        "  @abstractmethod\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    pass \n",
        "\n",
        "  @abstractmethod\n",
        "  def predict(self, df: pd.DataFrame):\n",
        "    pass \n",
        "  \n",
        "  def text_to_tokens_ids(self, text):\n",
        "\n",
        "    marked_text = CLS + text + SEP\n",
        "    tokenized_text = self._tokenizer.tokenize(marked_text)[0: MAX_NUMBER_OF_WORDS_IN_SENTENSE]\n",
        "    indexed_tokens = self._tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    return indexed_tokens\n",
        "\n",
        "  def text_to_sentense_embeddingds(self, text: str, embeddings_layer: int):\n",
        "    indexed_tokens = self.text_to_tokens_ids(text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "    segments_ids = [1] * len(indexed_tokens)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = self._bert_model(tokens_tensor, segments_tensors)\n",
        "      hidden_states = outputs[2]\n",
        "      \n",
        "    return torch.mean(hidden_states[embeddings_layer], dim=1).detach().cpu().numpy().flatten() if embeddings_layer is not None else hidden_states\n",
        "  \n",
        "  def evaluate(self, df):\n",
        "    predictions = self.predict(df)\n",
        "    targets = df['target'].tolist()\n",
        "\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(targets, predictions, average='binary')\n",
        "\n",
        "    return pd.DataFrame([(precision, recall, fscore)], columns = ['precision','recall', 'fscore'])\n",
        "\n",
        "  \n",
        "class NearestNeiborClassifier(BaseClassifier):\n",
        "  def __init__(self, bert_model, tokenizer, embeddings_layer, n_neighbors):\n",
        "    BaseClassifier.__init__(self, bert_model, tokenizer)\n",
        "    self._embeddings_layer = embeddings_layer\n",
        "    self._n_neighbors = n_neighbors\n",
        "    self._model = None\n",
        "\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    \n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    y = df['target'].tolist()\n",
        "\n",
        "    self._model = KNeighborsClassifier(n_neighbors = self._n_neighbors)\n",
        "    self._model.fit(X, y)\n",
        "\n",
        "  def predict(self, df):\n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    \n",
        "    return self._model.predict(X)\n",
        "  \n",
        "\n",
        "class TorchClassifier(BaseClassifier):\n",
        "  def __init__(self, bert_model, tokenizer, embeddings_layer, n_neighbors):\n",
        "    BaseClassifier.__init__(self, bert_model, tokenizer)\n",
        "    self._embeddings_layer = embeddings_layer\n",
        "    self._n_neighbors = n_neighbors\n",
        "    self._model = None\n",
        "\n",
        "  def fit(self, df: pd.DataFrame):\n",
        "    \n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    y = df['target'].tolist()\n",
        "\n",
        "    self._model = KNeighborsClassifier(n_neighbors = self._n_neighbors)\n",
        "    self._model.fit(X, y)\n",
        "\n",
        "  def predict(self, df):\n",
        "    X = df['comment_text'].progress_apply(lambda text: self.text_to_sentense_embeddingds(text, self._embeddings_layer)).tolist()\n",
        "    \n",
        "    return self._model.predict(X)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8xbBAO4Oh5j"
      },
      "source": [
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self._df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        row = self._df.iloc[idx]\n",
        "        return row['id'], row['comment_text_tokens_ids'], row['target'] if 'target' in self._df.columns else -1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz6z_dmAOrOs"
      },
      "source": [
        "def group_rows(rows):\n",
        "\n",
        "    max_length = np.max([len(tokenes_ids) for _, tokenes_ids, _ in rows])\n",
        "\n",
        "    ids = [id for id, _, _ in rows]\n",
        "\n",
        "    tokenes_ids = torch.LongTensor([np.concatenate([tokenes_ids, np.repeat(tokenizer.pad_token_id, max_length - len(tokenes_ids))])\n",
        "                   for id, tokenes_ids, target in rows])\n",
        "\n",
        "\n",
        "    targets = [target for _, _, target in rows]\n",
        "\n",
        "    masks = torch.LongTensor([np.concatenate([np.repeat(1, len(tokenes_ids)), np.repeat(0, max_length - len(tokenes_ids))])\n",
        "          for _, tokenes_ids, _ in rows])\n",
        "    \n",
        "    return ids, tokenes_ids, masks, torch.FloatTensor(targets).reshape(-1, 1)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRFYXTYIO601"
      },
      "source": [
        "class RelevanceModel(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, embeddings_layer):\n",
        "\n",
        "        super(RelevanceModel, self).__init__()\n",
        "\n",
        "        self._embeddings_layer = embeddings_layer\n",
        "        self._bert = bert\n",
        "\n",
        "        self._bert.eval()\n",
        "\n",
        "        for param in self._bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.af1 = nn.LeakyReLU()\n",
        "        self.fc1 = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, tokens, attention_mask):\n",
        "        \n",
        "        hidden_states = self._bert(tokens, attention_mask)[2]\n",
        "\n",
        "        sentense_embeddingds = torch.mean(hidden_states[self._embeddings_layer], dim=1)\n",
        "\n",
        "        out = self.af1(sentense_embeddingds)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      \n",
        "        initrange = 0.5\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        return self"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9jQmEZjPJU_"
      },
      "source": [
        "class DeepModel(BaseClassifier):\n",
        "\n",
        "    def __init__(self, bert, tokenizer, embeddings_layer, batch_size,\n",
        "                 prediction_threshold, learnning_rate = 0.001,\n",
        "                 number_of_epocs = 1000):\n",
        "        BaseClassifier.__init__(self, bert, tokenizer)\n",
        "        bert.to(device)\n",
        "        self._model  = RelevanceModel(bert, embeddings_layer).reset_parameters()\n",
        "        self._model.to(device)\n",
        "        self._batch_size = batch_size\n",
        "        self._prediction_threshold = prediction_threshold\n",
        "        self._learnning_rate = learnning_rate\n",
        "        self._number_of_epocs = number_of_epocs\n",
        "\n",
        "    def _calc_positive_weight(self, df: pd.DataFrame) -> float:\n",
        "      weights = compute_class_weight('balanced', np.unique(train_df.target),  train_df.target)\n",
        "      pos_weight = weights[1]/weights[0]\n",
        "\n",
        "      return pos_weight   \n",
        "\n",
        "\n",
        "    def _preprocessing(self, df: pd.DataFrame):\n",
        "      df['comment_text_tokens_ids'] = df['comment_text'].progress_apply(lambda text: self.text_to_tokens_ids(text))\n",
        "\n",
        "    def fit(self, df: pd.DataFrame):\n",
        "\n",
        "        self._model.train()\n",
        "\n",
        "        positive_weight = self._calc_positive_weight(df)\n",
        "        pos_weights_tensor = torch.Tensor([positive_weight])\n",
        "       \n",
        "        self._preprocessing(df)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self._model.parameters(), lr=self._learnning_rate)\n",
        "        train_dataset = DatasetLoader(df)\n",
        "        sampler = RandomSampler(train_dataset)\n",
        "\n",
        "        train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                        batch_size=self._batch_size,\n",
        "                                                        shuffle=False,\n",
        "                                                        num_workers=4,\n",
        "                                                        drop_last=False,\n",
        "                                                        sampler=sampler,\n",
        "                                                        collate_fn=group_rows)\n",
        "\n",
        "        loss_fn  = nn.BCEWithLogitsLoss(pos_weight = pos_weights_tensor).to(device)\n",
        "\n",
        "        for batch in range(self._number_of_epocs):\n",
        "\n",
        "          total_loss = 0.0\n",
        "          for ids, tokends_ids, attention_mask, targets in train_data_loader:\n",
        "                \n",
        "              tokends_ids = tokends_ids.to(device)\n",
        "              attention_mask = attention_mask.to(device)\n",
        "              targets = targets.to(device)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              output = self._model(tokends_ids, attention_mask)\n",
        "              loss = loss_fn(output, targets)\n",
        "    \n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              total_loss += loss.item()\n",
        "            \n",
        "          print('batch {} loss {}'.format(batch, total_loss/len(train_dataset)))\n",
        "\n",
        "    def predict(self, df: pd.DataFrame):\n",
        "\n",
        "      self._preprocessing(df)\n",
        "      \n",
        "      self._model.eval()\n",
        "\n",
        "      predict_dataset_loader = DatasetLoader(df)\n",
        "\n",
        "      predict_data_loader = torch.utils.data.DataLoader(predict_dataset_loader,\n",
        "                                                              batch_size=self._batch_size,\n",
        "                                                              shuffle=False,\n",
        "                                                              num_workers=4,\n",
        "                                                              drop_last=False,\n",
        "                                                              collate_fn=group_rows)\n",
        "      with torch.no_grad():\n",
        "\n",
        "        predictions = {}\n",
        "        \n",
        "        for ids, tokends_ids, attention_mask, _ in predict_data_loader:\n",
        "          tokends_ids = tokends_ids.to(device)\n",
        "          attention_mask = attention_mask.to(device)\n",
        "          \n",
        "          logit = self._model(tokends_ids, attention_mask)\n",
        "\n",
        "          probs = torch.sigmoid(logit).detach().cpu().numpy().flatten()\n",
        "          batch_predictions = probs > self._prediction_threshold\n",
        "\n",
        "          for id, prediction in zip(ids, batch_predictions):\n",
        "            predictions[id] = prediction \n",
        "          \n",
        "      return df['id'].apply(lambda id: predictions[id]).tolist()\n",
        "      "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woWgCg3OPM1X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "24df7ec5-35e1-469a-cb4c-b7e6841a606d"
      },
      "source": [
        "# hidden_layer = 12\n",
        "# deep_model = DeepModel(bert, tokenizer, hidden_layer, BATCH_SIZE, PREDICTION_THRESHOLD)\n",
        "\n",
        "# deep_model.fit(train_df.sample(1000))\n",
        "# scores2 = deep_model.evaluate(validation_df.sample(100))\n",
        "# scores2['model'] = 'deep'\n",
        "# scores2['hidden_layer'] = 11\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>fscore</th>\n",
              "      <th>model</th>\n",
              "      <th>hidden_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>deep</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>deep</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision    recall    fscore model  hidden_layer\n",
              "0       0.05  0.111111  0.068966  deep            11\n",
              "0       0.20  0.230769  0.214286  deep            11"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd2BRTnoszmH",
        "outputId": "34cd5934-2a58-40a8-ebe5-2a7cc1b7e91b"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "PREDICTION_THRESHOLD = 0.65 \n",
        "N_NEIGHBORS = 3\n",
        "\n",
        "scores_dfs = []\n",
        "for hidden_layer in [9,10, 11, 12]:\n",
        "\n",
        "  print('running on hidden layer {}'.format(hidden_layer))\n",
        "\n",
        "  deep_model = DeepModel(bert, tokenizer, hidden_layer, BATCH_SIZE, PREDICTION_THRESHOLD)\n",
        "\n",
        "  deep_model.fit(train_df)\n",
        "  scores_df = deep_model.evaluate(validation_df)\n",
        "  scores_df['model'] = 'Deep'\n",
        "  scores_df['hidden_layer'] = hidden_layer\n",
        "  scores_dfs.append(scores_df)\n",
        "  \n",
        "\n",
        "  nearestNeiborClassifier = NearestNeiborClassifier(bert, tokenizer, hidden_layer, N_NEIGHBORS)\n",
        "  nearestNeiborClassifier.fit(train_df)\n",
        "  scores_df = nearestNeiborClassifier.evaluate(validation_df)\n",
        "\n",
        "  scores_df['model'] = 'NearestNeibor'\n",
        "  scores_df['hidden_layer'] = hidden_layer\n",
        "  scores_dfs.append(scores_df)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on hidden layer 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 10743/80000 [00:18<01:47, 645.93it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "PRlrbL0uO0oB",
        "outputId": "86cdc0cb-dcc5-466d-b989-8a0070179c6f"
      },
      "source": [
        "pd.concat(scores_dfs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:03<00:00, 620.28it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>fscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.552901</td>\n",
              "      <td>0.80597</td>\n",
              "      <td>0.65587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision   recall   fscore\n",
              "0   0.552901  0.80597  0.65587"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ITAnaPU7P"
      },
      "source": [
        ""
      ]
    }
  ]
}